2024-04-26 18:19:32,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 18:19:32,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 18:19:32,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 18:19:32,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 18:45:51,696:INFO:PyCaret ClassificationExperiment
2024-04-26 18:45:51,696:INFO:Logging name: clf-default-name
2024-04-26 18:45:51,697:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 18:45:51,697:INFO:version 3.3.1
2024-04-26 18:45:51,697:INFO:Initializing setup()
2024-04-26 18:45:51,697:INFO:self.USI: a0d2
2024-04-26 18:45:51,698:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 18:45:51,698:INFO:Checking environment
2024-04-26 18:45:51,698:INFO:python_version: 3.10.9
2024-04-26 18:45:51,698:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 18:45:51,699:INFO:machine: AMD64
2024-04-26 18:45:51,719:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 18:45:51,719:INFO:Memory: svmem(total=16541904896, available=4163653632, percent=74.8, used=12378251264, free=4163653632)
2024-04-26 18:45:51,719:INFO:Physical Core: 6
2024-04-26 18:45:51,719:INFO:Logical Core: 12
2024-04-26 18:45:51,719:INFO:Checking libraries
2024-04-26 18:45:51,719:INFO:System:
2024-04-26 18:45:51,719:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 18:45:51,719:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 18:45:51,720:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 18:45:51,720:INFO:PyCaret required dependencies:
2024-04-26 18:48:50,081:INFO:PyCaret ClassificationExperiment
2024-04-26 18:48:50,081:INFO:Logging name: clf-default-name
2024-04-26 18:48:50,081:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 18:48:50,081:INFO:version 3.3.1
2024-04-26 18:48:50,081:INFO:Initializing setup()
2024-04-26 18:48:50,082:INFO:self.USI: f82b
2024-04-26 18:48:50,082:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 18:48:50,082:INFO:Checking environment
2024-04-26 18:48:50,082:INFO:python_version: 3.10.9
2024-04-26 18:48:50,082:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 18:48:50,083:INFO:machine: AMD64
2024-04-26 18:48:50,083:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 18:48:50,083:INFO:Memory: svmem(total=16541904896, available=3812380672, percent=77.0, used=12729524224, free=3812380672)
2024-04-26 18:48:50,083:INFO:Physical Core: 6
2024-04-26 18:48:50,083:INFO:Logical Core: 12
2024-04-26 18:48:50,083:INFO:Checking libraries
2024-04-26 18:48:50,083:INFO:System:
2024-04-26 18:48:50,084:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 18:48:50,084:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 18:48:50,084:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 18:48:50,084:INFO:PyCaret required dependencies:
2024-04-26 18:54:32,187:INFO:PyCaret ClassificationExperiment
2024-04-26 18:54:32,188:INFO:Logging name: clf-default-name
2024-04-26 18:54:32,188:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 18:54:32,188:INFO:version 3.3.1
2024-04-26 18:54:32,188:INFO:Initializing setup()
2024-04-26 18:54:32,188:INFO:self.USI: ca44
2024-04-26 18:54:32,188:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 18:54:32,188:INFO:Checking environment
2024-04-26 18:54:32,188:INFO:python_version: 3.10.9
2024-04-26 18:54:32,188:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 18:54:32,189:INFO:machine: AMD64
2024-04-26 18:54:32,189:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 18:54:32,189:INFO:Memory: svmem(total=16541904896, available=4559941632, percent=72.4, used=11981963264, free=4559941632)
2024-04-26 18:54:32,189:INFO:Physical Core: 6
2024-04-26 18:54:32,189:INFO:Logical Core: 12
2024-04-26 18:54:32,189:INFO:Checking libraries
2024-04-26 18:54:32,189:INFO:System:
2024-04-26 18:54:32,189:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 18:54:32,189:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 18:54:32,189:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 18:54:32,189:INFO:PyCaret required dependencies:
2024-04-26 18:58:41,465:INFO:PyCaret ClassificationExperiment
2024-04-26 18:58:41,465:INFO:Logging name: clf-default-name
2024-04-26 18:58:41,466:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 18:58:41,466:INFO:version 3.3.1
2024-04-26 18:58:41,466:INFO:Initializing setup()
2024-04-26 18:58:41,466:INFO:self.USI: 85f9
2024-04-26 18:58:41,466:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 18:58:41,466:INFO:Checking environment
2024-04-26 18:58:41,467:INFO:python_version: 3.10.9
2024-04-26 18:58:41,467:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 18:58:41,467:INFO:machine: AMD64
2024-04-26 18:58:41,467:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 18:58:41,467:INFO:Memory: svmem(total=16541904896, available=3932565504, percent=76.2, used=12609339392, free=3932565504)
2024-04-26 18:58:41,468:INFO:Physical Core: 6
2024-04-26 18:58:41,468:INFO:Logical Core: 12
2024-04-26 18:58:41,468:INFO:Checking libraries
2024-04-26 18:58:41,468:INFO:System:
2024-04-26 18:58:41,468:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 18:58:41,468:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 18:58:41,469:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 18:58:41,469:INFO:PyCaret required dependencies:
2024-04-26 18:58:48,216:INFO:PyCaret ClassificationExperiment
2024-04-26 18:58:48,216:INFO:Logging name: clf-default-name
2024-04-26 18:58:48,218:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 18:58:48,218:INFO:version 3.3.1
2024-04-26 18:58:48,218:INFO:Initializing setup()
2024-04-26 18:58:48,218:INFO:self.USI: 76d0
2024-04-26 18:58:48,218:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 18:58:48,218:INFO:Checking environment
2024-04-26 18:58:48,218:INFO:python_version: 3.10.9
2024-04-26 18:58:48,218:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 18:58:48,218:INFO:machine: AMD64
2024-04-26 18:58:48,218:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 18:58:48,218:INFO:Memory: svmem(total=16541904896, available=3955064832, percent=76.1, used=12586840064, free=3955064832)
2024-04-26 18:58:48,218:INFO:Physical Core: 6
2024-04-26 18:58:48,218:INFO:Logical Core: 12
2024-04-26 18:58:48,219:INFO:Checking libraries
2024-04-26 18:58:48,219:INFO:System:
2024-04-26 18:58:48,219:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 18:58:48,219:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 18:58:48,219:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 18:58:48,219:INFO:PyCaret required dependencies:
2024-04-26 18:59:36,601:INFO:PyCaret ClassificationExperiment
2024-04-26 18:59:36,602:INFO:Logging name: clf-default-name
2024-04-26 18:59:36,602:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 18:59:36,602:INFO:version 3.3.1
2024-04-26 18:59:36,602:INFO:Initializing setup()
2024-04-26 18:59:36,602:INFO:self.USI: fcc3
2024-04-26 18:59:36,602:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 18:59:36,602:INFO:Checking environment
2024-04-26 18:59:36,603:INFO:python_version: 3.10.9
2024-04-26 18:59:36,603:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 18:59:36,603:INFO:machine: AMD64
2024-04-26 18:59:36,603:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 18:59:36,603:INFO:Memory: svmem(total=16541904896, available=3921125376, percent=76.3, used=12620779520, free=3921125376)
2024-04-26 18:59:36,603:INFO:Physical Core: 6
2024-04-26 18:59:36,603:INFO:Logical Core: 12
2024-04-26 18:59:36,603:INFO:Checking libraries
2024-04-26 18:59:36,603:INFO:System:
2024-04-26 18:59:36,603:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 18:59:36,604:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 18:59:36,604:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 18:59:36,604:INFO:PyCaret required dependencies:
2024-04-26 18:59:51,980:INFO:PyCaret ClassificationExperiment
2024-04-26 18:59:51,980:INFO:Logging name: clf-default-name
2024-04-26 18:59:51,980:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 18:59:51,980:INFO:version 3.3.1
2024-04-26 18:59:51,980:INFO:Initializing setup()
2024-04-26 18:59:51,980:INFO:self.USI: 7cfb
2024-04-26 18:59:51,980:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 18:59:51,980:INFO:Checking environment
2024-04-26 18:59:51,980:INFO:python_version: 3.10.9
2024-04-26 18:59:51,980:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 18:59:51,981:INFO:machine: AMD64
2024-04-26 18:59:51,981:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 18:59:51,981:INFO:Memory: svmem(total=16541904896, available=3917733888, percent=76.3, used=12624171008, free=3917733888)
2024-04-26 18:59:51,981:INFO:Physical Core: 6
2024-04-26 18:59:51,981:INFO:Logical Core: 12
2024-04-26 18:59:51,981:INFO:Checking libraries
2024-04-26 18:59:51,981:INFO:System:
2024-04-26 18:59:51,981:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 18:59:51,981:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 18:59:51,982:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 18:59:51,982:INFO:PyCaret required dependencies:
2024-04-26 19:00:32,680:INFO:PyCaret ClassificationExperiment
2024-04-26 19:00:32,680:INFO:Logging name: clf-default-name
2024-04-26 19:00:32,680:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 19:00:32,682:INFO:version 3.3.1
2024-04-26 19:00:32,682:INFO:Initializing setup()
2024-04-26 19:00:32,682:INFO:self.USI: 644a
2024-04-26 19:00:32,682:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 19:00:32,682:INFO:Checking environment
2024-04-26 19:00:32,682:INFO:python_version: 3.10.9
2024-04-26 19:00:32,682:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 19:00:32,682:INFO:machine: AMD64
2024-04-26 19:00:32,682:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 19:00:32,682:INFO:Memory: svmem(total=16541904896, available=3927965696, percent=76.3, used=12613939200, free=3927965696)
2024-04-26 19:00:32,683:INFO:Physical Core: 6
2024-04-26 19:00:32,683:INFO:Logical Core: 12
2024-04-26 19:00:32,683:INFO:Checking libraries
2024-04-26 19:00:32,683:INFO:System:
2024-04-26 19:00:32,683:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 19:00:32,683:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 19:00:32,683:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 19:00:32,683:INFO:PyCaret required dependencies:
2024-04-26 19:00:37,305:INFO:PyCaret ClassificationExperiment
2024-04-26 19:00:37,306:INFO:Logging name: clf-default-name
2024-04-26 19:00:37,306:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 19:00:37,306:INFO:version 3.3.1
2024-04-26 19:00:37,306:INFO:Initializing setup()
2024-04-26 19:00:37,306:INFO:self.USI: fee9
2024-04-26 19:00:37,306:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 19:00:37,306:INFO:Checking environment
2024-04-26 19:00:37,306:INFO:python_version: 3.10.9
2024-04-26 19:00:37,307:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 19:00:37,307:INFO:machine: AMD64
2024-04-26 19:00:37,307:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 19:00:37,307:INFO:Memory: svmem(total=16541904896, available=3916804096, percent=76.3, used=12625100800, free=3916804096)
2024-04-26 19:00:37,307:INFO:Physical Core: 6
2024-04-26 19:00:37,307:INFO:Logical Core: 12
2024-04-26 19:00:37,307:INFO:Checking libraries
2024-04-26 19:00:37,307:INFO:System:
2024-04-26 19:00:37,307:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 19:00:37,307:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 19:00:37,308:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 19:00:37,308:INFO:PyCaret required dependencies:
2024-04-26 19:00:43,228:INFO:PyCaret ClassificationExperiment
2024-04-26 19:00:43,228:INFO:Logging name: clf-default-name
2024-04-26 19:00:43,228:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 19:00:43,229:INFO:version 3.3.1
2024-04-26 19:00:43,229:INFO:Initializing setup()
2024-04-26 19:00:43,229:INFO:self.USI: 6210
2024-04-26 19:00:43,229:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 19:00:43,229:INFO:Checking environment
2024-04-26 19:00:43,229:INFO:python_version: 3.10.9
2024-04-26 19:00:43,230:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 19:00:43,230:INFO:machine: AMD64
2024-04-26 19:00:43,230:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 19:00:43,230:INFO:Memory: svmem(total=16541904896, available=3938762752, percent=76.2, used=12603142144, free=3938762752)
2024-04-26 19:00:43,230:INFO:Physical Core: 6
2024-04-26 19:00:43,230:INFO:Logical Core: 12
2024-04-26 19:00:43,230:INFO:Checking libraries
2024-04-26 19:00:43,231:INFO:System:
2024-04-26 19:00:43,231:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 19:00:43,231:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 19:00:43,231:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 19:00:43,231:INFO:PyCaret required dependencies:
2024-04-26 19:04:59,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:04:59,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:04:59,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:04:59,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:06:19,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:06:19,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:06:19,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:06:19,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:07:10,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:07:10,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:07:10,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:07:10,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:08:20,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:08:20,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:08:20,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:08:20,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:08:40,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:08:40,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:08:40,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:08:40,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:09:50,884:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:09:50,884:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:09:50,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:09:50,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:09:52,920:INFO:PyCaret ClassificationExperiment
2024-04-26 19:09:52,920:INFO:Logging name: clf-default-name
2024-04-26 19:09:52,920:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 19:09:52,920:INFO:version 3.3.1
2024-04-26 19:09:52,920:INFO:Initializing setup()
2024-04-26 19:09:52,920:INFO:self.USI: b1e0
2024-04-26 19:09:52,920:INFO:self._variable_keys: {'target_param', 'exp_id', 'pipeline', 'fold_generator', '_available_plots', 'logging_param', 'X_train', 'y_test', 'memory', 'log_plots_param', 'data', 'fold_shuffle_param', 'X_test', 'gpu_param', 'fold_groups_param', 'gpu_n_jobs_param', 'is_multiclass', 'exp_name_log', 'seed', 'html_param', 'y_train', 'X', 'idx', 'y', 'USI', 'fix_imbalance', '_ml_usecase', 'n_jobs_param'}
2024-04-26 19:09:52,921:INFO:Checking environment
2024-04-26 19:09:52,921:INFO:python_version: 3.10.9
2024-04-26 19:09:52,921:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 19:09:52,921:INFO:machine: AMD64
2024-04-26 19:09:52,937:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 19:09:52,937:INFO:Memory: svmem(total=16541904896, available=4191854592, percent=74.7, used=12350050304, free=4191854592)
2024-04-26 19:09:52,937:INFO:Physical Core: 6
2024-04-26 19:09:52,938:INFO:Logical Core: 12
2024-04-26 19:09:52,938:INFO:Checking libraries
2024-04-26 19:09:52,938:INFO:System:
2024-04-26 19:09:52,938:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 19:09:52,938:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 19:09:52,939:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 19:09:52,939:INFO:PyCaret required dependencies:
2024-04-26 19:14:54,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:14:54,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:14:54,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:14:54,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 19:14:56,997:INFO:PyCaret ClassificationExperiment
2024-04-26 19:14:56,997:INFO:Logging name: clf-default-name
2024-04-26 19:14:56,998:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 19:14:56,998:INFO:version 3.3.1
2024-04-26 19:14:56,998:INFO:Initializing setup()
2024-04-26 19:14:56,998:INFO:self.USI: 6694
2024-04-26 19:14:56,998:INFO:self._variable_keys: {'_available_plots', 'pipeline', 'USI', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'html_param', 'target_param', 'memory', 'seed', 'gpu_param', 'fold_shuffle_param', 'fold_generator', 'X_test', 'X', '_ml_usecase', 'y_test', 'fold_groups_param', 'y', 'y_train', 'X_train', 'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'idx', 'exp_id', 'fix_imbalance', 'data'}
2024-04-26 19:14:56,998:INFO:Checking environment
2024-04-26 19:14:56,998:INFO:python_version: 3.10.9
2024-04-26 19:14:56,998:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 19:14:56,999:INFO:machine: AMD64
2024-04-26 19:14:57,014:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 19:14:57,014:INFO:Memory: svmem(total=16541904896, available=3945357312, percent=76.1, used=12596547584, free=3945357312)
2024-04-26 19:14:57,014:INFO:Physical Core: 6
2024-04-26 19:14:57,014:INFO:Logical Core: 12
2024-04-26 19:14:57,014:INFO:Checking libraries
2024-04-26 19:14:57,016:INFO:System:
2024-04-26 19:14:57,016:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 19:14:57,016:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 19:14:57,016:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 19:14:57,016:INFO:PyCaret required dependencies:
2024-04-26 19:28:37,027:INFO:PyCaret ClassificationExperiment
2024-04-26 19:28:37,027:INFO:Logging name: clf-default-name
2024-04-26 19:28:37,027:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 19:28:37,027:INFO:version 3.3.1
2024-04-26 19:28:37,027:INFO:Initializing setup()
2024-04-26 19:28:37,027:INFO:self.USI: f3d3
2024-04-26 19:28:37,027:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 19:28:37,027:INFO:Checking environment
2024-04-26 19:28:37,027:INFO:python_version: 3.10.9
2024-04-26 19:28:37,027:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 19:28:37,028:INFO:machine: AMD64
2024-04-26 19:28:37,028:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 19:28:37,028:INFO:Memory: svmem(total=16541904896, available=3871535104, percent=76.6, used=12670369792, free=3871535104)
2024-04-26 19:28:37,028:INFO:Physical Core: 6
2024-04-26 19:28:37,028:INFO:Logical Core: 12
2024-04-26 19:28:37,028:INFO:Checking libraries
2024-04-26 19:28:37,028:INFO:System:
2024-04-26 19:28:37,028:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 19:28:37,028:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 19:28:37,028:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 19:28:37,028:INFO:PyCaret required dependencies:
2024-04-26 22:05:48,495:INFO:PyCaret ClassificationExperiment
2024-04-26 22:05:48,495:INFO:Logging name: clf-default-name
2024-04-26 22:05:48,495:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 22:05:48,495:INFO:version 3.3.1
2024-04-26 22:05:48,495:INFO:Initializing setup()
2024-04-26 22:05:48,495:INFO:self.USI: 54fd
2024-04-26 22:05:48,495:INFO:self._variable_keys: {'_available_plots', 'USI', 'y_train', 'n_jobs_param', 'seed', 'fold_groups_param', 'X_test', 'memory', 'gpu_param', 'logging_param', 'y_test', 'X_train', 'html_param', 'fix_imbalance', 'exp_name_log', 'log_plots_param', 'idx', '_ml_usecase', 'target_param', 'exp_id', 'is_multiclass', 'pipeline', 'y', 'data', 'fold_generator', 'X', 'fold_shuffle_param', 'gpu_n_jobs_param'}
2024-04-26 22:05:48,495:INFO:Checking environment
2024-04-26 22:05:48,495:INFO:python_version: 3.10.9
2024-04-26 22:05:48,496:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 22:05:48,496:INFO:machine: AMD64
2024-04-26 22:05:48,496:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 22:05:48,496:INFO:Memory: svmem(total=16541904896, available=3897565184, percent=76.4, used=12644339712, free=3897565184)
2024-04-26 22:05:48,496:INFO:Physical Core: 6
2024-04-26 22:05:48,496:INFO:Logical Core: 12
2024-04-26 22:05:48,496:INFO:Checking libraries
2024-04-26 22:05:48,496:INFO:System:
2024-04-26 22:05:48,496:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 22:05:48,496:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 22:05:48,496:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 22:05:48,496:INFO:PyCaret required dependencies:
2024-04-26 22:31:46,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:31:46,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:31:46,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:31:46,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:31:47,210:INFO:PyCaret ClassificationExperiment
2024-04-26 22:31:47,211:INFO:Logging name: clf-default-name
2024-04-26 22:31:47,211:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 22:31:47,211:INFO:version 3.3.1
2024-04-26 22:31:47,211:INFO:Initializing setup()
2024-04-26 22:31:47,211:INFO:self.USI: 9803
2024-04-26 22:31:47,211:INFO:self._variable_keys: {'X', 'n_jobs_param', 'data', 'exp_name_log', 'target_param', 'fold_shuffle_param', 'X_train', 'USI', 'fold_groups_param', 'y', 'exp_id', '_ml_usecase', 'fold_generator', 'pipeline', 'y_train', 'logging_param', 'log_plots_param', '_available_plots', 'html_param', 'y_test', 'idx', 'memory', 'gpu_param', 'X_test', 'is_multiclass', 'seed', 'gpu_n_jobs_param', 'fix_imbalance'}
2024-04-26 22:31:47,211:INFO:Checking environment
2024-04-26 22:31:47,211:INFO:python_version: 3.10.9
2024-04-26 22:31:47,211:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 22:31:47,211:INFO:machine: AMD64
2024-04-26 22:31:47,218:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 22:31:47,218:INFO:Memory: svmem(total=16541904896, available=2882428928, percent=82.6, used=13659475968, free=2882428928)
2024-04-26 22:31:47,218:INFO:Physical Core: 6
2024-04-26 22:31:47,218:INFO:Logical Core: 12
2024-04-26 22:31:47,219:INFO:Checking libraries
2024-04-26 22:31:47,219:INFO:System:
2024-04-26 22:31:47,219:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 22:31:47,219:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 22:31:47,219:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 22:31:47,219:INFO:PyCaret required dependencies:
2024-04-26 22:35:44,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:35:44,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:35:44,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:35:44,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:35:45,360:INFO:PyCaret ClassificationExperiment
2024-04-26 22:35:45,360:INFO:Logging name: clf-default-name
2024-04-26 22:35:45,360:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 22:35:45,360:INFO:version 3.3.1
2024-04-26 22:35:45,360:INFO:Initializing setup()
2024-04-26 22:35:45,360:INFO:self.USI: 4ea2
2024-04-26 22:35:45,360:INFO:self._variable_keys: {'seed', 'X_test', 'y', '_ml_usecase', 'idx', 'exp_name_log', 'target_param', 'USI', 'fold_generator', 'fix_imbalance', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'exp_id', 'X_train', 'is_multiclass', 'memory', 'y_train', 'n_jobs_param', 'gpu_param', '_available_plots', 'y_test', 'log_plots_param', 'logging_param', 'X', 'html_param'}
2024-04-26 22:35:45,360:INFO:Checking environment
2024-04-26 22:35:45,360:INFO:python_version: 3.10.9
2024-04-26 22:35:45,360:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 22:35:45,360:INFO:machine: AMD64
2024-04-26 22:35:45,367:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 22:35:45,367:INFO:Memory: svmem(total=16541904896, available=2129141760, percent=87.1, used=14412763136, free=2129141760)
2024-04-26 22:35:45,367:INFO:Physical Core: 6
2024-04-26 22:35:45,367:INFO:Logical Core: 12
2024-04-26 22:35:45,367:INFO:Checking libraries
2024-04-26 22:35:45,368:INFO:System:
2024-04-26 22:35:45,368:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 22:35:45,368:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 22:35:45,368:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 22:35:45,368:INFO:PyCaret required dependencies:
2024-04-26 22:41:08,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:41:08,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:41:08,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:41:08,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:41:09,004:INFO:PyCaret ClassificationExperiment
2024-04-26 22:41:09,004:INFO:Logging name: clf-default-name
2024-04-26 22:41:09,004:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 22:41:09,004:INFO:version 3.3.1
2024-04-26 22:41:09,004:INFO:Initializing setup()
2024-04-26 22:41:09,004:INFO:self.USI: 8256
2024-04-26 22:41:09,004:INFO:self._variable_keys: {'exp_name_log', 'fold_generator', '_ml_usecase', 'data', 'X_test', 'logging_param', 'y_test', 'seed', 'pipeline', 'y', 'USI', 'target_param', 'log_plots_param', 'idx', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'html_param', '_available_plots', 'X', 'memory', 'fold_groups_param', 'fold_shuffle_param', 'exp_id', 'n_jobs_param', 'X_train', 'fix_imbalance', 'is_multiclass'}
2024-04-26 22:41:09,004:INFO:Checking environment
2024-04-26 22:41:09,004:INFO:python_version: 3.10.9
2024-04-26 22:41:09,004:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 22:41:09,004:INFO:machine: AMD64
2024-04-26 22:41:09,011:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 22:41:09,011:INFO:Memory: svmem(total=16541904896, available=2166702080, percent=86.9, used=14375202816, free=2166702080)
2024-04-26 22:41:09,011:INFO:Physical Core: 6
2024-04-26 22:41:09,011:INFO:Logical Core: 12
2024-04-26 22:41:09,011:INFO:Checking libraries
2024-04-26 22:41:09,011:INFO:System:
2024-04-26 22:41:09,011:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 22:41:09,012:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 22:41:09,012:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 22:41:09,012:INFO:PyCaret required dependencies:
2024-04-26 22:45:39,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:45:39,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:45:39,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:45:39,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:45:40,670:INFO:PyCaret ClassificationExperiment
2024-04-26 22:45:40,670:INFO:Logging name: clf-default-name
2024-04-26 22:45:40,670:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 22:45:40,670:INFO:version 3.3.1
2024-04-26 22:45:40,670:INFO:Initializing setup()
2024-04-26 22:45:40,670:INFO:self.USI: e100
2024-04-26 22:45:40,670:INFO:self._variable_keys: {'target_param', 'X_train', 'exp_id', 'memory', 'y_train', 'exp_name_log', 'html_param', 'data', 'fix_imbalance', '_available_plots', 'pipeline', 'log_plots_param', 'logging_param', 'y_test', 'X', 'gpu_n_jobs_param', 'fold_generator', 'USI', 'gpu_param', 'fold_groups_param', 'n_jobs_param', '_ml_usecase', 'idx', 'fold_shuffle_param', 'X_test', 'seed', 'y', 'is_multiclass'}
2024-04-26 22:45:40,670:INFO:Checking environment
2024-04-26 22:45:40,670:INFO:python_version: 3.10.9
2024-04-26 22:45:40,670:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 22:45:40,670:INFO:machine: AMD64
2024-04-26 22:45:40,677:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 22:45:40,677:INFO:Memory: svmem(total=16541904896, available=2143916032, percent=87.0, used=14397988864, free=2143916032)
2024-04-26 22:45:40,677:INFO:Physical Core: 6
2024-04-26 22:45:40,677:INFO:Logical Core: 12
2024-04-26 22:45:40,677:INFO:Checking libraries
2024-04-26 22:45:40,677:INFO:System:
2024-04-26 22:45:40,677:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 22:45:40,678:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 22:45:40,678:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 22:45:40,678:INFO:PyCaret required dependencies:
2024-04-26 22:53:33,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:53:33,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:53:33,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:53:33,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:53:34,672:INFO:PyCaret ClassificationExperiment
2024-04-26 22:53:34,673:INFO:Logging name: clf-default-name
2024-04-26 22:53:34,673:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 22:53:34,673:INFO:version 3.3.1
2024-04-26 22:53:34,673:INFO:Initializing setup()
2024-04-26 22:53:34,673:INFO:self.USI: e2f9
2024-04-26 22:53:34,673:INFO:self._variable_keys: {'y_test', 'USI', 'log_plots_param', 'X_test', 'fold_groups_param', 'exp_name_log', 'memory', 'fold_generator', 'n_jobs_param', 'gpu_n_jobs_param', 'data', 'gpu_param', 'fix_imbalance', 'idx', '_ml_usecase', 'fold_shuffle_param', '_available_plots', 'target_param', 'y', 'pipeline', 'X', 'exp_id', 'seed', 'y_train', 'X_train', 'html_param', 'logging_param', 'is_multiclass'}
2024-04-26 22:53:34,673:INFO:Checking environment
2024-04-26 22:53:34,673:INFO:python_version: 3.10.9
2024-04-26 22:53:34,673:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 22:53:34,673:INFO:machine: AMD64
2024-04-26 22:53:34,679:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 22:53:34,679:INFO:Memory: svmem(total=16541904896, available=2195030016, percent=86.7, used=14346874880, free=2195030016)
2024-04-26 22:53:34,679:INFO:Physical Core: 6
2024-04-26 22:53:34,680:INFO:Logical Core: 12
2024-04-26 22:53:34,680:INFO:Checking libraries
2024-04-26 22:53:34,680:INFO:System:
2024-04-26 22:53:34,680:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 22:53:34,680:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 22:53:34,680:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 22:53:34,680:INFO:PyCaret required dependencies:
2024-04-26 22:53:35,027:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 22:53:35,410:INFO:                 pip: 22.3.1
2024-04-26 22:53:35,410:INFO:          setuptools: 65.6.3
2024-04-26 22:53:35,410:INFO:             pycaret: 3.3.1
2024-04-26 22:53:35,411:INFO:             IPython: 8.10.0
2024-04-26 22:53:35,411:INFO:          ipywidgets: 7.6.5
2024-04-26 22:53:35,411:INFO:                tqdm: 4.64.1
2024-04-26 22:53:35,411:INFO:               numpy: 1.23.5
2024-04-26 22:53:35,411:INFO:              pandas: 2.2.2
2024-04-26 22:53:35,411:INFO:              jinja2: 3.1.2
2024-04-26 22:53:35,411:INFO:               scipy: 1.10.0
2024-04-26 22:53:35,411:INFO:              joblib: 1.3.2
2024-04-26 22:53:35,411:INFO:             sklearn: 1.4.2
2024-04-26 22:53:35,411:INFO:                pyod: 1.1.3
2024-04-26 22:53:35,411:INFO:            imblearn: 0.10.1
2024-04-26 22:53:35,411:INFO:   category_encoders: 2.6.3
2024-04-26 22:53:35,411:INFO:            lightgbm: 4.3.0
2024-04-26 22:53:35,411:INFO:               numba: 0.56.4
2024-04-26 22:53:35,411:INFO:            requests: 2.28.1
2024-04-26 22:53:35,411:INFO:          matplotlib: 3.7.0
2024-04-26 22:53:35,411:INFO:          scikitplot: 0.3.7
2024-04-26 22:53:35,411:INFO:         yellowbrick: 1.5
2024-04-26 22:53:35,411:INFO:              plotly: 5.21.0
2024-04-26 22:53:35,411:INFO:    plotly-resampler: Not installed
2024-04-26 22:53:35,411:INFO:             kaleido: 0.2.1
2024-04-26 22:53:35,411:INFO:           schemdraw: 0.15
2024-04-26 22:53:35,411:INFO:         statsmodels: 0.13.5
2024-04-26 22:53:35,411:INFO:              sktime: 0.26.0
2024-04-26 22:53:35,411:INFO:               tbats: 1.1.3
2024-04-26 22:53:35,411:INFO:            pmdarima: 2.0.4
2024-04-26 22:53:35,411:INFO:              psutil: 5.9.0
2024-04-26 22:53:35,412:INFO:          markupsafe: 2.1.1
2024-04-26 22:53:35,412:INFO:             pickle5: Not installed
2024-04-26 22:53:35,412:INFO:         cloudpickle: 2.0.0
2024-04-26 22:53:35,412:INFO:         deprecation: 2.1.0
2024-04-26 22:53:35,412:INFO:              xxhash: 3.4.1
2024-04-26 22:53:35,412:INFO:           wurlitzer: Not installed
2024-04-26 22:53:35,412:INFO:PyCaret optional dependencies:
2024-04-26 22:53:35,422:INFO:                shap: Not installed
2024-04-26 22:53:35,422:INFO:           interpret: Not installed
2024-04-26 22:53:35,422:INFO:                umap: Not installed
2024-04-26 22:53:35,422:INFO:     ydata_profiling: 4.7.0
2024-04-26 22:53:35,422:INFO:  explainerdashboard: Not installed
2024-04-26 22:53:35,422:INFO:             autoviz: Not installed
2024-04-26 22:53:35,422:INFO:           fairlearn: Not installed
2024-04-26 22:53:35,422:INFO:          deepchecks: Not installed
2024-04-26 22:53:35,422:INFO:             xgboost: Not installed
2024-04-26 22:53:35,422:INFO:            catboost: Not installed
2024-04-26 22:53:35,422:INFO:              kmodes: Not installed
2024-04-26 22:53:35,422:INFO:             mlxtend: Not installed
2024-04-26 22:53:35,422:INFO:       statsforecast: Not installed
2024-04-26 22:53:35,422:INFO:        tune_sklearn: Not installed
2024-04-26 22:53:35,423:INFO:                 ray: Not installed
2024-04-26 22:53:35,423:INFO:            hyperopt: Not installed
2024-04-26 22:53:35,423:INFO:              optuna: Not installed
2024-04-26 22:53:35,423:INFO:               skopt: Not installed
2024-04-26 22:53:35,423:INFO:              mlflow: Not installed
2024-04-26 22:53:35,423:INFO:              gradio: Not installed
2024-04-26 22:53:35,423:INFO:             fastapi: Not installed
2024-04-26 22:53:35,423:INFO:             uvicorn: Not installed
2024-04-26 22:53:35,423:INFO:              m2cgen: Not installed
2024-04-26 22:53:35,423:INFO:           evidently: Not installed
2024-04-26 22:53:35,423:INFO:               fugue: Not installed
2024-04-26 22:53:35,423:INFO:           streamlit: 1.33.0
2024-04-26 22:53:35,423:INFO:             prophet: Not installed
2024-04-26 22:53:35,423:INFO:None
2024-04-26 22:53:35,423:INFO:Set up data.
2024-04-26 22:53:35,427:INFO:Set up folding strategy.
2024-04-26 22:53:35,427:INFO:Set up train/test split.
2024-04-26 22:53:35,434:INFO:Set up index.
2024-04-26 22:53:35,434:INFO:Assigning column types.
2024-04-26 22:53:35,437:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-26 22:53:35,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 22:53:35,478:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 22:53:35,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 22:53:35,547:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 22:53:35,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,570:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-26 22:53:35,608:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 22:53:35,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 22:53:35,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,696:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-26 22:53:35,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,823:INFO:Preparing preprocessing pipeline...
2024-04-26 22:53:35,823:INFO:Set up simple imputation.
2024-04-26 22:53:35,845:INFO:Finished creating preprocessing pipeline.
2024-04-26 22:53:35,848:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-04-26 22:53:35,848:INFO:Creating final display dataframe.
2024-04-26 22:53:35,901:INFO:Setup _display_container:                     Description             Value
0                    Session id              8844
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape          (768, 9)
4        Transformed data shape          (768, 9)
5   Transformed train set shape          (537, 9)
6    Transformed test set shape          (231, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e2f9
2024-04-26 22:53:35,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:35,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:36,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:36,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 22:53:36,046:INFO:setup() successfully completed in 1.37s...............
2024-04-26 22:55:32,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:55:32,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:55:32,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:55:32,762:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:56:30,837:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:56:30,837:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:56:30,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 22:56:30,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 23:00:13,662:INFO:PyCaret ClassificationExperiment
2024-04-26 23:00:13,662:INFO:Logging name: clf-default-name
2024-04-26 23:00:13,662:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 23:00:13,662:INFO:version 3.3.1
2024-04-26 23:00:13,662:INFO:Initializing setup()
2024-04-26 23:00:13,662:INFO:self.USI: 2dbf
2024-04-26 23:00:13,662:INFO:self._variable_keys: {'data', 'fold_groups_param', 'X_test', 'y_test', 'log_plots_param', 'exp_id', 'y_train', 'X_train', 'target_param', 'logging_param', 'idx', 'html_param', 'gpu_param', 'y', 'is_multiclass', 'pipeline', 'X', 'exp_name_log', 'fix_imbalance', 'n_jobs_param', 'fold_shuffle_param', 'seed', 'memory', 'fold_generator', '_ml_usecase', 'USI', 'gpu_n_jobs_param', '_available_plots'}
2024-04-26 23:00:13,662:INFO:Checking environment
2024-04-26 23:00:13,662:INFO:python_version: 3.10.9
2024-04-26 23:00:13,662:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 23:00:13,663:INFO:machine: AMD64
2024-04-26 23:00:13,670:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 23:00:13,672:INFO:Memory: svmem(total=16541904896, available=3025055744, percent=81.7, used=13516849152, free=3025055744)
2024-04-26 23:00:13,672:INFO:Physical Core: 6
2024-04-26 23:00:13,672:INFO:Logical Core: 12
2024-04-26 23:00:13,672:INFO:Checking libraries
2024-04-26 23:00:13,672:INFO:System:
2024-04-26 23:00:13,672:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 23:00:13,672:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 23:00:13,672:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 23:00:13,672:INFO:PyCaret required dependencies:
2024-04-26 23:00:14,177:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:14,410:INFO:                 pip: 22.3.1
2024-04-26 23:00:14,410:INFO:          setuptools: 65.6.3
2024-04-26 23:00:14,410:INFO:             pycaret: 3.3.1
2024-04-26 23:00:14,410:INFO:             IPython: 8.10.0
2024-04-26 23:00:14,410:INFO:          ipywidgets: 7.6.5
2024-04-26 23:00:14,410:INFO:                tqdm: 4.64.1
2024-04-26 23:00:14,410:INFO:               numpy: 1.23.5
2024-04-26 23:00:14,410:INFO:              pandas: 2.2.2
2024-04-26 23:00:14,410:INFO:              jinja2: 3.1.2
2024-04-26 23:00:14,410:INFO:               scipy: 1.10.0
2024-04-26 23:00:14,410:INFO:              joblib: 1.3.2
2024-04-26 23:00:14,410:INFO:             sklearn: 1.4.2
2024-04-26 23:00:14,410:INFO:                pyod: 1.1.3
2024-04-26 23:00:14,410:INFO:            imblearn: 0.10.1
2024-04-26 23:00:14,410:INFO:   category_encoders: 2.6.3
2024-04-26 23:00:14,410:INFO:            lightgbm: 4.3.0
2024-04-26 23:00:14,410:INFO:               numba: 0.56.4
2024-04-26 23:00:14,410:INFO:            requests: 2.28.1
2024-04-26 23:00:14,410:INFO:          matplotlib: 3.7.0
2024-04-26 23:00:14,410:INFO:          scikitplot: 0.3.7
2024-04-26 23:00:14,410:INFO:         yellowbrick: 1.5
2024-04-26 23:00:14,410:INFO:              plotly: 5.21.0
2024-04-26 23:00:14,410:INFO:    plotly-resampler: Not installed
2024-04-26 23:00:14,411:INFO:             kaleido: 0.2.1
2024-04-26 23:00:14,411:INFO:           schemdraw: 0.15
2024-04-26 23:00:14,411:INFO:         statsmodels: 0.13.5
2024-04-26 23:00:14,411:INFO:              sktime: 0.26.0
2024-04-26 23:00:14,411:INFO:               tbats: 1.1.3
2024-04-26 23:00:14,411:INFO:            pmdarima: 2.0.4
2024-04-26 23:00:14,411:INFO:              psutil: 5.9.0
2024-04-26 23:00:14,411:INFO:          markupsafe: 2.1.1
2024-04-26 23:00:14,411:INFO:             pickle5: Not installed
2024-04-26 23:00:14,411:INFO:         cloudpickle: 2.0.0
2024-04-26 23:00:14,411:INFO:         deprecation: 2.1.0
2024-04-26 23:00:14,411:INFO:              xxhash: 3.4.1
2024-04-26 23:00:14,411:INFO:           wurlitzer: Not installed
2024-04-26 23:00:14,411:INFO:PyCaret optional dependencies:
2024-04-26 23:00:14,422:INFO:                shap: Not installed
2024-04-26 23:00:14,422:INFO:           interpret: Not installed
2024-04-26 23:00:14,422:INFO:                umap: Not installed
2024-04-26 23:00:14,422:INFO:     ydata_profiling: 4.7.0
2024-04-26 23:00:14,422:INFO:  explainerdashboard: Not installed
2024-04-26 23:00:14,422:INFO:             autoviz: Not installed
2024-04-26 23:00:14,422:INFO:           fairlearn: Not installed
2024-04-26 23:00:14,423:INFO:          deepchecks: Not installed
2024-04-26 23:00:14,423:INFO:             xgboost: Not installed
2024-04-26 23:00:14,423:INFO:            catboost: Not installed
2024-04-26 23:00:14,423:INFO:              kmodes: Not installed
2024-04-26 23:00:14,423:INFO:             mlxtend: Not installed
2024-04-26 23:00:14,423:INFO:       statsforecast: Not installed
2024-04-26 23:00:14,423:INFO:        tune_sklearn: Not installed
2024-04-26 23:00:14,423:INFO:                 ray: Not installed
2024-04-26 23:00:14,423:INFO:            hyperopt: Not installed
2024-04-26 23:00:14,423:INFO:              optuna: Not installed
2024-04-26 23:00:14,423:INFO:               skopt: Not installed
2024-04-26 23:00:14,423:INFO:              mlflow: Not installed
2024-04-26 23:00:14,423:INFO:              gradio: Not installed
2024-04-26 23:00:14,424:INFO:             fastapi: Not installed
2024-04-26 23:00:14,424:INFO:             uvicorn: Not installed
2024-04-26 23:00:14,424:INFO:              m2cgen: Not installed
2024-04-26 23:00:14,424:INFO:           evidently: Not installed
2024-04-26 23:00:14,424:INFO:               fugue: Not installed
2024-04-26 23:00:14,424:INFO:           streamlit: 1.33.0
2024-04-26 23:00:14,425:INFO:             prophet: Not installed
2024-04-26 23:00:14,425:INFO:None
2024-04-26 23:00:14,425:INFO:Set up data.
2024-04-26 23:00:14,429:INFO:Set up folding strategy.
2024-04-26 23:00:14,429:INFO:Set up train/test split.
2024-04-26 23:00:32,938:INFO:PyCaret ClassificationExperiment
2024-04-26 23:00:32,938:INFO:Logging name: clf-default-name
2024-04-26 23:00:32,938:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 23:00:32,938:INFO:version 3.3.1
2024-04-26 23:00:32,938:INFO:Initializing setup()
2024-04-26 23:00:32,938:INFO:self.USI: 1555
2024-04-26 23:00:32,938:INFO:self._variable_keys: {'data', 'fold_groups_param', 'X_test', 'y_test', 'log_plots_param', 'exp_id', 'y_train', 'X_train', 'target_param', 'logging_param', 'idx', 'html_param', 'gpu_param', 'y', 'is_multiclass', 'pipeline', 'X', 'exp_name_log', 'fix_imbalance', 'n_jobs_param', 'fold_shuffle_param', 'seed', 'memory', 'fold_generator', '_ml_usecase', 'USI', 'gpu_n_jobs_param', '_available_plots'}
2024-04-26 23:00:32,938:INFO:Checking environment
2024-04-26 23:00:32,938:INFO:python_version: 3.10.9
2024-04-26 23:00:32,938:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 23:00:32,938:INFO:machine: AMD64
2024-04-26 23:00:32,938:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 23:00:32,938:INFO:Memory: svmem(total=16541904896, available=3420524544, percent=79.3, used=13121380352, free=3420524544)
2024-04-26 23:00:32,938:INFO:Physical Core: 6
2024-04-26 23:00:32,938:INFO:Logical Core: 12
2024-04-26 23:00:32,938:INFO:Checking libraries
2024-04-26 23:00:32,938:INFO:System:
2024-04-26 23:00:32,939:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 23:00:32,939:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 23:00:32,939:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 23:00:32,939:INFO:PyCaret required dependencies:
2024-04-26 23:00:32,939:INFO:                 pip: 22.3.1
2024-04-26 23:00:32,939:INFO:          setuptools: 65.6.3
2024-04-26 23:00:32,939:INFO:             pycaret: 3.3.1
2024-04-26 23:00:32,939:INFO:             IPython: 8.10.0
2024-04-26 23:00:32,939:INFO:          ipywidgets: 7.6.5
2024-04-26 23:00:32,939:INFO:                tqdm: 4.64.1
2024-04-26 23:00:32,939:INFO:               numpy: 1.23.5
2024-04-26 23:00:32,940:INFO:              pandas: 2.2.2
2024-04-26 23:00:32,940:INFO:              jinja2: 3.1.2
2024-04-26 23:00:32,940:INFO:               scipy: 1.10.0
2024-04-26 23:00:32,940:INFO:              joblib: 1.3.2
2024-04-26 23:00:32,940:INFO:             sklearn: 1.4.2
2024-04-26 23:00:32,940:INFO:                pyod: 1.1.3
2024-04-26 23:00:32,940:INFO:            imblearn: 0.10.1
2024-04-26 23:00:32,940:INFO:   category_encoders: 2.6.3
2024-04-26 23:00:32,940:INFO:            lightgbm: 4.3.0
2024-04-26 23:00:32,940:INFO:               numba: 0.56.4
2024-04-26 23:00:32,940:INFO:            requests: 2.28.1
2024-04-26 23:00:32,940:INFO:          matplotlib: 3.7.0
2024-04-26 23:00:32,940:INFO:          scikitplot: 0.3.7
2024-04-26 23:00:32,940:INFO:         yellowbrick: 1.5
2024-04-26 23:00:32,940:INFO:              plotly: 5.21.0
2024-04-26 23:00:32,940:INFO:    plotly-resampler: Not installed
2024-04-26 23:00:32,940:INFO:             kaleido: 0.2.1
2024-04-26 23:00:32,940:INFO:           schemdraw: 0.15
2024-04-26 23:00:32,940:INFO:         statsmodels: 0.13.5
2024-04-26 23:00:32,940:INFO:              sktime: 0.26.0
2024-04-26 23:00:32,940:INFO:               tbats: 1.1.3
2024-04-26 23:00:32,940:INFO:            pmdarima: 2.0.4
2024-04-26 23:00:32,940:INFO:              psutil: 5.9.0
2024-04-26 23:00:32,940:INFO:          markupsafe: 2.1.1
2024-04-26 23:00:32,940:INFO:             pickle5: Not installed
2024-04-26 23:00:32,940:INFO:         cloudpickle: 2.0.0
2024-04-26 23:00:32,940:INFO:         deprecation: 2.1.0
2024-04-26 23:00:32,940:INFO:              xxhash: 3.4.1
2024-04-26 23:00:32,941:INFO:           wurlitzer: Not installed
2024-04-26 23:00:32,941:INFO:PyCaret optional dependencies:
2024-04-26 23:00:32,941:INFO:                shap: Not installed
2024-04-26 23:00:32,941:INFO:           interpret: Not installed
2024-04-26 23:00:32,941:INFO:                umap: Not installed
2024-04-26 23:00:32,941:INFO:     ydata_profiling: 4.7.0
2024-04-26 23:00:32,941:INFO:  explainerdashboard: Not installed
2024-04-26 23:00:32,941:INFO:             autoviz: Not installed
2024-04-26 23:00:32,941:INFO:           fairlearn: Not installed
2024-04-26 23:00:32,941:INFO:          deepchecks: Not installed
2024-04-26 23:00:32,941:INFO:             xgboost: Not installed
2024-04-26 23:00:32,941:INFO:            catboost: Not installed
2024-04-26 23:00:32,941:INFO:              kmodes: Not installed
2024-04-26 23:00:32,941:INFO:             mlxtend: Not installed
2024-04-26 23:00:32,941:INFO:       statsforecast: Not installed
2024-04-26 23:00:32,941:INFO:        tune_sklearn: Not installed
2024-04-26 23:00:32,941:INFO:                 ray: Not installed
2024-04-26 23:00:32,941:INFO:            hyperopt: Not installed
2024-04-26 23:00:32,941:INFO:              optuna: Not installed
2024-04-26 23:00:32,941:INFO:               skopt: Not installed
2024-04-26 23:00:32,941:INFO:              mlflow: Not installed
2024-04-26 23:00:32,941:INFO:              gradio: Not installed
2024-04-26 23:00:32,941:INFO:             fastapi: Not installed
2024-04-26 23:00:32,941:INFO:             uvicorn: Not installed
2024-04-26 23:00:32,941:INFO:              m2cgen: Not installed
2024-04-26 23:00:32,941:INFO:           evidently: Not installed
2024-04-26 23:00:32,942:INFO:               fugue: Not installed
2024-04-26 23:00:32,942:INFO:           streamlit: 1.33.0
2024-04-26 23:00:32,942:INFO:             prophet: Not installed
2024-04-26 23:00:32,942:INFO:None
2024-04-26 23:00:32,942:INFO:Set up data.
2024-04-26 23:00:32,945:INFO:Set up folding strategy.
2024-04-26 23:00:32,945:INFO:Set up train/test split.
2024-04-26 23:00:32,952:INFO:Set up index.
2024-04-26 23:00:32,952:INFO:Assigning column types.
2024-04-26 23:00:32,955:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-26 23:00:32,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 23:00:32,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:00:33,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,069:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 23:00:33,070:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:00:33,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,093:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-26 23:00:33,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:00:33,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:00:33,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,219:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-26 23:00:33,281:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,348:INFO:Preparing preprocessing pipeline...
2024-04-26 23:00:33,349:INFO:Set up simple imputation.
2024-04-26 23:00:33,380:INFO:Finished creating preprocessing pipeline.
2024-04-26 23:00:33,385:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-04-26 23:00:33,385:INFO:Creating final display dataframe.
2024-04-26 23:00:33,446:INFO:Setup _display_container:                     Description             Value
0                    Session id              8518
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape          (768, 9)
4        Transformed data shape          (768, 9)
5   Transformed train set shape          (537, 9)
6    Transformed test set shape          (231, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              1555
2024-04-26 23:00:33,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:00:33,588:INFO:setup() successfully completed in 0.65s...............
2024-04-26 23:00:33,594:INFO:Initializing compare_models()
2024-04-26 23:00:33,594:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-26 23:00:33,595:INFO:Checking exceptions
2024-04-26 23:00:33,597:INFO:Preparing display monitor
2024-04-26 23:00:33,600:INFO:Initializing Logistic Regression
2024-04-26 23:00:33,600:INFO:Total runtime is 0.0 minutes
2024-04-26 23:00:33,600:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:33,600:INFO:Initializing create_model()
2024-04-26 23:00:33,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:33,600:INFO:Checking exceptions
2024-04-26 23:00:33,600:INFO:Importing libraries
2024-04-26 23:00:33,600:INFO:Copying training dataset
2024-04-26 23:00:33,605:INFO:Defining folds
2024-04-26 23:00:33,605:INFO:Declaring metric variables
2024-04-26 23:00:33,605:INFO:Importing untrained model
2024-04-26 23:00:33,606:INFO:Logistic Regression Imported successfully
2024-04-26 23:00:33,606:INFO:Starting cross validation
2024-04-26 23:00:33,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:40,046:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,046:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,047:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,050:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,050:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,053:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,054:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,056:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,062:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,062:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:40,565:INFO:Calculating mean and std
2024-04-26 23:00:40,567:INFO:Creating metrics dataframe
2024-04-26 23:00:40,571:INFO:Uploading results into container
2024-04-26 23:00:40,572:INFO:Uploading model into container now
2024-04-26 23:00:40,573:INFO:_master_model_container: 1
2024-04-26 23:00:40,573:INFO:_display_container: 2
2024-04-26 23:00:40,573:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8518, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-26 23:00:40,573:INFO:create_model() successfully completed......................................
2024-04-26 23:00:40,796:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:40,796:INFO:Creating metrics dataframe
2024-04-26 23:00:40,800:INFO:Initializing K Neighbors Classifier
2024-04-26 23:00:40,800:INFO:Total runtime is 0.1200004498163859 minutes
2024-04-26 23:00:40,800:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:40,801:INFO:Initializing create_model()
2024-04-26 23:00:40,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:40,801:INFO:Checking exceptions
2024-04-26 23:00:40,801:INFO:Importing libraries
2024-04-26 23:00:40,801:INFO:Copying training dataset
2024-04-26 23:00:40,804:INFO:Defining folds
2024-04-26 23:00:40,804:INFO:Declaring metric variables
2024-04-26 23:00:40,804:INFO:Importing untrained model
2024-04-26 23:00:40,805:INFO:K Neighbors Classifier Imported successfully
2024-04-26 23:00:40,805:INFO:Starting cross validation
2024-04-26 23:00:40,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:44,671:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:44,671:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:00:45,108:INFO:Calculating mean and std
2024-04-26 23:00:45,110:INFO:Creating metrics dataframe
2024-04-26 23:00:45,111:INFO:Uploading results into container
2024-04-26 23:00:45,112:INFO:Uploading model into container now
2024-04-26 23:00:45,112:INFO:_master_model_container: 2
2024-04-26 23:00:45,112:INFO:_display_container: 2
2024-04-26 23:00:45,112:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-26 23:00:45,112:INFO:create_model() successfully completed......................................
2024-04-26 23:00:45,255:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:45,255:INFO:Creating metrics dataframe
2024-04-26 23:00:45,258:INFO:Initializing Naive Bayes
2024-04-26 23:00:45,258:INFO:Total runtime is 0.19430886904398598 minutes
2024-04-26 23:00:45,258:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:45,258:INFO:Initializing create_model()
2024-04-26 23:00:45,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:45,258:INFO:Checking exceptions
2024-04-26 23:00:45,259:INFO:Importing libraries
2024-04-26 23:00:45,259:INFO:Copying training dataset
2024-04-26 23:00:45,262:INFO:Defining folds
2024-04-26 23:00:45,262:INFO:Declaring metric variables
2024-04-26 23:00:45,262:INFO:Importing untrained model
2024-04-26 23:00:45,262:INFO:Naive Bayes Imported successfully
2024-04-26 23:00:45,262:INFO:Starting cross validation
2024-04-26 23:00:45,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:45,341:INFO:Calculating mean and std
2024-04-26 23:00:45,342:INFO:Creating metrics dataframe
2024-04-26 23:00:45,343:INFO:Uploading results into container
2024-04-26 23:00:45,343:INFO:Uploading model into container now
2024-04-26 23:00:45,343:INFO:_master_model_container: 3
2024-04-26 23:00:45,343:INFO:_display_container: 2
2024-04-26 23:00:45,344:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-26 23:00:45,344:INFO:create_model() successfully completed......................................
2024-04-26 23:00:45,469:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:45,469:INFO:Creating metrics dataframe
2024-04-26 23:00:45,472:INFO:Initializing Decision Tree Classifier
2024-04-26 23:00:45,472:INFO:Total runtime is 0.19786544640858966 minutes
2024-04-26 23:00:45,472:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:45,473:INFO:Initializing create_model()
2024-04-26 23:00:45,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:45,473:INFO:Checking exceptions
2024-04-26 23:00:45,473:INFO:Importing libraries
2024-04-26 23:00:45,473:INFO:Copying training dataset
2024-04-26 23:00:45,476:INFO:Defining folds
2024-04-26 23:00:45,476:INFO:Declaring metric variables
2024-04-26 23:00:45,476:INFO:Importing untrained model
2024-04-26 23:00:45,477:INFO:Decision Tree Classifier Imported successfully
2024-04-26 23:00:45,477:INFO:Starting cross validation
2024-04-26 23:00:45,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:45,560:INFO:Calculating mean and std
2024-04-26 23:00:45,561:INFO:Creating metrics dataframe
2024-04-26 23:00:45,562:INFO:Uploading results into container
2024-04-26 23:00:45,563:INFO:Uploading model into container now
2024-04-26 23:00:45,563:INFO:_master_model_container: 4
2024-04-26 23:00:45,563:INFO:_display_container: 2
2024-04-26 23:00:45,563:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8518, splitter='best')
2024-04-26 23:00:45,563:INFO:create_model() successfully completed......................................
2024-04-26 23:00:45,702:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:45,702:INFO:Creating metrics dataframe
2024-04-26 23:00:45,705:INFO:Initializing SVM - Linear Kernel
2024-04-26 23:00:45,705:INFO:Total runtime is 0.20175303618113197 minutes
2024-04-26 23:00:45,705:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:45,705:INFO:Initializing create_model()
2024-04-26 23:00:45,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:45,705:INFO:Checking exceptions
2024-04-26 23:00:45,705:INFO:Importing libraries
2024-04-26 23:00:45,705:INFO:Copying training dataset
2024-04-26 23:00:45,708:INFO:Defining folds
2024-04-26 23:00:45,708:INFO:Declaring metric variables
2024-04-26 23:00:45,708:INFO:Importing untrained model
2024-04-26 23:00:45,709:INFO:SVM - Linear Kernel Imported successfully
2024-04-26 23:00:45,709:INFO:Starting cross validation
2024-04-26 23:00:45,710:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:45,758:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:45,758:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:45,763:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:45,766:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:45,780:INFO:Calculating mean and std
2024-04-26 23:00:45,780:INFO:Creating metrics dataframe
2024-04-26 23:00:45,782:INFO:Uploading results into container
2024-04-26 23:00:45,782:INFO:Uploading model into container now
2024-04-26 23:00:45,783:INFO:_master_model_container: 5
2024-04-26 23:00:45,783:INFO:_display_container: 2
2024-04-26 23:00:45,783:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8518, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-26 23:00:45,783:INFO:create_model() successfully completed......................................
2024-04-26 23:00:45,911:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:45,911:INFO:Creating metrics dataframe
2024-04-26 23:00:45,914:INFO:Initializing Ridge Classifier
2024-04-26 23:00:45,914:INFO:Total runtime is 0.20523384809494016 minutes
2024-04-26 23:00:45,914:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:45,914:INFO:Initializing create_model()
2024-04-26 23:00:45,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:45,914:INFO:Checking exceptions
2024-04-26 23:00:45,914:INFO:Importing libraries
2024-04-26 23:00:45,914:INFO:Copying training dataset
2024-04-26 23:00:45,918:INFO:Defining folds
2024-04-26 23:00:45,918:INFO:Declaring metric variables
2024-04-26 23:00:45,918:INFO:Importing untrained model
2024-04-26 23:00:45,918:INFO:Ridge Classifier Imported successfully
2024-04-26 23:00:45,919:INFO:Starting cross validation
2024-04-26 23:00:45,919:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:46,000:INFO:Calculating mean and std
2024-04-26 23:00:46,000:INFO:Creating metrics dataframe
2024-04-26 23:00:46,003:INFO:Uploading results into container
2024-04-26 23:00:46,003:INFO:Uploading model into container now
2024-04-26 23:00:46,003:INFO:_master_model_container: 6
2024-04-26 23:00:46,003:INFO:_display_container: 2
2024-04-26 23:00:46,003:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8518, solver='auto',
                tol=0.0001)
2024-04-26 23:00:46,003:INFO:create_model() successfully completed......................................
2024-04-26 23:00:46,130:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:46,130:INFO:Creating metrics dataframe
2024-04-26 23:00:46,132:INFO:Initializing Random Forest Classifier
2024-04-26 23:00:46,133:INFO:Total runtime is 0.20888897577921547 minutes
2024-04-26 23:00:46,133:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:46,133:INFO:Initializing create_model()
2024-04-26 23:00:46,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:46,133:INFO:Checking exceptions
2024-04-26 23:00:46,133:INFO:Importing libraries
2024-04-26 23:00:46,133:INFO:Copying training dataset
2024-04-26 23:00:46,137:INFO:Defining folds
2024-04-26 23:00:46,137:INFO:Declaring metric variables
2024-04-26 23:00:46,137:INFO:Importing untrained model
2024-04-26 23:00:46,137:INFO:Random Forest Classifier Imported successfully
2024-04-26 23:00:46,138:INFO:Starting cross validation
2024-04-26 23:00:46,138:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:46,486:INFO:Calculating mean and std
2024-04-26 23:00:46,487:INFO:Creating metrics dataframe
2024-04-26 23:00:46,488:INFO:Uploading results into container
2024-04-26 23:00:46,489:INFO:Uploading model into container now
2024-04-26 23:00:46,489:INFO:_master_model_container: 7
2024-04-26 23:00:46,489:INFO:_display_container: 2
2024-04-26 23:00:46,490:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8518, verbose=0,
                       warm_start=False)
2024-04-26 23:00:46,490:INFO:create_model() successfully completed......................................
2024-04-26 23:00:46,620:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:46,620:INFO:Creating metrics dataframe
2024-04-26 23:00:46,622:INFO:Initializing Quadratic Discriminant Analysis
2024-04-26 23:00:46,622:INFO:Total runtime is 0.21704153617223101 minutes
2024-04-26 23:00:46,622:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:46,623:INFO:Initializing create_model()
2024-04-26 23:00:46,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:46,623:INFO:Checking exceptions
2024-04-26 23:00:46,623:INFO:Importing libraries
2024-04-26 23:00:46,623:INFO:Copying training dataset
2024-04-26 23:00:46,627:INFO:Defining folds
2024-04-26 23:00:46,627:INFO:Declaring metric variables
2024-04-26 23:00:46,627:INFO:Importing untrained model
2024-04-26 23:00:46,627:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-26 23:00:46,628:INFO:Starting cross validation
2024-04-26 23:00:46,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:46,705:INFO:Calculating mean and std
2024-04-26 23:00:46,705:INFO:Creating metrics dataframe
2024-04-26 23:00:46,706:INFO:Uploading results into container
2024-04-26 23:00:46,706:INFO:Uploading model into container now
2024-04-26 23:00:46,706:INFO:_master_model_container: 8
2024-04-26 23:00:46,706:INFO:_display_container: 2
2024-04-26 23:00:46,707:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-26 23:00:46,707:INFO:create_model() successfully completed......................................
2024-04-26 23:00:46,833:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:46,833:INFO:Creating metrics dataframe
2024-04-26 23:00:46,836:INFO:Initializing Ada Boost Classifier
2024-04-26 23:00:46,836:INFO:Total runtime is 0.2206127325693766 minutes
2024-04-26 23:00:46,836:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:46,837:INFO:Initializing create_model()
2024-04-26 23:00:46,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:46,837:INFO:Checking exceptions
2024-04-26 23:00:46,837:INFO:Importing libraries
2024-04-26 23:00:46,837:INFO:Copying training dataset
2024-04-26 23:00:46,840:INFO:Defining folds
2024-04-26 23:00:46,840:INFO:Declaring metric variables
2024-04-26 23:00:46,840:INFO:Importing untrained model
2024-04-26 23:00:46,840:INFO:Ada Boost Classifier Imported successfully
2024-04-26 23:00:46,841:INFO:Starting cross validation
2024-04-26 23:00:46,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:46,861:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,864:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,866:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,868:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,872:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,873:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,877:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,879:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,881:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:46,885:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:00:47,061:INFO:Calculating mean and std
2024-04-26 23:00:47,062:INFO:Creating metrics dataframe
2024-04-26 23:00:47,063:INFO:Uploading results into container
2024-04-26 23:00:47,064:INFO:Uploading model into container now
2024-04-26 23:00:47,064:INFO:_master_model_container: 9
2024-04-26 23:00:47,064:INFO:_display_container: 2
2024-04-26 23:00:47,064:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8518)
2024-04-26 23:00:47,064:INFO:create_model() successfully completed......................................
2024-04-26 23:00:47,191:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:47,191:INFO:Creating metrics dataframe
2024-04-26 23:00:47,193:INFO:Initializing Gradient Boosting Classifier
2024-04-26 23:00:47,195:INFO:Total runtime is 0.2265843311945597 minutes
2024-04-26 23:00:47,195:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:47,195:INFO:Initializing create_model()
2024-04-26 23:00:47,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:47,195:INFO:Checking exceptions
2024-04-26 23:00:47,195:INFO:Importing libraries
2024-04-26 23:00:47,195:INFO:Copying training dataset
2024-04-26 23:00:47,199:INFO:Defining folds
2024-04-26 23:00:47,199:INFO:Declaring metric variables
2024-04-26 23:00:47,199:INFO:Importing untrained model
2024-04-26 23:00:47,199:INFO:Gradient Boosting Classifier Imported successfully
2024-04-26 23:00:47,200:INFO:Starting cross validation
2024-04-26 23:00:47,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:47,481:INFO:Calculating mean and std
2024-04-26 23:00:47,482:INFO:Creating metrics dataframe
2024-04-26 23:00:47,483:INFO:Uploading results into container
2024-04-26 23:00:47,485:INFO:Uploading model into container now
2024-04-26 23:00:47,485:INFO:_master_model_container: 10
2024-04-26 23:00:47,485:INFO:_display_container: 2
2024-04-26 23:00:47,486:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8518, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-26 23:00:47,486:INFO:create_model() successfully completed......................................
2024-04-26 23:00:47,633:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:47,633:INFO:Creating metrics dataframe
2024-04-26 23:00:47,637:INFO:Initializing Linear Discriminant Analysis
2024-04-26 23:00:47,637:INFO:Total runtime is 0.23395941654841101 minutes
2024-04-26 23:00:47,637:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:47,638:INFO:Initializing create_model()
2024-04-26 23:00:47,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:47,638:INFO:Checking exceptions
2024-04-26 23:00:47,638:INFO:Importing libraries
2024-04-26 23:00:47,638:INFO:Copying training dataset
2024-04-26 23:00:47,641:INFO:Defining folds
2024-04-26 23:00:47,642:INFO:Declaring metric variables
2024-04-26 23:00:47,642:INFO:Importing untrained model
2024-04-26 23:00:47,642:INFO:Linear Discriminant Analysis Imported successfully
2024-04-26 23:00:47,642:INFO:Starting cross validation
2024-04-26 23:00:47,643:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:47,715:INFO:Calculating mean and std
2024-04-26 23:00:47,715:INFO:Creating metrics dataframe
2024-04-26 23:00:47,718:INFO:Uploading results into container
2024-04-26 23:00:47,719:INFO:Uploading model into container now
2024-04-26 23:00:47,719:INFO:_master_model_container: 11
2024-04-26 23:00:47,719:INFO:_display_container: 2
2024-04-26 23:00:47,719:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-26 23:00:47,719:INFO:create_model() successfully completed......................................
2024-04-26 23:00:47,848:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:47,848:INFO:Creating metrics dataframe
2024-04-26 23:00:47,851:INFO:Initializing Extra Trees Classifier
2024-04-26 23:00:47,851:INFO:Total runtime is 0.23752380609512325 minutes
2024-04-26 23:00:47,851:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:47,851:INFO:Initializing create_model()
2024-04-26 23:00:47,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:47,851:INFO:Checking exceptions
2024-04-26 23:00:47,851:INFO:Importing libraries
2024-04-26 23:00:47,851:INFO:Copying training dataset
2024-04-26 23:00:47,855:INFO:Defining folds
2024-04-26 23:00:47,855:INFO:Declaring metric variables
2024-04-26 23:00:47,855:INFO:Importing untrained model
2024-04-26 23:00:47,856:INFO:Extra Trees Classifier Imported successfully
2024-04-26 23:00:47,856:INFO:Starting cross validation
2024-04-26 23:00:47,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:48,248:INFO:Calculating mean and std
2024-04-26 23:00:48,249:INFO:Creating metrics dataframe
2024-04-26 23:00:48,251:INFO:Uploading results into container
2024-04-26 23:00:48,251:INFO:Uploading model into container now
2024-04-26 23:00:48,252:INFO:_master_model_container: 12
2024-04-26 23:00:48,252:INFO:_display_container: 2
2024-04-26 23:00:48,252:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8518, verbose=0,
                     warm_start=False)
2024-04-26 23:00:48,252:INFO:create_model() successfully completed......................................
2024-04-26 23:00:48,385:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:48,385:INFO:Creating metrics dataframe
2024-04-26 23:00:48,387:INFO:Initializing Light Gradient Boosting Machine
2024-04-26 23:00:48,387:INFO:Total runtime is 0.24645553032557166 minutes
2024-04-26 23:00:48,387:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:48,387:INFO:Initializing create_model()
2024-04-26 23:00:48,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:48,387:INFO:Checking exceptions
2024-04-26 23:00:48,387:INFO:Importing libraries
2024-04-26 23:00:48,387:INFO:Copying training dataset
2024-04-26 23:00:48,390:INFO:Defining folds
2024-04-26 23:00:48,390:INFO:Declaring metric variables
2024-04-26 23:00:48,391:INFO:Importing untrained model
2024-04-26 23:00:48,391:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-26 23:00:48,391:INFO:Starting cross validation
2024-04-26 23:00:48,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:49,111:INFO:Calculating mean and std
2024-04-26 23:00:49,112:INFO:Creating metrics dataframe
2024-04-26 23:00:49,114:INFO:Uploading results into container
2024-04-26 23:00:49,115:INFO:Uploading model into container now
2024-04-26 23:00:49,115:INFO:_master_model_container: 13
2024-04-26 23:00:49,115:INFO:_display_container: 2
2024-04-26 23:00:49,116:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8518, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-26 23:00:49,116:INFO:create_model() successfully completed......................................
2024-04-26 23:00:49,298:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:49,299:INFO:Creating metrics dataframe
2024-04-26 23:00:49,301:INFO:Initializing Dummy Classifier
2024-04-26 23:00:49,301:INFO:Total runtime is 0.26169323126475014 minutes
2024-04-26 23:00:49,302:INFO:SubProcess create_model() called ==================================
2024-04-26 23:00:49,302:INFO:Initializing create_model()
2024-04-26 23:00:49,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021479711CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:49,302:INFO:Checking exceptions
2024-04-26 23:00:49,302:INFO:Importing libraries
2024-04-26 23:00:49,302:INFO:Copying training dataset
2024-04-26 23:00:49,306:INFO:Defining folds
2024-04-26 23:00:49,306:INFO:Declaring metric variables
2024-04-26 23:00:49,306:INFO:Importing untrained model
2024-04-26 23:00:49,307:INFO:Dummy Classifier Imported successfully
2024-04-26 23:00:49,307:INFO:Starting cross validation
2024-04-26 23:00:49,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:00:49,342:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,347:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,351:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,355:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,355:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,363:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,363:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,363:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,370:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:00:49,390:INFO:Calculating mean and std
2024-04-26 23:00:49,390:INFO:Creating metrics dataframe
2024-04-26 23:00:49,392:INFO:Uploading results into container
2024-04-26 23:00:49,392:INFO:Uploading model into container now
2024-04-26 23:00:49,392:INFO:_master_model_container: 14
2024-04-26 23:00:49,392:INFO:_display_container: 2
2024-04-26 23:00:49,392:INFO:DummyClassifier(constant=None, random_state=8518, strategy='prior')
2024-04-26 23:00:49,392:INFO:create_model() successfully completed......................................
2024-04-26 23:00:49,523:INFO:SubProcess create_model() end ==================================
2024-04-26 23:00:49,523:INFO:Creating metrics dataframe
2024-04-26 23:00:49,530:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-26 23:00:49,531:INFO:Initializing create_model()
2024-04-26 23:00:49,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021473BF20E0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8518, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:00:49,531:INFO:Checking exceptions
2024-04-26 23:00:49,531:INFO:Importing libraries
2024-04-26 23:00:49,531:INFO:Copying training dataset
2024-04-26 23:00:49,535:INFO:Defining folds
2024-04-26 23:00:49,535:INFO:Declaring metric variables
2024-04-26 23:00:49,535:INFO:Importing untrained model
2024-04-26 23:00:49,535:INFO:Declaring custom model
2024-04-26 23:00:49,536:INFO:Logistic Regression Imported successfully
2024-04-26 23:00:49,537:INFO:Cross validation set to False
2024-04-26 23:00:49,537:INFO:Fitting Model
2024-04-26 23:00:49,562:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8518, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-26 23:00:49,562:INFO:create_model() successfully completed......................................
2024-04-26 23:00:49,707:INFO:_master_model_container: 14
2024-04-26 23:00:49,707:INFO:_display_container: 2
2024-04-26 23:00:49,707:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8518, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-26 23:00:49,707:INFO:compare_models() successfully completed......................................
2024-04-26 23:21:10,608:INFO:PyCaret ClassificationExperiment
2024-04-26 23:21:10,608:INFO:Logging name: clf-default-name
2024-04-26 23:21:10,608:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 23:21:10,608:INFO:version 3.3.1
2024-04-26 23:21:10,608:INFO:Initializing setup()
2024-04-26 23:21:10,608:INFO:self.USI: 9bd1
2024-04-26 23:21:10,608:INFO:self._variable_keys: {'data', 'fold_groups_param', 'X_test', 'y_test', 'log_plots_param', 'exp_id', 'y_train', 'X_train', 'target_param', 'logging_param', 'idx', 'html_param', 'gpu_param', 'y', 'is_multiclass', 'pipeline', 'X', 'exp_name_log', 'fix_imbalance', 'n_jobs_param', 'fold_shuffle_param', 'seed', 'memory', 'fold_generator', '_ml_usecase', 'USI', 'gpu_n_jobs_param', '_available_plots'}
2024-04-26 23:21:10,608:INFO:Checking environment
2024-04-26 23:21:10,608:INFO:python_version: 3.10.9
2024-04-26 23:21:10,608:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 23:21:10,608:INFO:machine: AMD64
2024-04-26 23:21:10,608:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 23:21:10,609:INFO:Memory: svmem(total=16541904896, available=5182951424, percent=68.7, used=11358953472, free=5182951424)
2024-04-26 23:21:10,609:INFO:Physical Core: 6
2024-04-26 23:21:10,609:INFO:Logical Core: 12
2024-04-26 23:21:10,609:INFO:Checking libraries
2024-04-26 23:21:10,609:INFO:System:
2024-04-26 23:21:10,609:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 23:21:10,609:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 23:21:10,609:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 23:21:10,609:INFO:PyCaret required dependencies:
2024-04-26 23:21:10,609:INFO:                 pip: 22.3.1
2024-04-26 23:21:10,609:INFO:          setuptools: 65.6.3
2024-04-26 23:21:10,609:INFO:             pycaret: 3.3.1
2024-04-26 23:21:10,609:INFO:             IPython: 8.10.0
2024-04-26 23:21:10,609:INFO:          ipywidgets: 7.6.5
2024-04-26 23:21:10,609:INFO:                tqdm: 4.64.1
2024-04-26 23:21:10,609:INFO:               numpy: 1.23.5
2024-04-26 23:21:10,609:INFO:              pandas: 2.2.2
2024-04-26 23:21:10,609:INFO:              jinja2: 3.1.2
2024-04-26 23:21:10,609:INFO:               scipy: 1.10.0
2024-04-26 23:21:10,609:INFO:              joblib: 1.3.2
2024-04-26 23:21:10,609:INFO:             sklearn: 1.4.2
2024-04-26 23:21:10,609:INFO:                pyod: 1.1.3
2024-04-26 23:21:10,609:INFO:            imblearn: 0.10.1
2024-04-26 23:21:10,609:INFO:   category_encoders: 2.6.3
2024-04-26 23:21:10,609:INFO:            lightgbm: 4.3.0
2024-04-26 23:21:10,609:INFO:               numba: 0.56.4
2024-04-26 23:21:10,610:INFO:            requests: 2.28.1
2024-04-26 23:21:10,610:INFO:          matplotlib: 3.7.0
2024-04-26 23:21:10,610:INFO:          scikitplot: 0.3.7
2024-04-26 23:21:10,610:INFO:         yellowbrick: 1.5
2024-04-26 23:21:10,610:INFO:              plotly: 5.21.0
2024-04-26 23:21:10,610:INFO:    plotly-resampler: Not installed
2024-04-26 23:21:10,610:INFO:             kaleido: 0.2.1
2024-04-26 23:21:10,610:INFO:           schemdraw: 0.15
2024-04-26 23:21:10,610:INFO:         statsmodels: 0.13.5
2024-04-26 23:21:10,610:INFO:              sktime: 0.26.0
2024-04-26 23:21:10,610:INFO:               tbats: 1.1.3
2024-04-26 23:21:10,610:INFO:            pmdarima: 2.0.4
2024-04-26 23:21:10,610:INFO:              psutil: 5.9.0
2024-04-26 23:21:10,610:INFO:          markupsafe: 2.1.1
2024-04-26 23:21:10,610:INFO:             pickle5: Not installed
2024-04-26 23:21:10,610:INFO:         cloudpickle: 2.0.0
2024-04-26 23:21:10,610:INFO:         deprecation: 2.1.0
2024-04-26 23:21:10,610:INFO:              xxhash: 3.4.1
2024-04-26 23:21:10,610:INFO:           wurlitzer: Not installed
2024-04-26 23:21:10,610:INFO:PyCaret optional dependencies:
2024-04-26 23:21:10,610:INFO:                shap: Not installed
2024-04-26 23:21:10,610:INFO:           interpret: Not installed
2024-04-26 23:21:10,610:INFO:                umap: Not installed
2024-04-26 23:21:10,610:INFO:     ydata_profiling: 4.7.0
2024-04-26 23:21:10,610:INFO:  explainerdashboard: Not installed
2024-04-26 23:21:10,610:INFO:             autoviz: Not installed
2024-04-26 23:21:10,610:INFO:           fairlearn: Not installed
2024-04-26 23:21:10,611:INFO:          deepchecks: Not installed
2024-04-26 23:21:10,611:INFO:             xgboost: Not installed
2024-04-26 23:21:10,611:INFO:            catboost: Not installed
2024-04-26 23:21:10,611:INFO:              kmodes: Not installed
2024-04-26 23:21:10,611:INFO:             mlxtend: Not installed
2024-04-26 23:21:10,611:INFO:       statsforecast: Not installed
2024-04-26 23:21:10,611:INFO:        tune_sklearn: Not installed
2024-04-26 23:21:10,611:INFO:                 ray: Not installed
2024-04-26 23:21:10,611:INFO:            hyperopt: Not installed
2024-04-26 23:21:10,611:INFO:              optuna: Not installed
2024-04-26 23:21:10,611:INFO:               skopt: Not installed
2024-04-26 23:21:10,611:INFO:              mlflow: Not installed
2024-04-26 23:21:10,611:INFO:              gradio: Not installed
2024-04-26 23:21:10,611:INFO:             fastapi: Not installed
2024-04-26 23:21:10,611:INFO:             uvicorn: Not installed
2024-04-26 23:21:10,611:INFO:              m2cgen: Not installed
2024-04-26 23:21:10,611:INFO:           evidently: Not installed
2024-04-26 23:21:10,611:INFO:               fugue: Not installed
2024-04-26 23:21:10,611:INFO:           streamlit: 1.33.0
2024-04-26 23:21:10,611:INFO:             prophet: Not installed
2024-04-26 23:21:10,611:INFO:None
2024-04-26 23:21:10,611:INFO:Set up data.
2024-04-26 23:21:10,615:INFO:Set up folding strategy.
2024-04-26 23:21:10,615:INFO:Set up train/test split.
2024-04-26 23:21:10,618:INFO:Set up index.
2024-04-26 23:21:10,618:INFO:Assigning column types.
2024-04-26 23:21:10,621:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-26 23:21:10,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 23:21:10,661:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:21:10,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,723:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 23:21:10,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:21:10,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,748:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-26 23:21:10,787:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:21:10,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:21:10,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,873:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-26 23:21:10,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:10,998:INFO:Preparing preprocessing pipeline...
2024-04-26 23:21:10,999:INFO:Set up simple imputation.
2024-04-26 23:21:11,016:INFO:Finished creating preprocessing pipeline.
2024-04-26 23:21:11,019:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-04-26 23:21:11,019:INFO:Creating final display dataframe.
2024-04-26 23:21:11,072:INFO:Setup _display_container:                     Description             Value
0                    Session id              8190
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape          (768, 9)
4        Transformed data shape          (768, 9)
5   Transformed train set shape          (537, 9)
6    Transformed test set shape          (231, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9bd1
2024-04-26 23:21:11,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:11,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:11,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:11,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:21:11,208:INFO:setup() successfully completed in 0.6s...............
2024-04-26 23:21:11,211:INFO:Initializing compare_models()
2024-04-26 23:21:11,211:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-26 23:21:11,211:INFO:Checking exceptions
2024-04-26 23:21:11,215:INFO:Preparing display monitor
2024-04-26 23:21:11,217:INFO:Initializing Logistic Regression
2024-04-26 23:21:11,217:INFO:Total runtime is 0.0 minutes
2024-04-26 23:21:11,217:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:11,217:INFO:Initializing create_model()
2024-04-26 23:21:11,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:11,217:INFO:Checking exceptions
2024-04-26 23:21:11,218:INFO:Importing libraries
2024-04-26 23:21:11,218:INFO:Copying training dataset
2024-04-26 23:21:11,222:INFO:Defining folds
2024-04-26 23:21:11,222:INFO:Declaring metric variables
2024-04-26 23:21:11,222:INFO:Importing untrained model
2024-04-26 23:21:11,223:INFO:Logistic Regression Imported successfully
2024-04-26 23:21:11,223:INFO:Starting cross validation
2024-04-26 23:21:11,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:18,080:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,080:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,081:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,081:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,081:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,081:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,081:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,082:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,082:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,087:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:18,724:INFO:Calculating mean and std
2024-04-26 23:21:18,729:INFO:Creating metrics dataframe
2024-04-26 23:21:18,732:INFO:Uploading results into container
2024-04-26 23:21:18,734:INFO:Uploading model into container now
2024-04-26 23:21:18,734:INFO:_master_model_container: 1
2024-04-26 23:21:18,735:INFO:_display_container: 2
2024-04-26 23:21:18,735:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8190, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-26 23:21:18,735:INFO:create_model() successfully completed......................................
2024-04-26 23:21:18,983:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:18,983:INFO:Creating metrics dataframe
2024-04-26 23:21:18,986:INFO:Initializing K Neighbors Classifier
2024-04-26 23:21:18,987:INFO:Total runtime is 0.12950310707092286 minutes
2024-04-26 23:21:18,987:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:18,987:INFO:Initializing create_model()
2024-04-26 23:21:18,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:18,987:INFO:Checking exceptions
2024-04-26 23:21:18,987:INFO:Importing libraries
2024-04-26 23:21:18,988:INFO:Copying training dataset
2024-04-26 23:21:18,994:INFO:Defining folds
2024-04-26 23:21:18,994:INFO:Declaring metric variables
2024-04-26 23:21:18,994:INFO:Importing untrained model
2024-04-26 23:21:18,995:INFO:K Neighbors Classifier Imported successfully
2024-04-26 23:21:18,995:INFO:Starting cross validation
2024-04-26 23:21:18,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:23,071:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:23,136:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:21:23,580:INFO:Calculating mean and std
2024-04-26 23:21:23,582:INFO:Creating metrics dataframe
2024-04-26 23:21:23,585:INFO:Uploading results into container
2024-04-26 23:21:23,586:INFO:Uploading model into container now
2024-04-26 23:21:23,586:INFO:_master_model_container: 2
2024-04-26 23:21:23,586:INFO:_display_container: 2
2024-04-26 23:21:23,587:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-26 23:21:23,587:INFO:create_model() successfully completed......................................
2024-04-26 23:21:23,749:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:23,749:INFO:Creating metrics dataframe
2024-04-26 23:21:23,752:INFO:Initializing Naive Bayes
2024-04-26 23:21:23,752:INFO:Total runtime is 0.20891213019688926 minutes
2024-04-26 23:21:23,752:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:23,752:INFO:Initializing create_model()
2024-04-26 23:21:23,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:23,752:INFO:Checking exceptions
2024-04-26 23:21:23,753:INFO:Importing libraries
2024-04-26 23:21:23,753:INFO:Copying training dataset
2024-04-26 23:21:23,757:INFO:Defining folds
2024-04-26 23:21:23,758:INFO:Declaring metric variables
2024-04-26 23:21:23,758:INFO:Importing untrained model
2024-04-26 23:21:23,758:INFO:Naive Bayes Imported successfully
2024-04-26 23:21:23,759:INFO:Starting cross validation
2024-04-26 23:21:23,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:23,844:INFO:Calculating mean and std
2024-04-26 23:21:23,844:INFO:Creating metrics dataframe
2024-04-26 23:21:23,846:INFO:Uploading results into container
2024-04-26 23:21:23,846:INFO:Uploading model into container now
2024-04-26 23:21:23,847:INFO:_master_model_container: 3
2024-04-26 23:21:23,847:INFO:_display_container: 2
2024-04-26 23:21:23,847:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-26 23:21:23,847:INFO:create_model() successfully completed......................................
2024-04-26 23:21:23,998:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:23,998:INFO:Creating metrics dataframe
2024-04-26 23:21:24,002:INFO:Initializing Decision Tree Classifier
2024-04-26 23:21:24,002:INFO:Total runtime is 0.21308260361353557 minutes
2024-04-26 23:21:24,003:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:24,003:INFO:Initializing create_model()
2024-04-26 23:21:24,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:24,003:INFO:Checking exceptions
2024-04-26 23:21:24,003:INFO:Importing libraries
2024-04-26 23:21:24,003:INFO:Copying training dataset
2024-04-26 23:21:24,009:INFO:Defining folds
2024-04-26 23:21:24,009:INFO:Declaring metric variables
2024-04-26 23:21:24,009:INFO:Importing untrained model
2024-04-26 23:21:24,010:INFO:Decision Tree Classifier Imported successfully
2024-04-26 23:21:24,010:INFO:Starting cross validation
2024-04-26 23:21:24,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:24,128:INFO:Calculating mean and std
2024-04-26 23:21:24,129:INFO:Creating metrics dataframe
2024-04-26 23:21:24,131:INFO:Uploading results into container
2024-04-26 23:21:24,132:INFO:Uploading model into container now
2024-04-26 23:21:24,132:INFO:_master_model_container: 4
2024-04-26 23:21:24,132:INFO:_display_container: 2
2024-04-26 23:21:24,133:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8190, splitter='best')
2024-04-26 23:21:24,133:INFO:create_model() successfully completed......................................
2024-04-26 23:21:24,304:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:24,304:INFO:Creating metrics dataframe
2024-04-26 23:21:24,307:INFO:Initializing SVM - Linear Kernel
2024-04-26 23:21:24,308:INFO:Total runtime is 0.21819026867548624 minutes
2024-04-26 23:21:24,308:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:24,308:INFO:Initializing create_model()
2024-04-26 23:21:24,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:24,308:INFO:Checking exceptions
2024-04-26 23:21:24,308:INFO:Importing libraries
2024-04-26 23:21:24,308:INFO:Copying training dataset
2024-04-26 23:21:24,312:INFO:Defining folds
2024-04-26 23:21:24,312:INFO:Declaring metric variables
2024-04-26 23:21:24,312:INFO:Importing untrained model
2024-04-26 23:21:24,312:INFO:SVM - Linear Kernel Imported successfully
2024-04-26 23:21:24,313:INFO:Starting cross validation
2024-04-26 23:21:24,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:24,394:INFO:Calculating mean and std
2024-04-26 23:21:24,395:INFO:Creating metrics dataframe
2024-04-26 23:21:24,396:INFO:Uploading results into container
2024-04-26 23:21:24,397:INFO:Uploading model into container now
2024-04-26 23:21:24,397:INFO:_master_model_container: 5
2024-04-26 23:21:24,397:INFO:_display_container: 2
2024-04-26 23:21:24,398:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8190, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-26 23:21:24,398:INFO:create_model() successfully completed......................................
2024-04-26 23:21:24,563:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:24,563:INFO:Creating metrics dataframe
2024-04-26 23:21:24,566:INFO:Initializing Ridge Classifier
2024-04-26 23:21:24,566:INFO:Total runtime is 0.2224852403004964 minutes
2024-04-26 23:21:24,566:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:24,566:INFO:Initializing create_model()
2024-04-26 23:21:24,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:24,567:INFO:Checking exceptions
2024-04-26 23:21:24,567:INFO:Importing libraries
2024-04-26 23:21:24,567:INFO:Copying training dataset
2024-04-26 23:21:24,570:INFO:Defining folds
2024-04-26 23:21:24,571:INFO:Declaring metric variables
2024-04-26 23:21:24,571:INFO:Importing untrained model
2024-04-26 23:21:24,572:INFO:Ridge Classifier Imported successfully
2024-04-26 23:21:24,572:INFO:Starting cross validation
2024-04-26 23:21:24,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:24,661:INFO:Calculating mean and std
2024-04-26 23:21:24,662:INFO:Creating metrics dataframe
2024-04-26 23:21:24,665:INFO:Uploading results into container
2024-04-26 23:21:24,666:INFO:Uploading model into container now
2024-04-26 23:21:24,666:INFO:_master_model_container: 6
2024-04-26 23:21:24,667:INFO:_display_container: 2
2024-04-26 23:21:24,667:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8190, solver='auto',
                tol=0.0001)
2024-04-26 23:21:24,667:INFO:create_model() successfully completed......................................
2024-04-26 23:21:24,812:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:24,812:INFO:Creating metrics dataframe
2024-04-26 23:21:24,814:INFO:Initializing Random Forest Classifier
2024-04-26 23:21:24,814:INFO:Total runtime is 0.22662496964136758 minutes
2024-04-26 23:21:24,815:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:24,815:INFO:Initializing create_model()
2024-04-26 23:21:24,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:24,815:INFO:Checking exceptions
2024-04-26 23:21:24,815:INFO:Importing libraries
2024-04-26 23:21:24,815:INFO:Copying training dataset
2024-04-26 23:21:24,818:INFO:Defining folds
2024-04-26 23:21:24,818:INFO:Declaring metric variables
2024-04-26 23:21:24,819:INFO:Importing untrained model
2024-04-26 23:21:24,819:INFO:Random Forest Classifier Imported successfully
2024-04-26 23:21:24,819:INFO:Starting cross validation
2024-04-26 23:21:24,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:25,258:INFO:Calculating mean and std
2024-04-26 23:21:25,258:INFO:Creating metrics dataframe
2024-04-26 23:21:25,261:INFO:Uploading results into container
2024-04-26 23:21:25,262:INFO:Uploading model into container now
2024-04-26 23:21:25,262:INFO:_master_model_container: 7
2024-04-26 23:21:25,262:INFO:_display_container: 2
2024-04-26 23:21:25,262:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8190, verbose=0,
                       warm_start=False)
2024-04-26 23:21:25,262:INFO:create_model() successfully completed......................................
2024-04-26 23:21:25,412:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:25,412:INFO:Creating metrics dataframe
2024-04-26 23:21:25,414:INFO:Initializing Quadratic Discriminant Analysis
2024-04-26 23:21:25,415:INFO:Total runtime is 0.23663790623346964 minutes
2024-04-26 23:21:25,415:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:25,415:INFO:Initializing create_model()
2024-04-26 23:21:25,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:25,415:INFO:Checking exceptions
2024-04-26 23:21:25,415:INFO:Importing libraries
2024-04-26 23:21:25,415:INFO:Copying training dataset
2024-04-26 23:21:25,419:INFO:Defining folds
2024-04-26 23:21:25,419:INFO:Declaring metric variables
2024-04-26 23:21:25,419:INFO:Importing untrained model
2024-04-26 23:21:25,419:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-26 23:21:25,421:INFO:Starting cross validation
2024-04-26 23:21:25,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:25,510:INFO:Calculating mean and std
2024-04-26 23:21:25,511:INFO:Creating metrics dataframe
2024-04-26 23:21:25,513:INFO:Uploading results into container
2024-04-26 23:21:25,514:INFO:Uploading model into container now
2024-04-26 23:21:25,514:INFO:_master_model_container: 8
2024-04-26 23:21:25,515:INFO:_display_container: 2
2024-04-26 23:21:25,515:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-26 23:21:25,515:INFO:create_model() successfully completed......................................
2024-04-26 23:21:25,667:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:25,667:INFO:Creating metrics dataframe
2024-04-26 23:21:25,670:INFO:Initializing Ada Boost Classifier
2024-04-26 23:21:25,670:INFO:Total runtime is 0.240890105565389 minutes
2024-04-26 23:21:25,670:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:25,670:INFO:Initializing create_model()
2024-04-26 23:21:25,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:25,670:INFO:Checking exceptions
2024-04-26 23:21:25,670:INFO:Importing libraries
2024-04-26 23:21:25,670:INFO:Copying training dataset
2024-04-26 23:21:25,673:INFO:Defining folds
2024-04-26 23:21:25,673:INFO:Declaring metric variables
2024-04-26 23:21:25,674:INFO:Importing untrained model
2024-04-26 23:21:25,674:INFO:Ada Boost Classifier Imported successfully
2024-04-26 23:21:25,674:INFO:Starting cross validation
2024-04-26 23:21:25,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:25,695:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,697:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,702:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,705:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,706:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,711:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,714:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,716:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,719:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,722:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:21:25,919:INFO:Calculating mean and std
2024-04-26 23:21:25,920:INFO:Creating metrics dataframe
2024-04-26 23:21:25,922:INFO:Uploading results into container
2024-04-26 23:21:25,923:INFO:Uploading model into container now
2024-04-26 23:21:25,924:INFO:_master_model_container: 9
2024-04-26 23:21:25,924:INFO:_display_container: 2
2024-04-26 23:21:25,924:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8190)
2024-04-26 23:21:25,924:INFO:create_model() successfully completed......................................
2024-04-26 23:21:26,078:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:26,078:INFO:Creating metrics dataframe
2024-04-26 23:21:26,082:INFO:Initializing Gradient Boosting Classifier
2024-04-26 23:21:26,082:INFO:Total runtime is 0.24775145848592123 minutes
2024-04-26 23:21:26,082:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:26,083:INFO:Initializing create_model()
2024-04-26 23:21:26,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:26,083:INFO:Checking exceptions
2024-04-26 23:21:26,083:INFO:Importing libraries
2024-04-26 23:21:26,083:INFO:Copying training dataset
2024-04-26 23:21:26,089:INFO:Defining folds
2024-04-26 23:21:26,089:INFO:Declaring metric variables
2024-04-26 23:21:26,089:INFO:Importing untrained model
2024-04-26 23:21:26,090:INFO:Gradient Boosting Classifier Imported successfully
2024-04-26 23:21:26,091:INFO:Starting cross validation
2024-04-26 23:21:26,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:26,402:INFO:Calculating mean and std
2024-04-26 23:21:26,403:INFO:Creating metrics dataframe
2024-04-26 23:21:26,405:INFO:Uploading results into container
2024-04-26 23:21:26,406:INFO:Uploading model into container now
2024-04-26 23:21:26,407:INFO:_master_model_container: 10
2024-04-26 23:21:26,407:INFO:_display_container: 2
2024-04-26 23:21:26,407:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8190, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-26 23:21:26,407:INFO:create_model() successfully completed......................................
2024-04-26 23:21:26,552:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:26,552:INFO:Creating metrics dataframe
2024-04-26 23:21:26,557:INFO:Initializing Linear Discriminant Analysis
2024-04-26 23:21:26,557:INFO:Total runtime is 0.2556668957074483 minutes
2024-04-26 23:21:26,557:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:26,558:INFO:Initializing create_model()
2024-04-26 23:21:26,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:26,558:INFO:Checking exceptions
2024-04-26 23:21:26,558:INFO:Importing libraries
2024-04-26 23:21:26,558:INFO:Copying training dataset
2024-04-26 23:21:26,563:INFO:Defining folds
2024-04-26 23:21:26,563:INFO:Declaring metric variables
2024-04-26 23:21:26,563:INFO:Importing untrained model
2024-04-26 23:21:26,563:INFO:Linear Discriminant Analysis Imported successfully
2024-04-26 23:21:26,564:INFO:Starting cross validation
2024-04-26 23:21:26,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:26,638:INFO:Calculating mean and std
2024-04-26 23:21:26,638:INFO:Creating metrics dataframe
2024-04-26 23:21:26,640:INFO:Uploading results into container
2024-04-26 23:21:26,641:INFO:Uploading model into container now
2024-04-26 23:21:26,641:INFO:_master_model_container: 11
2024-04-26 23:21:26,641:INFO:_display_container: 2
2024-04-26 23:21:26,641:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-26 23:21:26,641:INFO:create_model() successfully completed......................................
2024-04-26 23:21:26,807:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:26,807:INFO:Creating metrics dataframe
2024-04-26 23:21:26,811:INFO:Initializing Extra Trees Classifier
2024-04-26 23:21:26,811:INFO:Total runtime is 0.25989520947138467 minutes
2024-04-26 23:21:26,812:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:26,812:INFO:Initializing create_model()
2024-04-26 23:21:26,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:26,812:INFO:Checking exceptions
2024-04-26 23:21:26,812:INFO:Importing libraries
2024-04-26 23:21:26,812:INFO:Copying training dataset
2024-04-26 23:21:26,817:INFO:Defining folds
2024-04-26 23:21:26,817:INFO:Declaring metric variables
2024-04-26 23:21:26,817:INFO:Importing untrained model
2024-04-26 23:21:26,818:INFO:Extra Trees Classifier Imported successfully
2024-04-26 23:21:26,818:INFO:Starting cross validation
2024-04-26 23:21:26,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:27,156:INFO:Calculating mean and std
2024-04-26 23:21:27,157:INFO:Creating metrics dataframe
2024-04-26 23:21:27,159:INFO:Uploading results into container
2024-04-26 23:21:27,160:INFO:Uploading model into container now
2024-04-26 23:21:27,160:INFO:_master_model_container: 12
2024-04-26 23:21:27,160:INFO:_display_container: 2
2024-04-26 23:21:27,161:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8190, verbose=0,
                     warm_start=False)
2024-04-26 23:21:27,161:INFO:create_model() successfully completed......................................
2024-04-26 23:21:27,329:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:27,329:INFO:Creating metrics dataframe
2024-04-26 23:21:27,333:INFO:Initializing Light Gradient Boosting Machine
2024-04-26 23:21:27,333:INFO:Total runtime is 0.2685955882072449 minutes
2024-04-26 23:21:27,333:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:27,334:INFO:Initializing create_model()
2024-04-26 23:21:27,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:27,334:INFO:Checking exceptions
2024-04-26 23:21:27,334:INFO:Importing libraries
2024-04-26 23:21:27,334:INFO:Copying training dataset
2024-04-26 23:21:27,339:INFO:Defining folds
2024-04-26 23:21:27,339:INFO:Declaring metric variables
2024-04-26 23:21:27,340:INFO:Importing untrained model
2024-04-26 23:21:27,340:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-26 23:21:27,341:INFO:Starting cross validation
2024-04-26 23:21:27,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:27,900:INFO:Calculating mean and std
2024-04-26 23:21:27,901:INFO:Creating metrics dataframe
2024-04-26 23:21:27,904:INFO:Uploading results into container
2024-04-26 23:21:27,904:INFO:Uploading model into container now
2024-04-26 23:21:27,905:INFO:_master_model_container: 13
2024-04-26 23:21:27,905:INFO:_display_container: 2
2024-04-26 23:21:27,905:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8190, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-26 23:21:27,905:INFO:create_model() successfully completed......................................
2024-04-26 23:21:28,080:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:28,080:INFO:Creating metrics dataframe
2024-04-26 23:21:28,084:INFO:Initializing Dummy Classifier
2024-04-26 23:21:28,084:INFO:Total runtime is 0.2811133861541748 minutes
2024-04-26 23:21:28,085:INFO:SubProcess create_model() called ==================================
2024-04-26 23:21:28,085:INFO:Initializing create_model()
2024-04-26 23:21:28,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021477418040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:28,085:INFO:Checking exceptions
2024-04-26 23:21:28,085:INFO:Importing libraries
2024-04-26 23:21:28,085:INFO:Copying training dataset
2024-04-26 23:21:28,091:INFO:Defining folds
2024-04-26 23:21:28,091:INFO:Declaring metric variables
2024-04-26 23:21:28,091:INFO:Importing untrained model
2024-04-26 23:21:28,092:INFO:Dummy Classifier Imported successfully
2024-04-26 23:21:28,092:INFO:Starting cross validation
2024-04-26 23:21:28,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:21:28,138:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,144:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,145:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,146:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,151:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,152:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,154:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,158:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,160:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,164:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:21:28,183:INFO:Calculating mean and std
2024-04-26 23:21:28,183:INFO:Creating metrics dataframe
2024-04-26 23:21:28,185:INFO:Uploading results into container
2024-04-26 23:21:28,186:INFO:Uploading model into container now
2024-04-26 23:21:28,186:INFO:_master_model_container: 14
2024-04-26 23:21:28,186:INFO:_display_container: 2
2024-04-26 23:21:28,187:INFO:DummyClassifier(constant=None, random_state=8190, strategy='prior')
2024-04-26 23:21:28,187:INFO:create_model() successfully completed......................................
2024-04-26 23:21:28,350:INFO:SubProcess create_model() end ==================================
2024-04-26 23:21:28,350:INFO:Creating metrics dataframe
2024-04-26 23:21:28,354:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-26 23:21:28,356:INFO:Initializing create_model()
2024-04-26 23:21:28,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021476B72CE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8190, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:21:28,356:INFO:Checking exceptions
2024-04-26 23:21:28,356:INFO:Importing libraries
2024-04-26 23:21:28,356:INFO:Copying training dataset
2024-04-26 23:21:28,360:INFO:Defining folds
2024-04-26 23:21:28,360:INFO:Declaring metric variables
2024-04-26 23:21:28,360:INFO:Importing untrained model
2024-04-26 23:21:28,360:INFO:Declaring custom model
2024-04-26 23:21:28,361:INFO:Random Forest Classifier Imported successfully
2024-04-26 23:21:28,361:INFO:Cross validation set to False
2024-04-26 23:21:28,361:INFO:Fitting Model
2024-04-26 23:21:28,526:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8190, verbose=0,
                       warm_start=False)
2024-04-26 23:21:28,526:INFO:create_model() successfully completed......................................
2024-04-26 23:21:28,693:INFO:_master_model_container: 14
2024-04-26 23:21:28,693:INFO:_display_container: 2
2024-04-26 23:21:28,694:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8190, verbose=0,
                       warm_start=False)
2024-04-26 23:21:28,694:INFO:compare_models() successfully completed......................................
2024-04-26 23:21:28,702:INFO:Initializing save_model()
2024-04-26 23:21:28,703:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8190, verbose=0,
                       warm_start=False), model_name= THe Best Model the given dataset, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-26 23:21:28,703:INFO:Adding model into prep_pipe
2024-04-26 23:21:28,755:INFO: THe Best Model the given dataset.pkl saved in current working directory
2024-04-26 23:21:28,760:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                (...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=8190, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-04-26 23:21:28,760:INFO:save_model() successfully completed......................................
2024-04-26 23:22:27,855:INFO:PyCaret ClassificationExperiment
2024-04-26 23:22:27,855:INFO:Logging name: clf-default-name
2024-04-26 23:22:27,855:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 23:22:27,855:INFO:version 3.3.1
2024-04-26 23:22:27,856:INFO:Initializing setup()
2024-04-26 23:22:27,856:INFO:self.USI: 058d
2024-04-26 23:22:27,856:INFO:self._variable_keys: {'data', 'fold_groups_param', 'X_test', 'y_test', 'log_plots_param', 'exp_id', 'y_train', 'X_train', 'target_param', 'logging_param', 'idx', 'html_param', 'gpu_param', 'y', 'is_multiclass', 'pipeline', 'X', 'exp_name_log', 'fix_imbalance', 'n_jobs_param', 'fold_shuffle_param', 'seed', 'memory', 'fold_generator', '_ml_usecase', 'USI', 'gpu_n_jobs_param', '_available_plots'}
2024-04-26 23:22:27,856:INFO:Checking environment
2024-04-26 23:22:27,856:INFO:python_version: 3.10.9
2024-04-26 23:22:27,856:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 23:22:27,856:INFO:machine: AMD64
2024-04-26 23:22:27,856:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 23:22:27,856:INFO:Memory: svmem(total=16541904896, available=3349839872, percent=79.7, used=13192065024, free=3349839872)
2024-04-26 23:22:27,856:INFO:Physical Core: 6
2024-04-26 23:22:27,856:INFO:Logical Core: 12
2024-04-26 23:22:27,856:INFO:Checking libraries
2024-04-26 23:22:27,856:INFO:System:
2024-04-26 23:22:27,856:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 23:22:27,856:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 23:22:27,856:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 23:22:27,856:INFO:PyCaret required dependencies:
2024-04-26 23:22:27,856:INFO:                 pip: 22.3.1
2024-04-26 23:22:27,856:INFO:          setuptools: 65.6.3
2024-04-26 23:22:27,856:INFO:             pycaret: 3.3.1
2024-04-26 23:22:27,856:INFO:             IPython: 8.10.0
2024-04-26 23:22:27,857:INFO:          ipywidgets: 7.6.5
2024-04-26 23:22:27,857:INFO:                tqdm: 4.64.1
2024-04-26 23:22:27,857:INFO:               numpy: 1.23.5
2024-04-26 23:22:27,857:INFO:              pandas: 2.2.2
2024-04-26 23:22:27,857:INFO:              jinja2: 3.1.2
2024-04-26 23:22:27,857:INFO:               scipy: 1.10.0
2024-04-26 23:22:27,857:INFO:              joblib: 1.3.2
2024-04-26 23:22:27,857:INFO:             sklearn: 1.4.2
2024-04-26 23:22:27,857:INFO:                pyod: 1.1.3
2024-04-26 23:22:27,857:INFO:            imblearn: 0.10.1
2024-04-26 23:22:27,857:INFO:   category_encoders: 2.6.3
2024-04-26 23:22:27,857:INFO:            lightgbm: 4.3.0
2024-04-26 23:22:27,857:INFO:               numba: 0.56.4
2024-04-26 23:22:27,857:INFO:            requests: 2.28.1
2024-04-26 23:22:27,857:INFO:          matplotlib: 3.7.0
2024-04-26 23:22:27,857:INFO:          scikitplot: 0.3.7
2024-04-26 23:22:27,857:INFO:         yellowbrick: 1.5
2024-04-26 23:22:27,857:INFO:              plotly: 5.21.0
2024-04-26 23:22:27,857:INFO:    plotly-resampler: Not installed
2024-04-26 23:22:27,857:INFO:             kaleido: 0.2.1
2024-04-26 23:22:27,857:INFO:           schemdraw: 0.15
2024-04-26 23:22:27,857:INFO:         statsmodels: 0.13.5
2024-04-26 23:22:27,857:INFO:              sktime: 0.26.0
2024-04-26 23:22:27,857:INFO:               tbats: 1.1.3
2024-04-26 23:22:27,857:INFO:            pmdarima: 2.0.4
2024-04-26 23:22:27,857:INFO:              psutil: 5.9.0
2024-04-26 23:22:27,857:INFO:          markupsafe: 2.1.1
2024-04-26 23:22:27,857:INFO:             pickle5: Not installed
2024-04-26 23:22:27,857:INFO:         cloudpickle: 2.0.0
2024-04-26 23:22:27,858:INFO:         deprecation: 2.1.0
2024-04-26 23:22:27,858:INFO:              xxhash: 3.4.1
2024-04-26 23:22:27,858:INFO:           wurlitzer: Not installed
2024-04-26 23:22:27,858:INFO:PyCaret optional dependencies:
2024-04-26 23:22:27,858:INFO:                shap: Not installed
2024-04-26 23:22:27,858:INFO:           interpret: Not installed
2024-04-26 23:22:27,858:INFO:                umap: Not installed
2024-04-26 23:22:27,858:INFO:     ydata_profiling: 4.7.0
2024-04-26 23:22:27,858:INFO:  explainerdashboard: Not installed
2024-04-26 23:22:27,858:INFO:             autoviz: Not installed
2024-04-26 23:22:27,858:INFO:           fairlearn: Not installed
2024-04-26 23:22:27,858:INFO:          deepchecks: Not installed
2024-04-26 23:22:27,858:INFO:             xgboost: Not installed
2024-04-26 23:22:27,858:INFO:            catboost: Not installed
2024-04-26 23:22:27,858:INFO:              kmodes: Not installed
2024-04-26 23:22:27,858:INFO:             mlxtend: Not installed
2024-04-26 23:22:27,858:INFO:       statsforecast: Not installed
2024-04-26 23:22:27,858:INFO:        tune_sklearn: Not installed
2024-04-26 23:22:27,858:INFO:                 ray: Not installed
2024-04-26 23:22:27,858:INFO:            hyperopt: Not installed
2024-04-26 23:22:27,858:INFO:              optuna: Not installed
2024-04-26 23:22:27,858:INFO:               skopt: Not installed
2024-04-26 23:22:27,858:INFO:              mlflow: Not installed
2024-04-26 23:22:27,858:INFO:              gradio: Not installed
2024-04-26 23:22:27,858:INFO:             fastapi: Not installed
2024-04-26 23:22:27,858:INFO:             uvicorn: Not installed
2024-04-26 23:22:27,858:INFO:              m2cgen: Not installed
2024-04-26 23:22:27,858:INFO:           evidently: Not installed
2024-04-26 23:22:27,858:INFO:               fugue: Not installed
2024-04-26 23:22:27,858:INFO:           streamlit: 1.33.0
2024-04-26 23:22:27,859:INFO:             prophet: Not installed
2024-04-26 23:22:27,859:INFO:None
2024-04-26 23:22:27,859:INFO:Set up data.
2024-04-26 23:22:27,862:INFO:Set up folding strategy.
2024-04-26 23:22:27,862:INFO:Set up train/test split.
2024-04-26 23:22:27,865:INFO:Set up index.
2024-04-26 23:22:27,865:INFO:Assigning column types.
2024-04-26 23:22:27,868:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-26 23:22:27,907:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 23:22:27,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:22:27,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:27,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:27,972:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 23:22:27,973:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:22:27,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:27,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:27,997:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-26 23:22:28,036:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:22:28,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,097:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:22:28,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,122:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-26 23:22:28,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,248:INFO:Preparing preprocessing pipeline...
2024-04-26 23:22:28,249:INFO:Set up simple imputation.
2024-04-26 23:22:28,264:INFO:Finished creating preprocessing pipeline.
2024-04-26 23:22:28,267:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-04-26 23:22:28,267:INFO:Creating final display dataframe.
2024-04-26 23:22:28,319:INFO:Setup _display_container:                     Description             Value
0                    Session id              5246
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape          (768, 9)
4        Transformed data shape          (768, 9)
5   Transformed train set shape          (537, 9)
6    Transformed test set shape          (231, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              058d
2024-04-26 23:22:28,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:22:28,447:INFO:setup() successfully completed in 0.59s...............
2024-04-26 23:22:28,451:INFO:Initializing compare_models()
2024-04-26 23:22:28,451:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-26 23:22:28,451:INFO:Checking exceptions
2024-04-26 23:22:28,454:INFO:Preparing display monitor
2024-04-26 23:22:28,457:INFO:Initializing Logistic Regression
2024-04-26 23:22:28,457:INFO:Total runtime is 0.0 minutes
2024-04-26 23:22:28,457:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:28,457:INFO:Initializing create_model()
2024-04-26 23:22:28,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:28,457:INFO:Checking exceptions
2024-04-26 23:22:28,457:INFO:Importing libraries
2024-04-26 23:22:28,457:INFO:Copying training dataset
2024-04-26 23:22:28,461:INFO:Defining folds
2024-04-26 23:22:28,461:INFO:Declaring metric variables
2024-04-26 23:22:28,461:INFO:Importing untrained model
2024-04-26 23:22:28,461:INFO:Logistic Regression Imported successfully
2024-04-26 23:22:28,462:INFO:Starting cross validation
2024-04-26 23:22:28,462:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:28,560:INFO:Calculating mean and std
2024-04-26 23:22:28,561:INFO:Creating metrics dataframe
2024-04-26 23:22:28,563:INFO:Uploading results into container
2024-04-26 23:22:28,563:INFO:Uploading model into container now
2024-04-26 23:22:28,564:INFO:_master_model_container: 1
2024-04-26 23:22:28,564:INFO:_display_container: 2
2024-04-26 23:22:28,564:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5246, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-26 23:22:28,564:INFO:create_model() successfully completed......................................
2024-04-26 23:22:28,697:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:28,697:INFO:Creating metrics dataframe
2024-04-26 23:22:28,699:INFO:Initializing K Neighbors Classifier
2024-04-26 23:22:28,699:INFO:Total runtime is 0.00404427448908488 minutes
2024-04-26 23:22:28,699:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:28,700:INFO:Initializing create_model()
2024-04-26 23:22:28,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:28,700:INFO:Checking exceptions
2024-04-26 23:22:28,700:INFO:Importing libraries
2024-04-26 23:22:28,700:INFO:Copying training dataset
2024-04-26 23:22:28,703:INFO:Defining folds
2024-04-26 23:22:28,703:INFO:Declaring metric variables
2024-04-26 23:22:28,703:INFO:Importing untrained model
2024-04-26 23:22:28,703:INFO:K Neighbors Classifier Imported successfully
2024-04-26 23:22:28,704:INFO:Starting cross validation
2024-04-26 23:22:28,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:28,825:INFO:Calculating mean and std
2024-04-26 23:22:28,825:INFO:Creating metrics dataframe
2024-04-26 23:22:28,827:INFO:Uploading results into container
2024-04-26 23:22:28,827:INFO:Uploading model into container now
2024-04-26 23:22:28,828:INFO:_master_model_container: 2
2024-04-26 23:22:28,828:INFO:_display_container: 2
2024-04-26 23:22:28,828:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-26 23:22:28,828:INFO:create_model() successfully completed......................................
2024-04-26 23:22:28,959:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:28,959:INFO:Creating metrics dataframe
2024-04-26 23:22:28,961:INFO:Initializing Naive Bayes
2024-04-26 23:22:28,961:INFO:Total runtime is 0.008409539858500164 minutes
2024-04-26 23:22:28,961:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:28,962:INFO:Initializing create_model()
2024-04-26 23:22:28,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:28,962:INFO:Checking exceptions
2024-04-26 23:22:28,962:INFO:Importing libraries
2024-04-26 23:22:28,962:INFO:Copying training dataset
2024-04-26 23:22:28,964:INFO:Defining folds
2024-04-26 23:22:28,964:INFO:Declaring metric variables
2024-04-26 23:22:28,965:INFO:Importing untrained model
2024-04-26 23:22:28,965:INFO:Naive Bayes Imported successfully
2024-04-26 23:22:28,965:INFO:Starting cross validation
2024-04-26 23:22:28,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:29,032:INFO:Calculating mean and std
2024-04-26 23:22:29,032:INFO:Creating metrics dataframe
2024-04-26 23:22:29,034:INFO:Uploading results into container
2024-04-26 23:22:29,035:INFO:Uploading model into container now
2024-04-26 23:22:29,035:INFO:_master_model_container: 3
2024-04-26 23:22:29,035:INFO:_display_container: 2
2024-04-26 23:22:29,035:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-26 23:22:29,035:INFO:create_model() successfully completed......................................
2024-04-26 23:22:29,164:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:29,165:INFO:Creating metrics dataframe
2024-04-26 23:22:29,167:INFO:Initializing Decision Tree Classifier
2024-04-26 23:22:29,167:INFO:Total runtime is 0.011835813522338869 minutes
2024-04-26 23:22:29,167:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:29,168:INFO:Initializing create_model()
2024-04-26 23:22:29,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:29,168:INFO:Checking exceptions
2024-04-26 23:22:29,168:INFO:Importing libraries
2024-04-26 23:22:29,168:INFO:Copying training dataset
2024-04-26 23:22:29,171:INFO:Defining folds
2024-04-26 23:22:29,171:INFO:Declaring metric variables
2024-04-26 23:22:29,171:INFO:Importing untrained model
2024-04-26 23:22:29,171:INFO:Decision Tree Classifier Imported successfully
2024-04-26 23:22:29,171:INFO:Starting cross validation
2024-04-26 23:22:29,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:29,251:INFO:Calculating mean and std
2024-04-26 23:22:29,252:INFO:Creating metrics dataframe
2024-04-26 23:22:29,253:INFO:Uploading results into container
2024-04-26 23:22:29,254:INFO:Uploading model into container now
2024-04-26 23:22:29,254:INFO:_master_model_container: 4
2024-04-26 23:22:29,254:INFO:_display_container: 2
2024-04-26 23:22:29,255:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5246, splitter='best')
2024-04-26 23:22:29,255:INFO:create_model() successfully completed......................................
2024-04-26 23:22:29,384:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:29,384:INFO:Creating metrics dataframe
2024-04-26 23:22:29,386:INFO:Initializing SVM - Linear Kernel
2024-04-26 23:22:29,386:INFO:Total runtime is 0.015491843223571779 minutes
2024-04-26 23:22:29,387:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:29,387:INFO:Initializing create_model()
2024-04-26 23:22:29,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:29,387:INFO:Checking exceptions
2024-04-26 23:22:29,387:INFO:Importing libraries
2024-04-26 23:22:29,387:INFO:Copying training dataset
2024-04-26 23:22:29,390:INFO:Defining folds
2024-04-26 23:22:29,390:INFO:Declaring metric variables
2024-04-26 23:22:29,390:INFO:Importing untrained model
2024-04-26 23:22:29,391:INFO:SVM - Linear Kernel Imported successfully
2024-04-26 23:22:29,391:INFO:Starting cross validation
2024-04-26 23:22:29,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:29,453:INFO:Calculating mean and std
2024-04-26 23:22:29,453:INFO:Creating metrics dataframe
2024-04-26 23:22:29,455:INFO:Uploading results into container
2024-04-26 23:22:29,455:INFO:Uploading model into container now
2024-04-26 23:22:29,456:INFO:_master_model_container: 5
2024-04-26 23:22:29,456:INFO:_display_container: 2
2024-04-26 23:22:29,456:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5246, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-26 23:22:29,456:INFO:create_model() successfully completed......................................
2024-04-26 23:22:29,583:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:29,583:INFO:Creating metrics dataframe
2024-04-26 23:22:29,586:INFO:Initializing Ridge Classifier
2024-04-26 23:22:29,586:INFO:Total runtime is 0.018827752272288008 minutes
2024-04-26 23:22:29,586:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:29,586:INFO:Initializing create_model()
2024-04-26 23:22:29,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:29,586:INFO:Checking exceptions
2024-04-26 23:22:29,586:INFO:Importing libraries
2024-04-26 23:22:29,587:INFO:Copying training dataset
2024-04-26 23:22:29,590:INFO:Defining folds
2024-04-26 23:22:29,590:INFO:Declaring metric variables
2024-04-26 23:22:29,590:INFO:Importing untrained model
2024-04-26 23:22:29,590:INFO:Ridge Classifier Imported successfully
2024-04-26 23:22:29,590:INFO:Starting cross validation
2024-04-26 23:22:29,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:29,655:INFO:Calculating mean and std
2024-04-26 23:22:29,655:INFO:Creating metrics dataframe
2024-04-26 23:22:29,657:INFO:Uploading results into container
2024-04-26 23:22:29,658:INFO:Uploading model into container now
2024-04-26 23:22:29,658:INFO:_master_model_container: 6
2024-04-26 23:22:29,658:INFO:_display_container: 2
2024-04-26 23:22:29,658:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5246, solver='auto',
                tol=0.0001)
2024-04-26 23:22:29,658:INFO:create_model() successfully completed......................................
2024-04-26 23:22:29,785:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:29,785:INFO:Creating metrics dataframe
2024-04-26 23:22:29,787:INFO:Initializing Random Forest Classifier
2024-04-26 23:22:29,787:INFO:Total runtime is 0.02217983404795329 minutes
2024-04-26 23:22:29,787:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:29,788:INFO:Initializing create_model()
2024-04-26 23:22:29,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:29,788:INFO:Checking exceptions
2024-04-26 23:22:29,788:INFO:Importing libraries
2024-04-26 23:22:29,788:INFO:Copying training dataset
2024-04-26 23:22:29,791:INFO:Defining folds
2024-04-26 23:22:29,791:INFO:Declaring metric variables
2024-04-26 23:22:29,791:INFO:Importing untrained model
2024-04-26 23:22:29,792:INFO:Random Forest Classifier Imported successfully
2024-04-26 23:22:29,792:INFO:Starting cross validation
2024-04-26 23:22:29,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:30,140:INFO:Calculating mean and std
2024-04-26 23:22:30,141:INFO:Creating metrics dataframe
2024-04-26 23:22:30,142:INFO:Uploading results into container
2024-04-26 23:22:30,142:INFO:Uploading model into container now
2024-04-26 23:22:30,143:INFO:_master_model_container: 7
2024-04-26 23:22:30,143:INFO:_display_container: 2
2024-04-26 23:22:30,143:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5246, verbose=0,
                       warm_start=False)
2024-04-26 23:22:30,143:INFO:create_model() successfully completed......................................
2024-04-26 23:22:30,270:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:30,270:INFO:Creating metrics dataframe
2024-04-26 23:22:30,273:INFO:Initializing Quadratic Discriminant Analysis
2024-04-26 23:22:30,273:INFO:Total runtime is 0.030269145965576172 minutes
2024-04-26 23:22:30,273:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:30,273:INFO:Initializing create_model()
2024-04-26 23:22:30,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:30,273:INFO:Checking exceptions
2024-04-26 23:22:30,273:INFO:Importing libraries
2024-04-26 23:22:30,274:INFO:Copying training dataset
2024-04-26 23:22:30,276:INFO:Defining folds
2024-04-26 23:22:30,276:INFO:Declaring metric variables
2024-04-26 23:22:30,276:INFO:Importing untrained model
2024-04-26 23:22:30,277:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-26 23:22:30,277:INFO:Starting cross validation
2024-04-26 23:22:30,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:30,344:INFO:Calculating mean and std
2024-04-26 23:22:30,344:INFO:Creating metrics dataframe
2024-04-26 23:22:30,346:INFO:Uploading results into container
2024-04-26 23:22:30,346:INFO:Uploading model into container now
2024-04-26 23:22:30,346:INFO:_master_model_container: 8
2024-04-26 23:22:30,346:INFO:_display_container: 2
2024-04-26 23:22:30,347:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-26 23:22:30,347:INFO:create_model() successfully completed......................................
2024-04-26 23:22:30,477:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:30,477:INFO:Creating metrics dataframe
2024-04-26 23:22:30,480:INFO:Initializing Ada Boost Classifier
2024-04-26 23:22:30,480:INFO:Total runtime is 0.03372826178868612 minutes
2024-04-26 23:22:30,480:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:30,480:INFO:Initializing create_model()
2024-04-26 23:22:30,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:30,480:INFO:Checking exceptions
2024-04-26 23:22:30,480:INFO:Importing libraries
2024-04-26 23:22:30,480:INFO:Copying training dataset
2024-04-26 23:22:30,483:INFO:Defining folds
2024-04-26 23:22:30,483:INFO:Declaring metric variables
2024-04-26 23:22:30,483:INFO:Importing untrained model
2024-04-26 23:22:30,484:INFO:Ada Boost Classifier Imported successfully
2024-04-26 23:22:30,484:INFO:Starting cross validation
2024-04-26 23:22:30,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:30,505:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,507:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,509:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,512:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,515:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,516:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,518:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,521:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,521:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,526:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:22:30,701:INFO:Calculating mean and std
2024-04-26 23:22:30,702:INFO:Creating metrics dataframe
2024-04-26 23:22:30,704:INFO:Uploading results into container
2024-04-26 23:22:30,704:INFO:Uploading model into container now
2024-04-26 23:22:30,704:INFO:_master_model_container: 9
2024-04-26 23:22:30,704:INFO:_display_container: 2
2024-04-26 23:22:30,705:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5246)
2024-04-26 23:22:30,705:INFO:create_model() successfully completed......................................
2024-04-26 23:22:30,841:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:30,841:INFO:Creating metrics dataframe
2024-04-26 23:22:30,844:INFO:Initializing Gradient Boosting Classifier
2024-04-26 23:22:30,844:INFO:Total runtime is 0.039791421095530195 minutes
2024-04-26 23:22:30,844:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:30,845:INFO:Initializing create_model()
2024-04-26 23:22:30,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:30,845:INFO:Checking exceptions
2024-04-26 23:22:30,845:INFO:Importing libraries
2024-04-26 23:22:30,845:INFO:Copying training dataset
2024-04-26 23:22:30,848:INFO:Defining folds
2024-04-26 23:22:30,848:INFO:Declaring metric variables
2024-04-26 23:22:30,848:INFO:Importing untrained model
2024-04-26 23:22:30,848:INFO:Gradient Boosting Classifier Imported successfully
2024-04-26 23:22:30,849:INFO:Starting cross validation
2024-04-26 23:22:30,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:31,121:INFO:Calculating mean and std
2024-04-26 23:22:31,122:INFO:Creating metrics dataframe
2024-04-26 23:22:31,124:INFO:Uploading results into container
2024-04-26 23:22:31,124:INFO:Uploading model into container now
2024-04-26 23:22:31,125:INFO:_master_model_container: 10
2024-04-26 23:22:31,125:INFO:_display_container: 2
2024-04-26 23:22:31,125:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5246, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-26 23:22:31,125:INFO:create_model() successfully completed......................................
2024-04-26 23:22:31,254:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:31,254:INFO:Creating metrics dataframe
2024-04-26 23:22:31,256:INFO:Initializing Linear Discriminant Analysis
2024-04-26 23:22:31,256:INFO:Total runtime is 0.046653314431508386 minutes
2024-04-26 23:22:31,256:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:31,257:INFO:Initializing create_model()
2024-04-26 23:22:31,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:31,257:INFO:Checking exceptions
2024-04-26 23:22:31,257:INFO:Importing libraries
2024-04-26 23:22:31,257:INFO:Copying training dataset
2024-04-26 23:22:31,260:INFO:Defining folds
2024-04-26 23:22:31,260:INFO:Declaring metric variables
2024-04-26 23:22:31,260:INFO:Importing untrained model
2024-04-26 23:22:31,260:INFO:Linear Discriminant Analysis Imported successfully
2024-04-26 23:22:31,261:INFO:Starting cross validation
2024-04-26 23:22:31,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:31,321:INFO:Calculating mean and std
2024-04-26 23:22:31,321:INFO:Creating metrics dataframe
2024-04-26 23:22:31,323:INFO:Uploading results into container
2024-04-26 23:22:31,323:INFO:Uploading model into container now
2024-04-26 23:22:31,323:INFO:_master_model_container: 11
2024-04-26 23:22:31,323:INFO:_display_container: 2
2024-04-26 23:22:31,324:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-26 23:22:31,324:INFO:create_model() successfully completed......................................
2024-04-26 23:22:31,450:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:31,450:INFO:Creating metrics dataframe
2024-04-26 23:22:31,453:INFO:Initializing Extra Trees Classifier
2024-04-26 23:22:31,453:INFO:Total runtime is 0.04993711312611898 minutes
2024-04-26 23:22:31,454:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:31,454:INFO:Initializing create_model()
2024-04-26 23:22:31,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:31,454:INFO:Checking exceptions
2024-04-26 23:22:31,454:INFO:Importing libraries
2024-04-26 23:22:31,454:INFO:Copying training dataset
2024-04-26 23:22:31,459:INFO:Defining folds
2024-04-26 23:22:31,459:INFO:Declaring metric variables
2024-04-26 23:22:31,459:INFO:Importing untrained model
2024-04-26 23:22:31,459:INFO:Extra Trees Classifier Imported successfully
2024-04-26 23:22:31,460:INFO:Starting cross validation
2024-04-26 23:22:31,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:31,759:INFO:Calculating mean and std
2024-04-26 23:22:31,760:INFO:Creating metrics dataframe
2024-04-26 23:22:31,761:INFO:Uploading results into container
2024-04-26 23:22:31,762:INFO:Uploading model into container now
2024-04-26 23:22:31,762:INFO:_master_model_container: 12
2024-04-26 23:22:31,762:INFO:_display_container: 2
2024-04-26 23:22:31,763:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5246, verbose=0,
                     warm_start=False)
2024-04-26 23:22:31,763:INFO:create_model() successfully completed......................................
2024-04-26 23:22:31,893:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:31,893:INFO:Creating metrics dataframe
2024-04-26 23:22:31,895:INFO:Initializing Light Gradient Boosting Machine
2024-04-26 23:22:31,896:INFO:Total runtime is 0.05730369488398235 minutes
2024-04-26 23:22:31,896:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:31,896:INFO:Initializing create_model()
2024-04-26 23:22:31,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:31,896:INFO:Checking exceptions
2024-04-26 23:22:31,896:INFO:Importing libraries
2024-04-26 23:22:31,896:INFO:Copying training dataset
2024-04-26 23:22:31,899:INFO:Defining folds
2024-04-26 23:22:31,899:INFO:Declaring metric variables
2024-04-26 23:22:31,899:INFO:Importing untrained model
2024-04-26 23:22:31,900:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-26 23:22:31,900:INFO:Starting cross validation
2024-04-26 23:22:31,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:32,345:INFO:Calculating mean and std
2024-04-26 23:22:32,346:INFO:Creating metrics dataframe
2024-04-26 23:22:32,348:INFO:Uploading results into container
2024-04-26 23:22:32,349:INFO:Uploading model into container now
2024-04-26 23:22:32,349:INFO:_master_model_container: 13
2024-04-26 23:22:32,349:INFO:_display_container: 2
2024-04-26 23:22:32,350:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5246, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-26 23:22:32,350:INFO:create_model() successfully completed......................................
2024-04-26 23:22:32,511:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:32,511:INFO:Creating metrics dataframe
2024-04-26 23:22:32,514:INFO:Initializing Dummy Classifier
2024-04-26 23:22:32,514:INFO:Total runtime is 0.06762829621632895 minutes
2024-04-26 23:22:32,514:INFO:SubProcess create_model() called ==================================
2024-04-26 23:22:32,514:INFO:Initializing create_model()
2024-04-26 23:22:32,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002147741B370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:32,514:INFO:Checking exceptions
2024-04-26 23:22:32,514:INFO:Importing libraries
2024-04-26 23:22:32,514:INFO:Copying training dataset
2024-04-26 23:22:32,518:INFO:Defining folds
2024-04-26 23:22:32,518:INFO:Declaring metric variables
2024-04-26 23:22:32,518:INFO:Importing untrained model
2024-04-26 23:22:32,518:INFO:Dummy Classifier Imported successfully
2024-04-26 23:22:32,518:INFO:Starting cross validation
2024-04-26 23:22:32,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:22:32,549:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,552:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,557:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,559:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,563:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,564:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,566:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,568:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,568:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,568:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:22:32,581:INFO:Calculating mean and std
2024-04-26 23:22:32,581:INFO:Creating metrics dataframe
2024-04-26 23:22:32,583:INFO:Uploading results into container
2024-04-26 23:22:32,583:INFO:Uploading model into container now
2024-04-26 23:22:32,584:INFO:_master_model_container: 14
2024-04-26 23:22:32,584:INFO:_display_container: 2
2024-04-26 23:22:32,584:INFO:DummyClassifier(constant=None, random_state=5246, strategy='prior')
2024-04-26 23:22:32,584:INFO:create_model() successfully completed......................................
2024-04-26 23:22:32,710:INFO:SubProcess create_model() end ==================================
2024-04-26 23:22:32,711:INFO:Creating metrics dataframe
2024-04-26 23:22:32,714:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-26 23:22:32,715:INFO:Initializing create_model()
2024-04-26 23:22:32,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214719A80D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5246, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:22:32,715:INFO:Checking exceptions
2024-04-26 23:22:32,716:INFO:Importing libraries
2024-04-26 23:22:32,716:INFO:Copying training dataset
2024-04-26 23:22:32,718:INFO:Defining folds
2024-04-26 23:22:32,718:INFO:Declaring metric variables
2024-04-26 23:22:32,719:INFO:Importing untrained model
2024-04-26 23:22:32,719:INFO:Declaring custom model
2024-04-26 23:22:32,719:INFO:Gradient Boosting Classifier Imported successfully
2024-04-26 23:22:32,720:INFO:Cross validation set to False
2024-04-26 23:22:32,720:INFO:Fitting Model
2024-04-26 23:22:32,855:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5246, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-26 23:22:32,855:INFO:create_model() successfully completed......................................
2024-04-26 23:22:32,994:INFO:_master_model_container: 14
2024-04-26 23:22:32,994:INFO:_display_container: 2
2024-04-26 23:22:32,995:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5246, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-26 23:22:32,995:INFO:compare_models() successfully completed......................................
2024-04-26 23:22:33,001:INFO:Initializing save_model()
2024-04-26 23:22:33,001:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5246, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name= THe Best Model the given dataset, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-26 23:22:33,001:INFO:Adding model into prep_pipe
2024-04-26 23:22:33,010:INFO: THe Best Model the given dataset.pkl saved in current working directory
2024-04-26 23:22:33,014:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                (...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=5246, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-04-26 23:22:33,014:INFO:save_model() successfully completed......................................
2024-04-26 23:33:28,398:INFO:PyCaret ClassificationExperiment
2024-04-26 23:33:28,399:INFO:Logging name: clf-default-name
2024-04-26 23:33:28,399:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-26 23:33:28,399:INFO:version 3.3.1
2024-04-26 23:33:28,399:INFO:Initializing setup()
2024-04-26 23:33:28,400:INFO:self.USI: 3891
2024-04-26 23:33:28,400:INFO:self._variable_keys: {'data', 'fold_groups_param', 'X_test', 'y_test', 'log_plots_param', 'exp_id', 'y_train', 'X_train', 'target_param', 'logging_param', 'idx', 'html_param', 'gpu_param', 'y', 'is_multiclass', 'pipeline', 'X', 'exp_name_log', 'fix_imbalance', 'n_jobs_param', 'fold_shuffle_param', 'seed', 'memory', 'fold_generator', '_ml_usecase', 'USI', 'gpu_n_jobs_param', '_available_plots'}
2024-04-26 23:33:28,400:INFO:Checking environment
2024-04-26 23:33:28,400:INFO:python_version: 3.10.9
2024-04-26 23:33:28,400:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-26 23:33:28,400:INFO:machine: AMD64
2024-04-26 23:33:28,401:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-26 23:33:28,401:INFO:Memory: svmem(total=16541904896, available=4089929728, percent=75.3, used=12451975168, free=4089929728)
2024-04-26 23:33:28,401:INFO:Physical Core: 6
2024-04-26 23:33:28,401:INFO:Logical Core: 12
2024-04-26 23:33:28,402:INFO:Checking libraries
2024-04-26 23:33:28,402:INFO:System:
2024-04-26 23:33:28,402:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-26 23:33:28,402:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-26 23:33:28,402:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-26 23:33:28,402:INFO:PyCaret required dependencies:
2024-04-26 23:33:28,403:INFO:                 pip: 22.3.1
2024-04-26 23:33:28,403:INFO:          setuptools: 65.6.3
2024-04-26 23:33:28,403:INFO:             pycaret: 3.3.1
2024-04-26 23:33:28,403:INFO:             IPython: 8.10.0
2024-04-26 23:33:28,403:INFO:          ipywidgets: 7.6.5
2024-04-26 23:33:28,404:INFO:                tqdm: 4.64.1
2024-04-26 23:33:28,404:INFO:               numpy: 1.23.5
2024-04-26 23:33:28,404:INFO:              pandas: 2.2.2
2024-04-26 23:33:28,404:INFO:              jinja2: 3.1.2
2024-04-26 23:33:28,404:INFO:               scipy: 1.10.0
2024-04-26 23:33:28,404:INFO:              joblib: 1.3.2
2024-04-26 23:33:28,404:INFO:             sklearn: 1.4.2
2024-04-26 23:33:28,404:INFO:                pyod: 1.1.3
2024-04-26 23:33:28,406:INFO:            imblearn: 0.10.1
2024-04-26 23:33:28,406:INFO:   category_encoders: 2.6.3
2024-04-26 23:33:28,406:INFO:            lightgbm: 4.3.0
2024-04-26 23:33:28,406:INFO:               numba: 0.56.4
2024-04-26 23:33:28,406:INFO:            requests: 2.28.1
2024-04-26 23:33:28,406:INFO:          matplotlib: 3.7.0
2024-04-26 23:33:28,406:INFO:          scikitplot: 0.3.7
2024-04-26 23:33:28,406:INFO:         yellowbrick: 1.5
2024-04-26 23:33:28,406:INFO:              plotly: 5.21.0
2024-04-26 23:33:28,406:INFO:    plotly-resampler: Not installed
2024-04-26 23:33:28,407:INFO:             kaleido: 0.2.1
2024-04-26 23:33:28,407:INFO:           schemdraw: 0.15
2024-04-26 23:33:28,407:INFO:         statsmodels: 0.13.5
2024-04-26 23:33:28,407:INFO:              sktime: 0.26.0
2024-04-26 23:33:28,407:INFO:               tbats: 1.1.3
2024-04-26 23:33:28,407:INFO:            pmdarima: 2.0.4
2024-04-26 23:33:28,407:INFO:              psutil: 5.9.0
2024-04-26 23:33:28,407:INFO:          markupsafe: 2.1.1
2024-04-26 23:33:28,407:INFO:             pickle5: Not installed
2024-04-26 23:33:28,407:INFO:         cloudpickle: 2.0.0
2024-04-26 23:33:28,407:INFO:         deprecation: 2.1.0
2024-04-26 23:33:28,407:INFO:              xxhash: 3.4.1
2024-04-26 23:33:28,407:INFO:           wurlitzer: Not installed
2024-04-26 23:33:28,408:INFO:PyCaret optional dependencies:
2024-04-26 23:33:28,408:INFO:                shap: Not installed
2024-04-26 23:33:28,408:INFO:           interpret: Not installed
2024-04-26 23:33:28,408:INFO:                umap: Not installed
2024-04-26 23:33:28,408:INFO:     ydata_profiling: 4.7.0
2024-04-26 23:33:28,408:INFO:  explainerdashboard: Not installed
2024-04-26 23:33:28,408:INFO:             autoviz: Not installed
2024-04-26 23:33:28,408:INFO:           fairlearn: Not installed
2024-04-26 23:33:28,408:INFO:          deepchecks: Not installed
2024-04-26 23:33:28,409:INFO:             xgboost: Not installed
2024-04-26 23:33:28,409:INFO:            catboost: Not installed
2024-04-26 23:33:28,410:INFO:              kmodes: Not installed
2024-04-26 23:33:28,410:INFO:             mlxtend: Not installed
2024-04-26 23:33:28,410:INFO:       statsforecast: Not installed
2024-04-26 23:33:28,410:INFO:        tune_sklearn: Not installed
2024-04-26 23:33:28,410:INFO:                 ray: Not installed
2024-04-26 23:33:28,410:INFO:            hyperopt: Not installed
2024-04-26 23:33:28,410:INFO:              optuna: Not installed
2024-04-26 23:33:28,411:INFO:               skopt: Not installed
2024-04-26 23:33:28,411:INFO:              mlflow: Not installed
2024-04-26 23:33:28,411:INFO:              gradio: Not installed
2024-04-26 23:33:28,411:INFO:             fastapi: Not installed
2024-04-26 23:33:28,411:INFO:             uvicorn: Not installed
2024-04-26 23:33:28,411:INFO:              m2cgen: Not installed
2024-04-26 23:33:28,411:INFO:           evidently: Not installed
2024-04-26 23:33:28,411:INFO:               fugue: Not installed
2024-04-26 23:33:28,412:INFO:           streamlit: 1.33.0
2024-04-26 23:33:28,412:INFO:             prophet: Not installed
2024-04-26 23:33:28,412:INFO:None
2024-04-26 23:33:28,412:INFO:Set up data.
2024-04-26 23:33:28,418:INFO:Set up folding strategy.
2024-04-26 23:33:28,419:INFO:Set up train/test split.
2024-04-26 23:33:28,426:INFO:Set up index.
2024-04-26 23:33:28,427:INFO:Assigning column types.
2024-04-26 23:33:28,433:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-26 23:33:28,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 23:33:28,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:33:28,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:28,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:28,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-26 23:33:28,681:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:33:28,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:28,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:28,745:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-26 23:33:28,839:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:33:28,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:28,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-26 23:33:29,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,062:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-26 23:33:29,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,407:INFO:Preparing preprocessing pipeline...
2024-04-26 23:33:29,410:INFO:Set up simple imputation.
2024-04-26 23:33:29,448:INFO:Finished creating preprocessing pipeline.
2024-04-26 23:33:29,454:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-04-26 23:33:29,454:INFO:Creating final display dataframe.
2024-04-26 23:33:29,589:INFO:Setup _display_container:                     Description             Value
0                    Session id              1565
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape          (768, 9)
4        Transformed data shape          (768, 9)
5   Transformed train set shape          (537, 9)
6    Transformed test set shape          (231, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3891
2024-04-26 23:33:29,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-26 23:33:29,909:INFO:setup() successfully completed in 1.51s...............
2024-04-26 23:33:29,916:INFO:Initializing compare_models()
2024-04-26 23:33:29,916:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-26 23:33:29,916:INFO:Checking exceptions
2024-04-26 23:33:29,925:INFO:Preparing display monitor
2024-04-26 23:33:29,930:INFO:Initializing Logistic Regression
2024-04-26 23:33:29,931:INFO:Total runtime is 1.6780694325764976e-05 minutes
2024-04-26 23:33:29,932:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:29,933:INFO:Initializing create_model()
2024-04-26 23:33:29,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:29,933:INFO:Checking exceptions
2024-04-26 23:33:29,933:INFO:Importing libraries
2024-04-26 23:33:29,933:INFO:Copying training dataset
2024-04-26 23:33:29,943:INFO:Defining folds
2024-04-26 23:33:29,943:INFO:Declaring metric variables
2024-04-26 23:33:29,944:INFO:Importing untrained model
2024-04-26 23:33:29,947:INFO:Logistic Regression Imported successfully
2024-04-26 23:33:29,949:INFO:Starting cross validation
2024-04-26 23:33:29,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:43,702:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,702:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,702:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,702:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,704:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,704:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,704:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,704:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,709:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:43,726:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:44,784:INFO:Calculating mean and std
2024-04-26 23:33:44,786:INFO:Creating metrics dataframe
2024-04-26 23:33:44,792:INFO:Uploading results into container
2024-04-26 23:33:44,793:INFO:Uploading model into container now
2024-04-26 23:33:44,794:INFO:_master_model_container: 1
2024-04-26 23:33:44,795:INFO:_display_container: 2
2024-04-26 23:33:44,796:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1565, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-26 23:33:44,796:INFO:create_model() successfully completed......................................
2024-04-26 23:33:45,085:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:45,085:INFO:Creating metrics dataframe
2024-04-26 23:33:45,090:INFO:Initializing K Neighbors Classifier
2024-04-26 23:33:45,090:INFO:Total runtime is 0.2526577035586039 minutes
2024-04-26 23:33:45,091:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:45,091:INFO:Initializing create_model()
2024-04-26 23:33:45,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:45,091:INFO:Checking exceptions
2024-04-26 23:33:45,091:INFO:Importing libraries
2024-04-26 23:33:45,092:INFO:Copying training dataset
2024-04-26 23:33:45,101:INFO:Defining folds
2024-04-26 23:33:45,101:INFO:Declaring metric variables
2024-04-26 23:33:45,101:INFO:Importing untrained model
2024-04-26 23:33:45,102:INFO:K Neighbors Classifier Imported successfully
2024-04-26 23:33:45,103:INFO:Starting cross validation
2024-04-26 23:33:45,104:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:53,303:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:53,309:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-26 23:33:54,136:INFO:Calculating mean and std
2024-04-26 23:33:54,138:INFO:Creating metrics dataframe
2024-04-26 23:33:54,141:INFO:Uploading results into container
2024-04-26 23:33:54,141:INFO:Uploading model into container now
2024-04-26 23:33:54,143:INFO:_master_model_container: 2
2024-04-26 23:33:54,143:INFO:_display_container: 2
2024-04-26 23:33:54,143:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-26 23:33:54,144:INFO:create_model() successfully completed......................................
2024-04-26 23:33:54,376:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:54,376:INFO:Creating metrics dataframe
2024-04-26 23:33:54,384:INFO:Initializing Naive Bayes
2024-04-26 23:33:54,384:INFO:Total runtime is 0.4075591524442037 minutes
2024-04-26 23:33:54,385:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:54,385:INFO:Initializing create_model()
2024-04-26 23:33:54,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:54,386:INFO:Checking exceptions
2024-04-26 23:33:54,386:INFO:Importing libraries
2024-04-26 23:33:54,386:INFO:Copying training dataset
2024-04-26 23:33:54,396:INFO:Defining folds
2024-04-26 23:33:54,396:INFO:Declaring metric variables
2024-04-26 23:33:54,398:INFO:Importing untrained model
2024-04-26 23:33:54,398:INFO:Naive Bayes Imported successfully
2024-04-26 23:33:54,399:INFO:Starting cross validation
2024-04-26 23:33:54,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:54,559:INFO:Calculating mean and std
2024-04-26 23:33:54,561:INFO:Creating metrics dataframe
2024-04-26 23:33:54,565:INFO:Uploading results into container
2024-04-26 23:33:54,565:INFO:Uploading model into container now
2024-04-26 23:33:54,566:INFO:_master_model_container: 3
2024-04-26 23:33:54,566:INFO:_display_container: 2
2024-04-26 23:33:54,567:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-26 23:33:54,567:INFO:create_model() successfully completed......................................
2024-04-26 23:33:54,773:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:54,773:INFO:Creating metrics dataframe
2024-04-26 23:33:54,778:INFO:Initializing Decision Tree Classifier
2024-04-26 23:33:54,778:INFO:Total runtime is 0.4141320824623108 minutes
2024-04-26 23:33:54,779:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:54,779:INFO:Initializing create_model()
2024-04-26 23:33:54,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:54,780:INFO:Checking exceptions
2024-04-26 23:33:54,780:INFO:Importing libraries
2024-04-26 23:33:54,780:INFO:Copying training dataset
2024-04-26 23:33:54,789:INFO:Defining folds
2024-04-26 23:33:54,789:INFO:Declaring metric variables
2024-04-26 23:33:54,790:INFO:Importing untrained model
2024-04-26 23:33:54,791:INFO:Decision Tree Classifier Imported successfully
2024-04-26 23:33:54,791:INFO:Starting cross validation
2024-04-26 23:33:54,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:55,006:INFO:Calculating mean and std
2024-04-26 23:33:55,008:INFO:Creating metrics dataframe
2024-04-26 23:33:55,013:INFO:Uploading results into container
2024-04-26 23:33:55,014:INFO:Uploading model into container now
2024-04-26 23:33:55,014:INFO:_master_model_container: 4
2024-04-26 23:33:55,014:INFO:_display_container: 2
2024-04-26 23:33:55,015:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1565, splitter='best')
2024-04-26 23:33:55,015:INFO:create_model() successfully completed......................................
2024-04-26 23:33:55,224:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:55,225:INFO:Creating metrics dataframe
2024-04-26 23:33:55,232:INFO:Initializing SVM - Linear Kernel
2024-04-26 23:33:55,232:INFO:Total runtime is 0.42168918053309123 minutes
2024-04-26 23:33:55,233:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:55,233:INFO:Initializing create_model()
2024-04-26 23:33:55,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:55,233:INFO:Checking exceptions
2024-04-26 23:33:55,233:INFO:Importing libraries
2024-04-26 23:33:55,233:INFO:Copying training dataset
2024-04-26 23:33:55,241:INFO:Defining folds
2024-04-26 23:33:55,241:INFO:Declaring metric variables
2024-04-26 23:33:55,241:INFO:Importing untrained model
2024-04-26 23:33:55,242:INFO:SVM - Linear Kernel Imported successfully
2024-04-26 23:33:55,243:INFO:Starting cross validation
2024-04-26 23:33:55,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:55,439:INFO:Calculating mean and std
2024-04-26 23:33:55,440:INFO:Creating metrics dataframe
2024-04-26 23:33:55,443:INFO:Uploading results into container
2024-04-26 23:33:55,445:INFO:Uploading model into container now
2024-04-26 23:33:55,446:INFO:_master_model_container: 5
2024-04-26 23:33:55,446:INFO:_display_container: 2
2024-04-26 23:33:55,448:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1565, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-26 23:33:55,448:INFO:create_model() successfully completed......................................
2024-04-26 23:33:55,646:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:55,646:INFO:Creating metrics dataframe
2024-04-26 23:33:55,652:INFO:Initializing Ridge Classifier
2024-04-26 23:33:55,652:INFO:Total runtime is 0.4286891579627991 minutes
2024-04-26 23:33:55,653:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:55,653:INFO:Initializing create_model()
2024-04-26 23:33:55,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:55,653:INFO:Checking exceptions
2024-04-26 23:33:55,653:INFO:Importing libraries
2024-04-26 23:33:55,653:INFO:Copying training dataset
2024-04-26 23:33:55,660:INFO:Defining folds
2024-04-26 23:33:55,660:INFO:Declaring metric variables
2024-04-26 23:33:55,661:INFO:Importing untrained model
2024-04-26 23:33:55,662:INFO:Ridge Classifier Imported successfully
2024-04-26 23:33:55,663:INFO:Starting cross validation
2024-04-26 23:33:55,664:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:55,826:INFO:Calculating mean and std
2024-04-26 23:33:55,829:INFO:Creating metrics dataframe
2024-04-26 23:33:55,834:INFO:Uploading results into container
2024-04-26 23:33:55,835:INFO:Uploading model into container now
2024-04-26 23:33:55,835:INFO:_master_model_container: 6
2024-04-26 23:33:55,836:INFO:_display_container: 2
2024-04-26 23:33:55,836:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1565, solver='auto',
                tol=0.0001)
2024-04-26 23:33:55,836:INFO:create_model() successfully completed......................................
2024-04-26 23:33:56,038:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:56,038:INFO:Creating metrics dataframe
2024-04-26 23:33:56,043:INFO:Initializing Random Forest Classifier
2024-04-26 23:33:56,043:INFO:Total runtime is 0.4352091193199158 minutes
2024-04-26 23:33:56,044:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:56,044:INFO:Initializing create_model()
2024-04-26 23:33:56,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:56,045:INFO:Checking exceptions
2024-04-26 23:33:56,045:INFO:Importing libraries
2024-04-26 23:33:56,045:INFO:Copying training dataset
2024-04-26 23:33:56,051:INFO:Defining folds
2024-04-26 23:33:56,052:INFO:Declaring metric variables
2024-04-26 23:33:56,052:INFO:Importing untrained model
2024-04-26 23:33:56,053:INFO:Random Forest Classifier Imported successfully
2024-04-26 23:33:56,054:INFO:Starting cross validation
2024-04-26 23:33:56,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:56,922:INFO:Calculating mean and std
2024-04-26 23:33:56,923:INFO:Creating metrics dataframe
2024-04-26 23:33:56,926:INFO:Uploading results into container
2024-04-26 23:33:56,927:INFO:Uploading model into container now
2024-04-26 23:33:56,927:INFO:_master_model_container: 7
2024-04-26 23:33:56,927:INFO:_display_container: 2
2024-04-26 23:33:56,929:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1565, verbose=0,
                       warm_start=False)
2024-04-26 23:33:56,929:INFO:create_model() successfully completed......................................
2024-04-26 23:33:57,132:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:57,133:INFO:Creating metrics dataframe
2024-04-26 23:33:57,139:INFO:Initializing Quadratic Discriminant Analysis
2024-04-26 23:33:57,140:INFO:Total runtime is 0.45348973671595255 minutes
2024-04-26 23:33:57,140:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:57,141:INFO:Initializing create_model()
2024-04-26 23:33:57,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:57,141:INFO:Checking exceptions
2024-04-26 23:33:57,141:INFO:Importing libraries
2024-04-26 23:33:57,141:INFO:Copying training dataset
2024-04-26 23:33:57,148:INFO:Defining folds
2024-04-26 23:33:57,149:INFO:Declaring metric variables
2024-04-26 23:33:57,149:INFO:Importing untrained model
2024-04-26 23:33:57,150:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-26 23:33:57,151:INFO:Starting cross validation
2024-04-26 23:33:57,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:57,306:INFO:Calculating mean and std
2024-04-26 23:33:57,307:INFO:Creating metrics dataframe
2024-04-26 23:33:57,310:INFO:Uploading results into container
2024-04-26 23:33:57,310:INFO:Uploading model into container now
2024-04-26 23:33:57,312:INFO:_master_model_container: 8
2024-04-26 23:33:57,312:INFO:_display_container: 2
2024-04-26 23:33:57,313:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-26 23:33:57,313:INFO:create_model() successfully completed......................................
2024-04-26 23:33:57,516:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:57,516:INFO:Creating metrics dataframe
2024-04-26 23:33:57,521:INFO:Initializing Ada Boost Classifier
2024-04-26 23:33:57,521:INFO:Total runtime is 0.45984252691268923 minutes
2024-04-26 23:33:57,521:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:57,522:INFO:Initializing create_model()
2024-04-26 23:33:57,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:57,522:INFO:Checking exceptions
2024-04-26 23:33:57,522:INFO:Importing libraries
2024-04-26 23:33:57,522:INFO:Copying training dataset
2024-04-26 23:33:57,529:INFO:Defining folds
2024-04-26 23:33:57,529:INFO:Declaring metric variables
2024-04-26 23:33:57,530:INFO:Importing untrained model
2024-04-26 23:33:57,531:INFO:Ada Boost Classifier Imported successfully
2024-04-26 23:33:57,531:INFO:Starting cross validation
2024-04-26 23:33:57,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:57,578:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,580:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,584:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,589:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,593:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,598:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,603:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,607:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,613:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,620:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-26 23:33:57,992:INFO:Calculating mean and std
2024-04-26 23:33:57,994:INFO:Creating metrics dataframe
2024-04-26 23:33:57,997:INFO:Uploading results into container
2024-04-26 23:33:57,999:INFO:Uploading model into container now
2024-04-26 23:33:57,999:INFO:_master_model_container: 9
2024-04-26 23:33:57,999:INFO:_display_container: 2
2024-04-26 23:33:58,000:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1565)
2024-04-26 23:33:58,000:INFO:create_model() successfully completed......................................
2024-04-26 23:33:58,199:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:58,199:INFO:Creating metrics dataframe
2024-04-26 23:33:58,204:INFO:Initializing Gradient Boosting Classifier
2024-04-26 23:33:58,204:INFO:Total runtime is 0.47123524745305384 minutes
2024-04-26 23:33:58,205:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:58,206:INFO:Initializing create_model()
2024-04-26 23:33:58,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:58,206:INFO:Checking exceptions
2024-04-26 23:33:58,206:INFO:Importing libraries
2024-04-26 23:33:58,206:INFO:Copying training dataset
2024-04-26 23:33:58,216:INFO:Defining folds
2024-04-26 23:33:58,216:INFO:Declaring metric variables
2024-04-26 23:33:58,216:INFO:Importing untrained model
2024-04-26 23:33:58,217:INFO:Gradient Boosting Classifier Imported successfully
2024-04-26 23:33:58,218:INFO:Starting cross validation
2024-04-26 23:33:58,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:58,821:INFO:Calculating mean and std
2024-04-26 23:33:58,822:INFO:Creating metrics dataframe
2024-04-26 23:33:58,825:INFO:Uploading results into container
2024-04-26 23:33:58,826:INFO:Uploading model into container now
2024-04-26 23:33:58,827:INFO:_master_model_container: 10
2024-04-26 23:33:58,827:INFO:_display_container: 2
2024-04-26 23:33:58,828:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1565, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-26 23:33:58,828:INFO:create_model() successfully completed......................................
2024-04-26 23:33:59,030:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:59,030:INFO:Creating metrics dataframe
2024-04-26 23:33:59,036:INFO:Initializing Linear Discriminant Analysis
2024-04-26 23:33:59,036:INFO:Total runtime is 0.4850984930992127 minutes
2024-04-26 23:33:59,036:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:59,037:INFO:Initializing create_model()
2024-04-26 23:33:59,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:59,038:INFO:Checking exceptions
2024-04-26 23:33:59,038:INFO:Importing libraries
2024-04-26 23:33:59,038:INFO:Copying training dataset
2024-04-26 23:33:59,046:INFO:Defining folds
2024-04-26 23:33:59,046:INFO:Declaring metric variables
2024-04-26 23:33:59,046:INFO:Importing untrained model
2024-04-26 23:33:59,049:INFO:Linear Discriminant Analysis Imported successfully
2024-04-26 23:33:59,051:INFO:Starting cross validation
2024-04-26 23:33:59,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:33:59,193:INFO:Calculating mean and std
2024-04-26 23:33:59,195:INFO:Creating metrics dataframe
2024-04-26 23:33:59,198:INFO:Uploading results into container
2024-04-26 23:33:59,199:INFO:Uploading model into container now
2024-04-26 23:33:59,199:INFO:_master_model_container: 11
2024-04-26 23:33:59,199:INFO:_display_container: 2
2024-04-26 23:33:59,200:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-26 23:33:59,200:INFO:create_model() successfully completed......................................
2024-04-26 23:33:59,403:INFO:SubProcess create_model() end ==================================
2024-04-26 23:33:59,403:INFO:Creating metrics dataframe
2024-04-26 23:33:59,409:INFO:Initializing Extra Trees Classifier
2024-04-26 23:33:59,409:INFO:Total runtime is 0.4913072387377422 minutes
2024-04-26 23:33:59,410:INFO:SubProcess create_model() called ==================================
2024-04-26 23:33:59,410:INFO:Initializing create_model()
2024-04-26 23:33:59,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:33:59,410:INFO:Checking exceptions
2024-04-26 23:33:59,411:INFO:Importing libraries
2024-04-26 23:33:59,411:INFO:Copying training dataset
2024-04-26 23:33:59,423:INFO:Defining folds
2024-04-26 23:33:59,423:INFO:Declaring metric variables
2024-04-26 23:33:59,423:INFO:Importing untrained model
2024-04-26 23:33:59,424:INFO:Extra Trees Classifier Imported successfully
2024-04-26 23:33:59,425:INFO:Starting cross validation
2024-04-26 23:33:59,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:34:00,185:INFO:Calculating mean and std
2024-04-26 23:34:00,187:INFO:Creating metrics dataframe
2024-04-26 23:34:00,190:INFO:Uploading results into container
2024-04-26 23:34:00,191:INFO:Uploading model into container now
2024-04-26 23:34:00,191:INFO:_master_model_container: 12
2024-04-26 23:34:00,191:INFO:_display_container: 2
2024-04-26 23:34:00,192:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1565, verbose=0,
                     warm_start=False)
2024-04-26 23:34:00,192:INFO:create_model() successfully completed......................................
2024-04-26 23:34:00,411:INFO:SubProcess create_model() end ==================================
2024-04-26 23:34:00,411:INFO:Creating metrics dataframe
2024-04-26 23:34:00,416:INFO:Initializing Light Gradient Boosting Machine
2024-04-26 23:34:00,416:INFO:Total runtime is 0.508102019627889 minutes
2024-04-26 23:34:00,418:INFO:SubProcess create_model() called ==================================
2024-04-26 23:34:00,418:INFO:Initializing create_model()
2024-04-26 23:34:00,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:34:00,418:INFO:Checking exceptions
2024-04-26 23:34:00,419:INFO:Importing libraries
2024-04-26 23:34:00,419:INFO:Copying training dataset
2024-04-26 23:34:00,428:INFO:Defining folds
2024-04-26 23:34:00,428:INFO:Declaring metric variables
2024-04-26 23:34:00,429:INFO:Importing untrained model
2024-04-26 23:34:00,430:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-26 23:34:00,431:INFO:Starting cross validation
2024-04-26 23:34:00,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:34:01,656:INFO:Calculating mean and std
2024-04-26 23:34:01,657:INFO:Creating metrics dataframe
2024-04-26 23:34:01,662:INFO:Uploading results into container
2024-04-26 23:34:01,663:INFO:Uploading model into container now
2024-04-26 23:34:01,664:INFO:_master_model_container: 13
2024-04-26 23:34:01,664:INFO:_display_container: 2
2024-04-26 23:34:01,665:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1565, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-26 23:34:01,665:INFO:create_model() successfully completed......................................
2024-04-26 23:34:01,890:INFO:SubProcess create_model() end ==================================
2024-04-26 23:34:01,892:INFO:Creating metrics dataframe
2024-04-26 23:34:01,896:INFO:Initializing Dummy Classifier
2024-04-26 23:34:01,896:INFO:Total runtime is 0.5327632665634155 minutes
2024-04-26 23:34:01,897:INFO:SubProcess create_model() called ==================================
2024-04-26 23:34:01,898:INFO:Initializing create_model()
2024-04-26 23:34:01,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021476CC7520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:34:01,898:INFO:Checking exceptions
2024-04-26 23:34:01,898:INFO:Importing libraries
2024-04-26 23:34:01,898:INFO:Copying training dataset
2024-04-26 23:34:01,905:INFO:Defining folds
2024-04-26 23:34:01,906:INFO:Declaring metric variables
2024-04-26 23:34:01,906:INFO:Importing untrained model
2024-04-26 23:34:01,907:INFO:Dummy Classifier Imported successfully
2024-04-26 23:34:01,907:INFO:Starting cross validation
2024-04-26 23:34:01,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-26 23:34:01,980:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:01,986:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:01,991:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:01,991:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:01,997:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:01,999:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:02,008:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:02,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:02,017:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:02,022:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-26 23:34:02,045:INFO:Calculating mean and std
2024-04-26 23:34:02,046:INFO:Creating metrics dataframe
2024-04-26 23:34:02,050:INFO:Uploading results into container
2024-04-26 23:34:02,050:INFO:Uploading model into container now
2024-04-26 23:34:02,051:INFO:_master_model_container: 14
2024-04-26 23:34:02,051:INFO:_display_container: 2
2024-04-26 23:34:02,051:INFO:DummyClassifier(constant=None, random_state=1565, strategy='prior')
2024-04-26 23:34:02,052:INFO:create_model() successfully completed......................................
2024-04-26 23:34:02,256:INFO:SubProcess create_model() end ==================================
2024-04-26 23:34:02,257:INFO:Creating metrics dataframe
2024-04-26 23:34:02,263:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-26 23:34:02,267:INFO:Initializing create_model()
2024-04-26 23:34:02,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021478D42FE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1565, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-26 23:34:02,267:INFO:Checking exceptions
2024-04-26 23:34:02,269:INFO:Importing libraries
2024-04-26 23:34:02,269:INFO:Copying training dataset
2024-04-26 23:34:02,279:INFO:Defining folds
2024-04-26 23:34:02,279:INFO:Declaring metric variables
2024-04-26 23:34:02,280:INFO:Importing untrained model
2024-04-26 23:34:02,280:INFO:Declaring custom model
2024-04-26 23:34:02,282:INFO:Logistic Regression Imported successfully
2024-04-26 23:34:02,283:INFO:Cross validation set to False
2024-04-26 23:34:02,283:INFO:Fitting Model
2024-04-26 23:34:02,328:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1565, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-26 23:34:02,328:INFO:create_model() successfully completed......................................
2024-04-26 23:34:02,565:INFO:_master_model_container: 14
2024-04-26 23:34:02,565:INFO:_display_container: 2
2024-04-26 23:34:02,566:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1565, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-26 23:34:02,566:INFO:compare_models() successfully completed......................................
2024-04-26 23:34:02,582:INFO:Initializing save_model()
2024-04-26 23:34:02,582:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1565, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-26 23:34:02,582:INFO:Adding model into prep_pipe
2024-04-26 23:34:02,592:INFO:best_model.pkl saved in current working directory
2024-04-26 23:34:02,603:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                (...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1565,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-04-26 23:34:02,603:INFO:save_model() successfully completed......................................
2024-04-26 23:47:30,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 23:47:30,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 23:47:30,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 23:47:30,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-26 23:47:32,952:INFO:Initializing load_model()
2024-04-26 23:47:32,952:INFO:load_model(model_name=trained_model, platform=None, authentication=None, verbose=True)
2024-04-26 23:47:33,959:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:00:39,420:INFO:Initializing load_model()
2024-04-27 00:00:39,420:INFO:load_model(model_name=trained_model, platform=None, authentication=None, verbose=True)
2024-04-27 00:01:35,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:01:35,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:01:35,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:01:35,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:05:09,145:INFO:PyCaret ClassificationExperiment
2024-04-27 00:05:09,146:INFO:Logging name: clf-default-name
2024-04-27 00:05:09,146:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-27 00:05:09,146:INFO:version 3.3.1
2024-04-27 00:05:09,146:INFO:Initializing setup()
2024-04-27 00:05:09,146:INFO:self.USI: a670
2024-04-27 00:05:09,146:INFO:self._variable_keys: {'n_jobs_param', 'gpu_n_jobs_param', 'exp_name_log', 'gpu_param', '_available_plots', 'fold_generator', '_ml_usecase', 'idx', 'fix_imbalance', 'X_train', 'X', 'fold_groups_param', 'USI', 'y', 'memory', 'y_train', 'seed', 'fold_shuffle_param', 'is_multiclass', 'logging_param', 'exp_id', 'data', 'X_test', 'pipeline', 'target_param', 'html_param', 'y_test', 'log_plots_param'}
2024-04-27 00:05:09,146:INFO:Checking environment
2024-04-27 00:05:09,146:INFO:python_version: 3.10.9
2024-04-27 00:05:09,146:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-27 00:05:09,146:INFO:machine: AMD64
2024-04-27 00:05:09,167:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-27 00:05:09,167:INFO:Memory: svmem(total=16541904896, available=4664475648, percent=71.8, used=11877429248, free=4664475648)
2024-04-27 00:05:09,167:INFO:Physical Core: 6
2024-04-27 00:05:09,167:INFO:Logical Core: 12
2024-04-27 00:05:09,168:INFO:Checking libraries
2024-04-27 00:05:09,168:INFO:System:
2024-04-27 00:05:09,168:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-27 00:05:09,168:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-27 00:05:09,168:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-27 00:05:09,169:INFO:PyCaret required dependencies:
2024-04-27 00:05:10,140:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:10,679:INFO:                 pip: 22.3.1
2024-04-27 00:05:10,679:INFO:          setuptools: 65.6.3
2024-04-27 00:05:10,681:INFO:             pycaret: 3.3.1
2024-04-27 00:05:10,681:INFO:             IPython: 8.10.0
2024-04-27 00:05:10,681:INFO:          ipywidgets: 7.6.5
2024-04-27 00:05:10,681:INFO:                tqdm: 4.64.1
2024-04-27 00:05:10,681:INFO:               numpy: 1.23.5
2024-04-27 00:05:10,681:INFO:              pandas: 2.2.2
2024-04-27 00:05:10,681:INFO:              jinja2: 3.1.2
2024-04-27 00:05:10,681:INFO:               scipy: 1.10.0
2024-04-27 00:05:10,681:INFO:              joblib: 1.3.2
2024-04-27 00:05:10,681:INFO:             sklearn: 1.4.2
2024-04-27 00:05:10,681:INFO:                pyod: 1.1.3
2024-04-27 00:05:10,682:INFO:            imblearn: 0.10.1
2024-04-27 00:05:10,682:INFO:   category_encoders: 2.6.3
2024-04-27 00:05:10,682:INFO:            lightgbm: 4.3.0
2024-04-27 00:05:10,682:INFO:               numba: 0.56.4
2024-04-27 00:05:10,682:INFO:            requests: 2.28.1
2024-04-27 00:05:10,682:INFO:          matplotlib: 3.7.0
2024-04-27 00:05:10,682:INFO:          scikitplot: 0.3.7
2024-04-27 00:05:10,682:INFO:         yellowbrick: 1.5
2024-04-27 00:05:10,682:INFO:              plotly: 5.21.0
2024-04-27 00:05:10,682:INFO:    plotly-resampler: Not installed
2024-04-27 00:05:10,682:INFO:             kaleido: 0.2.1
2024-04-27 00:05:10,682:INFO:           schemdraw: 0.15
2024-04-27 00:05:10,682:INFO:         statsmodels: 0.13.5
2024-04-27 00:05:10,683:INFO:              sktime: 0.26.0
2024-04-27 00:05:10,683:INFO:               tbats: 1.1.3
2024-04-27 00:05:10,683:INFO:            pmdarima: 2.0.4
2024-04-27 00:05:10,683:INFO:              psutil: 5.9.0
2024-04-27 00:05:10,683:INFO:          markupsafe: 2.1.1
2024-04-27 00:05:10,683:INFO:             pickle5: Not installed
2024-04-27 00:05:10,683:INFO:         cloudpickle: 2.0.0
2024-04-27 00:05:10,683:INFO:         deprecation: 2.1.0
2024-04-27 00:05:10,683:INFO:              xxhash: 3.4.1
2024-04-27 00:05:10,683:INFO:           wurlitzer: Not installed
2024-04-27 00:05:10,683:INFO:PyCaret optional dependencies:
2024-04-27 00:05:10,713:INFO:                shap: Not installed
2024-04-27 00:05:10,713:INFO:           interpret: Not installed
2024-04-27 00:05:10,713:INFO:                umap: Not installed
2024-04-27 00:05:10,713:INFO:     ydata_profiling: 4.7.0
2024-04-27 00:05:10,713:INFO:  explainerdashboard: Not installed
2024-04-27 00:05:10,713:INFO:             autoviz: Not installed
2024-04-27 00:05:10,713:INFO:           fairlearn: Not installed
2024-04-27 00:05:10,713:INFO:          deepchecks: Not installed
2024-04-27 00:05:10,713:INFO:             xgboost: Not installed
2024-04-27 00:05:10,714:INFO:            catboost: Not installed
2024-04-27 00:05:10,714:INFO:              kmodes: Not installed
2024-04-27 00:05:10,714:INFO:             mlxtend: Not installed
2024-04-27 00:05:10,714:INFO:       statsforecast: Not installed
2024-04-27 00:05:10,714:INFO:        tune_sklearn: Not installed
2024-04-27 00:05:10,714:INFO:                 ray: Not installed
2024-04-27 00:05:10,714:INFO:            hyperopt: Not installed
2024-04-27 00:05:10,714:INFO:              optuna: Not installed
2024-04-27 00:05:10,714:INFO:               skopt: Not installed
2024-04-27 00:05:10,714:INFO:              mlflow: Not installed
2024-04-27 00:05:10,714:INFO:              gradio: Not installed
2024-04-27 00:05:10,715:INFO:             fastapi: Not installed
2024-04-27 00:05:10,715:INFO:             uvicorn: Not installed
2024-04-27 00:05:10,715:INFO:              m2cgen: Not installed
2024-04-27 00:05:10,715:INFO:           evidently: Not installed
2024-04-27 00:05:10,715:INFO:               fugue: Not installed
2024-04-27 00:05:10,715:INFO:           streamlit: 1.33.0
2024-04-27 00:05:10,715:INFO:             prophet: Not installed
2024-04-27 00:05:10,715:INFO:None
2024-04-27 00:05:10,715:INFO:Set up data.
2024-04-27 00:05:10,723:INFO:Set up folding strategy.
2024-04-27 00:05:10,723:INFO:Set up train/test split.
2024-04-27 00:05:10,734:INFO:Set up index.
2024-04-27 00:05:10,734:INFO:Assigning column types.
2024-04-27 00:05:10,741:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-27 00:05:10,833:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-27 00:05:10,840:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 00:05:10,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:10,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-27 00:05:11,030:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 00:05:11,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,091:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-27 00:05:11,186:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 00:05:11,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,330:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 00:05:11,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,391:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-27 00:05:11,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:11,705:INFO:Preparing preprocessing pipeline...
2024-04-27 00:05:11,707:INFO:Set up label encoding.
2024-04-27 00:05:11,707:INFO:Set up simple imputation.
2024-04-27 00:05:11,789:INFO:Finished creating preprocessing pipeline.
2024-04-27 00:05:11,799:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-04-27 00:05:11,800:INFO:Creating final display dataframe.
2024-04-27 00:05:11,987:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                309
1                        Target                                            Species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 6)
5        Transformed data shape                                           (150, 6)
6   Transformed train set shape                                           (105, 6)
7    Transformed test set shape                                            (45, 6)
8              Numeric features                                                  5
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               a670
2024-04-27 00:05:12,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:12,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:12,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:12,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 00:05:12,311:INFO:setup() successfully completed in 3.17s...............
2024-04-27 00:05:12,319:INFO:Initializing compare_models()
2024-04-27 00:05:12,319:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-27 00:05:12,319:INFO:Checking exceptions
2024-04-27 00:05:12,325:INFO:Preparing display monitor
2024-04-27 00:05:12,330:INFO:Initializing Logistic Regression
2024-04-27 00:05:12,330:INFO:Total runtime is 0.0 minutes
2024-04-27 00:05:12,330:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:12,331:INFO:Initializing create_model()
2024-04-27 00:05:12,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:12,331:INFO:Checking exceptions
2024-04-27 00:05:12,331:INFO:Importing libraries
2024-04-27 00:05:12,331:INFO:Copying training dataset
2024-04-27 00:05:12,340:INFO:Defining folds
2024-04-27 00:05:12,340:INFO:Declaring metric variables
2024-04-27 00:05:12,341:INFO:Importing untrained model
2024-04-27 00:05:12,342:INFO:Logistic Regression Imported successfully
2024-04-27 00:05:12,342:INFO:Starting cross validation
2024-04-27 00:05:12,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:27,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,442:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,452:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,482:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,485:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,517:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,520:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,533:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,615:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:27,679:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:28,581:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,589:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,598:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,606:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,668:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,673:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,675:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,685:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,687:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,696:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,700:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,709:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,830:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,834:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,838:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,839:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,841:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,841:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,842:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,847:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,847:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,849:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,854:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,856:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,857:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,860:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,861:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,865:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,867:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,870:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,883:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:28,892:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,903:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:28,913:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,006:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:29,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,021:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,028:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,045:INFO:Calculating mean and std
2024-04-27 00:05:29,046:INFO:Creating metrics dataframe
2024-04-27 00:05:29,051:INFO:Uploading results into container
2024-04-27 00:05:29,052:INFO:Uploading model into container now
2024-04-27 00:05:29,053:INFO:_master_model_container: 1
2024-04-27 00:05:29,053:INFO:_display_container: 2
2024-04-27 00:05:29,053:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=309, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-27 00:05:29,053:INFO:create_model() successfully completed......................................
2024-04-27 00:05:29,270:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:29,270:INFO:Creating metrics dataframe
2024-04-27 00:05:29,275:INFO:Initializing K Neighbors Classifier
2024-04-27 00:05:29,275:INFO:Total runtime is 0.282410736878713 minutes
2024-04-27 00:05:29,275:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:29,276:INFO:Initializing create_model()
2024-04-27 00:05:29,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:29,276:INFO:Checking exceptions
2024-04-27 00:05:29,276:INFO:Importing libraries
2024-04-27 00:05:29,276:INFO:Copying training dataset
2024-04-27 00:05:29,282:INFO:Defining folds
2024-04-27 00:05:29,282:INFO:Declaring metric variables
2024-04-27 00:05:29,283:INFO:Importing untrained model
2024-04-27 00:05:29,284:INFO:K Neighbors Classifier Imported successfully
2024-04-27 00:05:29,285:INFO:Starting cross validation
2024-04-27 00:05:29,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:29,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:29,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:29,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:29,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:29,446:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:29,446:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:29,448:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:29,451:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:29,451:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:29,451:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:29,451:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:29,454:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:29,456:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,457:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,457:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,458:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,463:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:29,463:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:29,464:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,465:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,467:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,467:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,467:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,467:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,467:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,472:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,474:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,474:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,475:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,475:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,477:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,477:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,485:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,487:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,489:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:29,496:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:38,680:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:38,686:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:05:39,440:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,457:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:39,457:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,464:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,469:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:39,471:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,476:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,478:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,483:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,489:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,520:INFO:Calculating mean and std
2024-04-27 00:05:39,522:INFO:Creating metrics dataframe
2024-04-27 00:05:39,525:INFO:Uploading results into container
2024-04-27 00:05:39,525:INFO:Uploading model into container now
2024-04-27 00:05:39,526:INFO:_master_model_container: 2
2024-04-27 00:05:39,526:INFO:_display_container: 2
2024-04-27 00:05:39,526:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-27 00:05:39,526:INFO:create_model() successfully completed......................................
2024-04-27 00:05:39,767:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:39,769:INFO:Creating metrics dataframe
2024-04-27 00:05:39,779:INFO:Initializing Naive Bayes
2024-04-27 00:05:39,779:INFO:Total runtime is 0.4574745376904806 minutes
2024-04-27 00:05:39,779:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:39,780:INFO:Initializing create_model()
2024-04-27 00:05:39,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:39,780:INFO:Checking exceptions
2024-04-27 00:05:39,780:INFO:Importing libraries
2024-04-27 00:05:39,780:INFO:Copying training dataset
2024-04-27 00:05:39,789:INFO:Defining folds
2024-04-27 00:05:39,789:INFO:Declaring metric variables
2024-04-27 00:05:39,790:INFO:Importing untrained model
2024-04-27 00:05:39,790:INFO:Naive Bayes Imported successfully
2024-04-27 00:05:39,791:INFO:Starting cross validation
2024-04-27 00:05:39,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:39,877:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,881:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,883:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:39,886:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,887:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,887:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:39,892:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,893:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,894:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,895:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:39,899:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,900:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,904:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,908:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,911:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,916:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,920:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,921:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,922:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,924:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:39,924:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:39,929:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,929:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,935:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:39,939:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,939:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,941:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,941:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,944:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:39,946:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:39,949:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,951:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,952:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,952:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,953:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:39,953:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,957:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,959:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,961:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,961:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,971:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,971:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:39,972:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,974:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,974:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:39,978:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,980:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:39,994:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,006:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,020:INFO:Calculating mean and std
2024-04-27 00:05:40,022:INFO:Creating metrics dataframe
2024-04-27 00:05:40,025:INFO:Uploading results into container
2024-04-27 00:05:40,026:INFO:Uploading model into container now
2024-04-27 00:05:40,026:INFO:_master_model_container: 3
2024-04-27 00:05:40,026:INFO:_display_container: 2
2024-04-27 00:05:40,027:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-27 00:05:40,027:INFO:create_model() successfully completed......................................
2024-04-27 00:05:40,238:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:40,238:INFO:Creating metrics dataframe
2024-04-27 00:05:40,243:INFO:Initializing Decision Tree Classifier
2024-04-27 00:05:40,244:INFO:Total runtime is 0.46523054440816247 minutes
2024-04-27 00:05:40,244:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:40,244:INFO:Initializing create_model()
2024-04-27 00:05:40,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:40,246:INFO:Checking exceptions
2024-04-27 00:05:40,246:INFO:Importing libraries
2024-04-27 00:05:40,246:INFO:Copying training dataset
2024-04-27 00:05:40,252:INFO:Defining folds
2024-04-27 00:05:40,254:INFO:Declaring metric variables
2024-04-27 00:05:40,254:INFO:Importing untrained model
2024-04-27 00:05:40,255:INFO:Decision Tree Classifier Imported successfully
2024-04-27 00:05:40,255:INFO:Starting cross validation
2024-04-27 00:05:40,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:40,319:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,321:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,321:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:40,322:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:40,326:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,327:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,328:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,330:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:40,334:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,335:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,335:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,335:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,336:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,337:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:40,337:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:40,341:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,342:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,342:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,343:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,344:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,345:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,346:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:40,349:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,350:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,350:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,350:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,351:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,353:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:40,353:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,355:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:40,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,357:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,357:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,357:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,359:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:40,359:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,360:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:40,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:40,363:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,364:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,366:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,371:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,373:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,374:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,378:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,383:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,407:INFO:Calculating mean and std
2024-04-27 00:05:40,411:INFO:Creating metrics dataframe
2024-04-27 00:05:40,415:INFO:Uploading results into container
2024-04-27 00:05:40,417:INFO:Uploading model into container now
2024-04-27 00:05:40,417:INFO:_master_model_container: 4
2024-04-27 00:05:40,417:INFO:_display_container: 2
2024-04-27 00:05:40,419:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=309, splitter='best')
2024-04-27 00:05:40,419:INFO:create_model() successfully completed......................................
2024-04-27 00:05:40,626:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:40,627:INFO:Creating metrics dataframe
2024-04-27 00:05:40,633:INFO:Initializing SVM - Linear Kernel
2024-04-27 00:05:40,633:INFO:Total runtime is 0.4717169841130575 minutes
2024-04-27 00:05:40,635:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:40,635:INFO:Initializing create_model()
2024-04-27 00:05:40,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:40,635:INFO:Checking exceptions
2024-04-27 00:05:40,636:INFO:Importing libraries
2024-04-27 00:05:40,636:INFO:Copying training dataset
2024-04-27 00:05:40,642:INFO:Defining folds
2024-04-27 00:05:40,642:INFO:Declaring metric variables
2024-04-27 00:05:40,642:INFO:Importing untrained model
2024-04-27 00:05:40,643:INFO:SVM - Linear Kernel Imported successfully
2024-04-27 00:05:40,644:INFO:Starting cross validation
2024-04-27 00:05:40,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:40,742:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,745:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,746:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,752:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,754:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,755:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:40,757:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:40,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,760:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,762:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,762:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,763:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,767:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,770:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,774:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,775:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,780:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,784:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,785:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:40,788:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,789:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,789:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,790:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,792:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:40,793:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,794:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,797:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,797:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,799:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:40,801:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:40,803:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,803:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:40,805:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,806:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,808:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,808:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,812:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,813:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,816:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:40,818:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:40,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,823:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:40,840:INFO:Calculating mean and std
2024-04-27 00:05:40,841:INFO:Creating metrics dataframe
2024-04-27 00:05:40,845:INFO:Uploading results into container
2024-04-27 00:05:40,846:INFO:Uploading model into container now
2024-04-27 00:05:40,847:INFO:_master_model_container: 5
2024-04-27 00:05:40,847:INFO:_display_container: 2
2024-04-27 00:05:40,847:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=309, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-27 00:05:40,847:INFO:create_model() successfully completed......................................
2024-04-27 00:05:41,048:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:41,048:INFO:Creating metrics dataframe
2024-04-27 00:05:41,054:INFO:Initializing Ridge Classifier
2024-04-27 00:05:41,054:INFO:Total runtime is 0.47872473398844406 minutes
2024-04-27 00:05:41,055:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:41,056:INFO:Initializing create_model()
2024-04-27 00:05:41,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:41,056:INFO:Checking exceptions
2024-04-27 00:05:41,056:INFO:Importing libraries
2024-04-27 00:05:41,056:INFO:Copying training dataset
2024-04-27 00:05:41,063:INFO:Defining folds
2024-04-27 00:05:41,063:INFO:Declaring metric variables
2024-04-27 00:05:41,064:INFO:Importing untrained model
2024-04-27 00:05:41,065:INFO:Ridge Classifier Imported successfully
2024-04-27 00:05:41,065:INFO:Starting cross validation
2024-04-27 00:05:41,067:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:41,139:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,139:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,143:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,143:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,145:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,150:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,151:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,151:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,151:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,152:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,156:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,156:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,157:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,159:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,160:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,161:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,163:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,165:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,165:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,165:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,166:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,170:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,171:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,172:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,174:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,175:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,176:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,177:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,182:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,185:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,186:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,186:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,191:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,191:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:41,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,195:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,198:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,203:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,206:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,210:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:41,229:INFO:Calculating mean and std
2024-04-27 00:05:41,230:INFO:Creating metrics dataframe
2024-04-27 00:05:41,234:INFO:Uploading results into container
2024-04-27 00:05:41,234:INFO:Uploading model into container now
2024-04-27 00:05:41,235:INFO:_master_model_container: 6
2024-04-27 00:05:41,235:INFO:_display_container: 2
2024-04-27 00:05:41,236:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=309, solver='auto',
                tol=0.0001)
2024-04-27 00:05:41,236:INFO:create_model() successfully completed......................................
2024-04-27 00:05:41,434:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:41,434:INFO:Creating metrics dataframe
2024-04-27 00:05:41,439:INFO:Initializing Random Forest Classifier
2024-04-27 00:05:41,439:INFO:Total runtime is 0.485145111878713 minutes
2024-04-27 00:05:41,439:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:41,440:INFO:Initializing create_model()
2024-04-27 00:05:41,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:41,440:INFO:Checking exceptions
2024-04-27 00:05:41,440:INFO:Importing libraries
2024-04-27 00:05:41,440:INFO:Copying training dataset
2024-04-27 00:05:41,447:INFO:Defining folds
2024-04-27 00:05:41,447:INFO:Declaring metric variables
2024-04-27 00:05:41,448:INFO:Importing untrained model
2024-04-27 00:05:41,449:INFO:Random Forest Classifier Imported successfully
2024-04-27 00:05:41,450:INFO:Starting cross validation
2024-04-27 00:05:41,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:42,001:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,002:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,003:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,004:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:42,004:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:42,008:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:42,010:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,012:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,014:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,018:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,019:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,019:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:42,019:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,021:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:42,021:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,022:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:42,026:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,027:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,029:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,029:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,029:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,030:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,034:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,035:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,040:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,043:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,048:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,049:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:42,053:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,055:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,062:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,070:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,089:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,090:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:42,093:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,098:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,103:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,149:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,150:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:42,153:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,158:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,163:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,211:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:42,213:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:42,216:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,222:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,227:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,252:INFO:Calculating mean and std
2024-04-27 00:05:42,254:INFO:Creating metrics dataframe
2024-04-27 00:05:42,257:INFO:Uploading results into container
2024-04-27 00:05:42,259:INFO:Uploading model into container now
2024-04-27 00:05:42,259:INFO:_master_model_container: 7
2024-04-27 00:05:42,259:INFO:_display_container: 2
2024-04-27 00:05:42,261:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=309, verbose=0,
                       warm_start=False)
2024-04-27 00:05:42,261:INFO:create_model() successfully completed......................................
2024-04-27 00:05:42,462:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:42,462:INFO:Creating metrics dataframe
2024-04-27 00:05:42,467:INFO:Initializing Quadratic Discriminant Analysis
2024-04-27 00:05:42,468:INFO:Total runtime is 0.5022969603538514 minutes
2024-04-27 00:05:42,469:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:42,469:INFO:Initializing create_model()
2024-04-27 00:05:42,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:42,469:INFO:Checking exceptions
2024-04-27 00:05:42,469:INFO:Importing libraries
2024-04-27 00:05:42,470:INFO:Copying training dataset
2024-04-27 00:05:42,475:INFO:Defining folds
2024-04-27 00:05:42,475:INFO:Declaring metric variables
2024-04-27 00:05:42,476:INFO:Importing untrained model
2024-04-27 00:05:42,477:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-27 00:05:42,477:INFO:Starting cross validation
2024-04-27 00:05:42,478:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:42,556:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,561:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,563:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,564:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,568:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,568:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,569:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,570:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,573:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,574:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,575:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,575:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,576:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,577:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,577:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,579:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,580:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,583:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,583:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,585:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,585:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,586:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,589:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,590:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,591:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,593:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,592:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,596:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,597:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,599:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,600:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:42,604:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,605:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,610:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,610:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,612:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,613:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,619:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:42,639:INFO:Calculating mean and std
2024-04-27 00:05:42,640:INFO:Creating metrics dataframe
2024-04-27 00:05:42,643:INFO:Uploading results into container
2024-04-27 00:05:42,644:INFO:Uploading model into container now
2024-04-27 00:05:42,645:INFO:_master_model_container: 8
2024-04-27 00:05:42,645:INFO:_display_container: 2
2024-04-27 00:05:42,645:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-27 00:05:42,645:INFO:create_model() successfully completed......................................
2024-04-27 00:05:42,863:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:42,863:INFO:Creating metrics dataframe
2024-04-27 00:05:42,869:INFO:Initializing Ada Boost Classifier
2024-04-27 00:05:42,869:INFO:Total runtime is 0.508975366751353 minutes
2024-04-27 00:05:42,869:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:42,870:INFO:Initializing create_model()
2024-04-27 00:05:42,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:42,870:INFO:Checking exceptions
2024-04-27 00:05:42,870:INFO:Importing libraries
2024-04-27 00:05:42,870:INFO:Copying training dataset
2024-04-27 00:05:42,877:INFO:Defining folds
2024-04-27 00:05:42,877:INFO:Declaring metric variables
2024-04-27 00:05:42,878:INFO:Importing untrained model
2024-04-27 00:05:42,879:INFO:Ada Boost Classifier Imported successfully
2024-04-27 00:05:42,880:INFO:Starting cross validation
2024-04-27 00:05:42,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:42,923:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,929:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,937:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,938:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,947:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,950:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,954:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,957:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,963:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:42,972:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 00:05:43,236:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,241:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,249:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,257:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,259:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,263:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,265:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,269:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,271:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,277:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,279:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,286:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,291:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,295:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,303:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,312:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,323:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,326:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,327:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,329:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,329:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,332:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,334:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,335:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,338:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,339:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,341:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,342:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,343:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,346:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,348:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,349:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,349:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,354:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,359:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:43,361:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,366:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,371:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:43,387:INFO:Calculating mean and std
2024-04-27 00:05:43,388:INFO:Creating metrics dataframe
2024-04-27 00:05:43,392:INFO:Uploading results into container
2024-04-27 00:05:43,393:INFO:Uploading model into container now
2024-04-27 00:05:43,394:INFO:_master_model_container: 9
2024-04-27 00:05:43,394:INFO:_display_container: 2
2024-04-27 00:05:43,394:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=309)
2024-04-27 00:05:43,395:INFO:create_model() successfully completed......................................
2024-04-27 00:05:43,592:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:43,592:INFO:Creating metrics dataframe
2024-04-27 00:05:43,598:INFO:Initializing Gradient Boosting Classifier
2024-04-27 00:05:43,598:INFO:Total runtime is 0.5211247722307841 minutes
2024-04-27 00:05:43,599:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:43,599:INFO:Initializing create_model()
2024-04-27 00:05:43,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:43,599:INFO:Checking exceptions
2024-04-27 00:05:43,599:INFO:Importing libraries
2024-04-27 00:05:43,599:INFO:Copying training dataset
2024-04-27 00:05:43,607:INFO:Defining folds
2024-04-27 00:05:43,607:INFO:Declaring metric variables
2024-04-27 00:05:43,609:INFO:Importing untrained model
2024-04-27 00:05:43,609:INFO:Gradient Boosting Classifier Imported successfully
2024-04-27 00:05:43,610:INFO:Starting cross validation
2024-04-27 00:05:43,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:44,278:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,282:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,295:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,304:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,330:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,335:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,343:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,353:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,370:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,374:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,381:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,382:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,383:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,385:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,390:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,392:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,394:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,398:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,399:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,401:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,402:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,404:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,405:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,413:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,420:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,421:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,453:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,456:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,460:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,465:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,471:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,475:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,481:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,486:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,594:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,597:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,602:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,607:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,620:INFO:Calculating mean and std
2024-04-27 00:05:44,622:INFO:Creating metrics dataframe
2024-04-27 00:05:44,625:INFO:Uploading results into container
2024-04-27 00:05:44,626:INFO:Uploading model into container now
2024-04-27 00:05:44,627:INFO:_master_model_container: 10
2024-04-27 00:05:44,627:INFO:_display_container: 2
2024-04-27 00:05:44,628:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-27 00:05:44,628:INFO:create_model() successfully completed......................................
2024-04-27 00:05:44,836:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:44,837:INFO:Creating metrics dataframe
2024-04-27 00:05:44,842:INFO:Initializing Linear Discriminant Analysis
2024-04-27 00:05:44,842:INFO:Total runtime is 0.5418642481168111 minutes
2024-04-27 00:05:44,842:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:44,843:INFO:Initializing create_model()
2024-04-27 00:05:44,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:44,843:INFO:Checking exceptions
2024-04-27 00:05:44,843:INFO:Importing libraries
2024-04-27 00:05:44,843:INFO:Copying training dataset
2024-04-27 00:05:44,850:INFO:Defining folds
2024-04-27 00:05:44,851:INFO:Declaring metric variables
2024-04-27 00:05:44,851:INFO:Importing untrained model
2024-04-27 00:05:44,852:INFO:Linear Discriminant Analysis Imported successfully
2024-04-27 00:05:44,853:INFO:Starting cross validation
2024-04-27 00:05:44,855:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:44,918:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,921:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,923:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,925:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,931:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,931:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,934:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,935:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,936:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,939:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,939:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,940:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,941:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,942:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,943:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,948:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,949:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,950:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,955:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,958:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,959:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,963:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,964:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,970:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,972:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,972:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,973:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,978:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,979:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,980:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,981:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,981:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,986:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,987:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,989:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 00:05:44,991:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:44,993:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,001:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,007:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,020:INFO:Calculating mean and std
2024-04-27 00:05:45,021:INFO:Creating metrics dataframe
2024-04-27 00:05:45,025:INFO:Uploading results into container
2024-04-27 00:05:45,025:INFO:Uploading model into container now
2024-04-27 00:05:45,026:INFO:_master_model_container: 11
2024-04-27 00:05:45,026:INFO:_display_container: 2
2024-04-27 00:05:45,026:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-27 00:05:45,026:INFO:create_model() successfully completed......................................
2024-04-27 00:05:45,233:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:45,234:INFO:Creating metrics dataframe
2024-04-27 00:05:45,239:INFO:Initializing Extra Trees Classifier
2024-04-27 00:05:45,239:INFO:Total runtime is 0.5484715104103088 minutes
2024-04-27 00:05:45,239:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:45,240:INFO:Initializing create_model()
2024-04-27 00:05:45,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:45,240:INFO:Checking exceptions
2024-04-27 00:05:45,240:INFO:Importing libraries
2024-04-27 00:05:45,240:INFO:Copying training dataset
2024-04-27 00:05:45,246:INFO:Defining folds
2024-04-27 00:05:45,246:INFO:Declaring metric variables
2024-04-27 00:05:45,246:INFO:Importing untrained model
2024-04-27 00:05:45,247:INFO:Extra Trees Classifier Imported successfully
2024-04-27 00:05:45,248:INFO:Starting cross validation
2024-04-27 00:05:45,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:45,711:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,715:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:45,715:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,717:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:45,720:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,721:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,727:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,729:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,738:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,738:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,741:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,742:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,742:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,745:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:45,750:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,750:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,750:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,757:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,757:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,764:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,765:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,767:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,820:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,820:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:45,823:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:45,823:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:45,824:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:45,825:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,825:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,826:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,826:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,830:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,830:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,832:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,832:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,837:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,837:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,837:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,839:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,882:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:45,884:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:45,886:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,892:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,898:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:45,922:INFO:Calculating mean and std
2024-04-27 00:05:45,924:INFO:Creating metrics dataframe
2024-04-27 00:05:45,927:INFO:Uploading results into container
2024-04-27 00:05:45,927:INFO:Uploading model into container now
2024-04-27 00:05:45,928:INFO:_master_model_container: 12
2024-04-27 00:05:45,928:INFO:_display_container: 2
2024-04-27 00:05:45,929:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=309, verbose=0,
                     warm_start=False)
2024-04-27 00:05:45,929:INFO:create_model() successfully completed......................................
2024-04-27 00:05:46,129:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:46,129:INFO:Creating metrics dataframe
2024-04-27 00:05:46,135:INFO:Initializing Light Gradient Boosting Machine
2024-04-27 00:05:46,136:INFO:Total runtime is 0.5634268045425415 minutes
2024-04-27 00:05:46,137:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:46,137:INFO:Initializing create_model()
2024-04-27 00:05:46,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:46,137:INFO:Checking exceptions
2024-04-27 00:05:46,137:INFO:Importing libraries
2024-04-27 00:05:46,137:INFO:Copying training dataset
2024-04-27 00:05:46,143:INFO:Defining folds
2024-04-27 00:05:46,143:INFO:Declaring metric variables
2024-04-27 00:05:46,144:INFO:Importing untrained model
2024-04-27 00:05:46,145:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-27 00:05:46,145:INFO:Starting cross validation
2024-04-27 00:05:46,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:48,441:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:48,444:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:48,452:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,461:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,471:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,590:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:48,592:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:48,598:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,610:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,624:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,626:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:48,629:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:48,635:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,643:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,656:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,696:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:48,699:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:48,706:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,719:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,732:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,773:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:48,775:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:48,780:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,782:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:48,788:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:48,795:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,799:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,807:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,815:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,832:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,843:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:48,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:48,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,860:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:48,915:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,009:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,010:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:49,014:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,028:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,029:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,030:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:49,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,045:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,047:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,047:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:49,055:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,057:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,066:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,074:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,103:INFO:Calculating mean and std
2024-04-27 00:05:49,105:INFO:Creating metrics dataframe
2024-04-27 00:05:49,110:INFO:Uploading results into container
2024-04-27 00:05:49,111:INFO:Uploading model into container now
2024-04-27 00:05:49,112:INFO:_master_model_container: 13
2024-04-27 00:05:49,113:INFO:_display_container: 2
2024-04-27 00:05:49,114:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-27 00:05:49,114:INFO:create_model() successfully completed......................................
2024-04-27 00:05:49,314:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:49,314:INFO:Creating metrics dataframe
2024-04-27 00:05:49,319:INFO:Initializing Dummy Classifier
2024-04-27 00:05:49,319:INFO:Total runtime is 0.6164732575416565 minutes
2024-04-27 00:05:49,320:INFO:SubProcess create_model() called ==================================
2024-04-27 00:05:49,320:INFO:Initializing create_model()
2024-04-27 00:05:49,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001459DAC3D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:49,321:INFO:Checking exceptions
2024-04-27 00:05:49,321:INFO:Importing libraries
2024-04-27 00:05:49,321:INFO:Copying training dataset
2024-04-27 00:05:49,327:INFO:Defining folds
2024-04-27 00:05:49,328:INFO:Declaring metric variables
2024-04-27 00:05:49,329:INFO:Importing untrained model
2024-04-27 00:05:49,330:INFO:Dummy Classifier Imported successfully
2024-04-27 00:05:49,331:INFO:Starting cross validation
2024-04-27 00:05:49,334:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 00:05:49,385:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,387:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:49,391:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,391:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,391:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,394:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:49,394:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:49,397:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,397:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,399:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,399:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:49,403:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,404:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,405:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,405:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 00:05:49,406:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,407:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,409:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,409:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,409:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,409:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,409:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,411:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,411:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:49,411:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:49,411:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,413:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,414:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,415:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,415:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,416:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,416:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:49,417:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,419:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,420:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,420:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,420:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,422:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:49,423:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,424:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,424:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,426:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,426:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 00:05:49,427:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,427:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,429:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,429:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 00:05:49,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,432:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,433:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,433:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,434:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,435:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,437:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,441:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,442:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,443:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 00:05:49,446:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 00:05:49,461:INFO:Calculating mean and std
2024-04-27 00:05:49,462:INFO:Creating metrics dataframe
2024-04-27 00:05:49,465:INFO:Uploading results into container
2024-04-27 00:05:49,466:INFO:Uploading model into container now
2024-04-27 00:05:49,467:INFO:_master_model_container: 14
2024-04-27 00:05:49,467:INFO:_display_container: 2
2024-04-27 00:05:49,468:INFO:DummyClassifier(constant=None, random_state=309, strategy='prior')
2024-04-27 00:05:49,468:INFO:create_model() successfully completed......................................
2024-04-27 00:05:49,668:INFO:SubProcess create_model() end ==================================
2024-04-27 00:05:49,669:INFO:Creating metrics dataframe
2024-04-27 00:05:49,680:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-27 00:05:49,684:INFO:Initializing create_model()
2024-04-27 00:05:49,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001459ACFF880>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=309, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 00:05:49,685:INFO:Checking exceptions
2024-04-27 00:05:49,685:INFO:Importing libraries
2024-04-27 00:05:49,686:INFO:Copying training dataset
2024-04-27 00:05:49,691:INFO:Defining folds
2024-04-27 00:05:49,691:INFO:Declaring metric variables
2024-04-27 00:05:49,691:INFO:Importing untrained model
2024-04-27 00:05:49,692:INFO:Declaring custom model
2024-04-27 00:05:49,693:INFO:Random Forest Classifier Imported successfully
2024-04-27 00:05:49,695:INFO:Cross validation set to False
2024-04-27 00:05:49,695:INFO:Fitting Model
2024-04-27 00:05:50,018:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=309, verbose=0,
                       warm_start=False)
2024-04-27 00:05:50,018:INFO:create_model() successfully completed......................................
2024-04-27 00:05:50,242:INFO:_master_model_container: 14
2024-04-27 00:05:50,243:INFO:_display_container: 2
2024-04-27 00:05:50,243:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=309, verbose=0,
                       warm_start=False)
2024-04-27 00:05:50,243:INFO:compare_models() successfully completed......................................
2024-04-27 00:05:50,275:INFO:Initializing save_model()
2024-04-27 00:05:50,275:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=309, verbose=0,
                       warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-27 00:05:50,276:INFO:Adding model into prep_pipe
2024-04-27 00:05:50,424:INFO:best_model.pkl saved in current working directory
2024-04-27 00:05:50,434:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=309, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-04-27 00:05:50,434:INFO:save_model() successfully completed......................................
2024-04-27 00:09:51,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:09:51,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:09:51,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:09:51,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:09:53,605:INFO:Initializing load_model()
2024-04-27 00:09:53,605:INFO:load_model(model_name=train_model_kiran, platform=None, authentication=None, verbose=True)
2024-04-27 00:10:28,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:10:28,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:10:28,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:10:28,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:10:31,213:INFO:Initializing load_model()
2024-04-27 00:10:31,213:INFO:load_model(model_name=trained_model_kiran, platform=None, authentication=None, verbose=True)
2024-04-27 00:10:32,256:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 00:11:58,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:11:58,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:11:58,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:11:58,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 00:12:01,002:INFO:Initializing load_model()
2024-04-27 00:12:01,003:INFO:load_model(model_name=trained_model_kiran, platform=None, authentication=None, verbose=True)
2024-04-27 00:12:02,099:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:15:20,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:15:20,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:15:20,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:15:20,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:23:28,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:23:28,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:23:28,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:23:28,734:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:34:33,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:34:33,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:34:33,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:34:33,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 09:36:46,628:INFO:PyCaret ClassificationExperiment
2024-04-27 09:36:46,628:INFO:Logging name: clf-default-name
2024-04-27 09:36:46,628:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-27 09:36:46,628:INFO:version 3.3.1
2024-04-27 09:36:46,628:INFO:Initializing setup()
2024-04-27 09:36:46,628:INFO:self.USI: dd30
2024-04-27 09:36:46,628:INFO:self._variable_keys: {'target_param', 'logging_param', 'data', 'y', 'log_plots_param', 'idx', 'y_train', 'X_train', 'memory', '_available_plots', 'fold_shuffle_param', 'exp_id', 'USI', 'X', 'y_test', 'is_multiclass', 'X_test', 'fix_imbalance', 'seed', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_name_log', 'fold_generator', 'fold_groups_param', 'pipeline', '_ml_usecase', 'html_param', 'gpu_param'}
2024-04-27 09:36:46,628:INFO:Checking environment
2024-04-27 09:36:46,628:INFO:python_version: 3.10.9
2024-04-27 09:36:46,628:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-27 09:36:46,628:INFO:machine: AMD64
2024-04-27 09:36:46,635:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-27 09:36:46,636:INFO:Memory: svmem(total=16541904896, available=4970086400, percent=70.0, used=11571818496, free=4970086400)
2024-04-27 09:36:46,636:INFO:Physical Core: 6
2024-04-27 09:36:46,636:INFO:Logical Core: 12
2024-04-27 09:36:46,636:INFO:Checking libraries
2024-04-27 09:36:46,636:INFO:System:
2024-04-27 09:36:46,636:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-27 09:36:46,636:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-27 09:36:46,636:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-27 09:36:46,636:INFO:PyCaret required dependencies:
2024-04-27 09:36:47,003:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:47,218:INFO:                 pip: 22.3.1
2024-04-27 09:36:47,218:INFO:          setuptools: 65.6.3
2024-04-27 09:36:47,218:INFO:             pycaret: 3.3.1
2024-04-27 09:36:47,218:INFO:             IPython: 8.10.0
2024-04-27 09:36:47,218:INFO:          ipywidgets: 7.6.5
2024-04-27 09:36:47,218:INFO:                tqdm: 4.64.1
2024-04-27 09:36:47,218:INFO:               numpy: 1.23.5
2024-04-27 09:36:47,218:INFO:              pandas: 2.2.2
2024-04-27 09:36:47,218:INFO:              jinja2: 3.1.2
2024-04-27 09:36:47,218:INFO:               scipy: 1.10.0
2024-04-27 09:36:47,218:INFO:              joblib: 1.3.2
2024-04-27 09:36:47,218:INFO:             sklearn: 1.4.2
2024-04-27 09:36:47,218:INFO:                pyod: 1.1.3
2024-04-27 09:36:47,218:INFO:            imblearn: 0.10.1
2024-04-27 09:36:47,219:INFO:   category_encoders: 2.6.3
2024-04-27 09:36:47,219:INFO:            lightgbm: 4.3.0
2024-04-27 09:36:47,219:INFO:               numba: 0.56.4
2024-04-27 09:36:47,219:INFO:            requests: 2.28.1
2024-04-27 09:36:47,219:INFO:          matplotlib: 3.7.0
2024-04-27 09:36:47,219:INFO:          scikitplot: 0.3.7
2024-04-27 09:36:47,219:INFO:         yellowbrick: 1.5
2024-04-27 09:36:47,219:INFO:              plotly: 5.21.0
2024-04-27 09:36:47,219:INFO:    plotly-resampler: Not installed
2024-04-27 09:36:47,219:INFO:             kaleido: 0.2.1
2024-04-27 09:36:47,219:INFO:           schemdraw: 0.15
2024-04-27 09:36:47,219:INFO:         statsmodels: 0.13.5
2024-04-27 09:36:47,219:INFO:              sktime: 0.26.0
2024-04-27 09:36:47,219:INFO:               tbats: 1.1.3
2024-04-27 09:36:47,220:INFO:            pmdarima: 2.0.4
2024-04-27 09:36:47,220:INFO:              psutil: 5.9.0
2024-04-27 09:36:47,220:INFO:          markupsafe: 2.1.1
2024-04-27 09:36:47,220:INFO:             pickle5: Not installed
2024-04-27 09:36:47,220:INFO:         cloudpickle: 2.0.0
2024-04-27 09:36:47,220:INFO:         deprecation: 2.1.0
2024-04-27 09:36:47,220:INFO:              xxhash: 3.4.1
2024-04-27 09:36:47,220:INFO:           wurlitzer: Not installed
2024-04-27 09:36:47,220:INFO:PyCaret optional dependencies:
2024-04-27 09:36:47,230:INFO:                shap: Not installed
2024-04-27 09:36:47,230:INFO:           interpret: Not installed
2024-04-27 09:36:47,231:INFO:                umap: Not installed
2024-04-27 09:36:47,231:INFO:     ydata_profiling: 4.7.0
2024-04-27 09:36:47,231:INFO:  explainerdashboard: Not installed
2024-04-27 09:36:47,231:INFO:             autoviz: Not installed
2024-04-27 09:36:47,231:INFO:           fairlearn: Not installed
2024-04-27 09:36:47,231:INFO:          deepchecks: Not installed
2024-04-27 09:36:47,231:INFO:             xgboost: Not installed
2024-04-27 09:36:47,231:INFO:            catboost: Not installed
2024-04-27 09:36:47,231:INFO:              kmodes: Not installed
2024-04-27 09:36:47,231:INFO:             mlxtend: Not installed
2024-04-27 09:36:47,231:INFO:       statsforecast: Not installed
2024-04-27 09:36:47,231:INFO:        tune_sklearn: Not installed
2024-04-27 09:36:47,231:INFO:                 ray: Not installed
2024-04-27 09:36:47,231:INFO:            hyperopt: Not installed
2024-04-27 09:36:47,231:INFO:              optuna: Not installed
2024-04-27 09:36:47,231:INFO:               skopt: Not installed
2024-04-27 09:36:47,231:INFO:              mlflow: Not installed
2024-04-27 09:36:47,231:INFO:              gradio: Not installed
2024-04-27 09:36:47,231:INFO:             fastapi: Not installed
2024-04-27 09:36:47,231:INFO:             uvicorn: Not installed
2024-04-27 09:36:47,231:INFO:              m2cgen: Not installed
2024-04-27 09:36:47,231:INFO:           evidently: Not installed
2024-04-27 09:36:47,231:INFO:               fugue: Not installed
2024-04-27 09:36:47,231:INFO:           streamlit: 1.33.0
2024-04-27 09:36:47,231:INFO:             prophet: Not installed
2024-04-27 09:36:47,231:INFO:None
2024-04-27 09:36:47,231:INFO:Set up data.
2024-04-27 09:36:47,235:INFO:Set up folding strategy.
2024-04-27 09:36:47,235:INFO:Set up train/test split.
2024-04-27 09:36:47,239:INFO:Set up index.
2024-04-27 09:36:47,239:INFO:Assigning column types.
2024-04-27 09:36:47,241:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-27 09:36:47,278:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-27 09:36:47,282:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 09:36:47,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,349:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-27 09:36:47,349:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 09:36:47,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,374:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-27 09:36:47,411:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 09:36:47,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,474:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 09:36:47,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,499:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-27 09:36:47,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,619:INFO:Preparing preprocessing pipeline...
2024-04-27 09:36:47,620:INFO:Set up label encoding.
2024-04-27 09:36:47,620:INFO:Set up simple imputation.
2024-04-27 09:36:47,643:INFO:Finished creating preprocessing pipeline.
2024-04-27 09:36:47,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Weight', 'Length1', 'Length2',
                                             'Length3', 'Height', 'Width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-04-27 09:36:47,649:INFO:Creating final display dataframe.
2024-04-27 09:36:47,709:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               5020
1                        Target                                            Species
2                   Target type                                         Multiclass
3                Target mapping  Bream: 0, Parkki: 1, Perch: 2, Pike: 3, Roach:...
4           Original data shape                                           (159, 7)
5        Transformed data shape                                           (159, 7)
6   Transformed train set shape                                           (111, 7)
7    Transformed test set shape                                            (48, 7)
8              Numeric features                                                  6
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               dd30
2024-04-27 09:36:47,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 09:36:47,841:INFO:setup() successfully completed in 1.22s...............
2024-04-27 09:36:47,844:INFO:Initializing compare_models()
2024-04-27 09:36:47,844:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-27 09:36:47,844:INFO:Checking exceptions
2024-04-27 09:36:47,846:INFO:Preparing display monitor
2024-04-27 09:36:47,849:INFO:Initializing Logistic Regression
2024-04-27 09:36:47,849:INFO:Total runtime is 0.0 minutes
2024-04-27 09:36:47,849:INFO:SubProcess create_model() called ==================================
2024-04-27 09:36:47,850:INFO:Initializing create_model()
2024-04-27 09:36:47,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:36:47,850:INFO:Checking exceptions
2024-04-27 09:36:47,850:INFO:Importing libraries
2024-04-27 09:36:47,850:INFO:Copying training dataset
2024-04-27 09:36:47,853:INFO:Defining folds
2024-04-27 09:36:47,853:INFO:Declaring metric variables
2024-04-27 09:36:47,853:INFO:Importing untrained model
2024-04-27 09:36:47,853:INFO:Logistic Regression Imported successfully
2024-04-27 09:36:47,853:INFO:Starting cross validation
2024-04-27 09:36:47,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:36:47,866:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:36:54,104:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,118:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,119:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,125:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,127:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,128:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,129:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,132:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,134:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,143:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:54,807:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,822:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,825:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,826:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,828:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,831:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,832:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,834:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,836:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,836:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,837:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,837:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,837:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,839:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,842:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,842:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,842:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,842:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,843:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,843:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-27 09:36:54,844:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,847:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,847:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,847:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,847:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,849:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,849:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,851:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,851:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,851:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,852:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,852:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,852:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,853:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,854:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,854:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,854:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,854:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,856:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,857:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,857:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,858:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,859:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:36:54,859:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,860:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,861:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,861:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,862:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,865:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

.capitalize()} is", len(result))

2024-04-27 09:36:54,865:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,867:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

.capitalize()} is", len(result))

2024-04-27 09:36:54,869:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,869:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,871:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,871:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,873:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,873:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:54,875:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:54,882:INFO:Calculating mean and std
2024-04-27 09:36:54,884:INFO:Creating metrics dataframe
2024-04-27 09:36:54,886:INFO:Uploading results into container
2024-04-27 09:36:54,887:INFO:Uploading model into container now
2024-04-27 09:36:54,888:INFO:_master_model_container: 1
2024-04-27 09:36:54,888:INFO:_display_container: 2
2024-04-27 09:36:54,888:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-27 09:36:54,888:INFO:create_model() successfully completed......................................
2024-04-27 09:36:55,110:INFO:SubProcess create_model() end ==================================
2024-04-27 09:36:55,110:INFO:Creating metrics dataframe
2024-04-27 09:36:55,112:INFO:Initializing K Neighbors Classifier
2024-04-27 09:36:55,112:INFO:Total runtime is 0.12104902664820354 minutes
2024-04-27 09:36:55,112:INFO:SubProcess create_model() called ==================================
2024-04-27 09:36:55,112:INFO:Initializing create_model()
2024-04-27 09:36:55,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:36:55,113:INFO:Checking exceptions
2024-04-27 09:36:55,113:INFO:Importing libraries
2024-04-27 09:36:55,113:INFO:Copying training dataset
2024-04-27 09:36:55,115:INFO:Defining folds
2024-04-27 09:36:55,115:INFO:Declaring metric variables
2024-04-27 09:36:55,115:INFO:Importing untrained model
2024-04-27 09:36:55,116:INFO:K Neighbors Classifier Imported successfully
2024-04-27 09:36:55,116:INFO:Starting cross validation
2024-04-27 09:36:55,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:36:55,119:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:36:55,186:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:55,186:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:55,187:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:55,187:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:55,187:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:55,187:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:55,187:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:55,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:55,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:55,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:55,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:55,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:55,195:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:55,195:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:55,198:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,198:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,198:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,198:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,198:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,198:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,199:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,199:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,199:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,200:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,201:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,202:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,202:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,202:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,202:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,202:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,202:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:55,202:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,203:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,203:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,203:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,204:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,204:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,204:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,204:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,205:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,206:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,206:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,206:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,206:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,206:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,207:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,207:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,209:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,209:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,209:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:55,212:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,213:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,216:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,217:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:55,219:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:55,220:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,099:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:59,099:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 09:36:59,488:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,488:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,494:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 12)

  warnings.warn(

2024-04-27 09:36:59,495:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,497:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,498:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,499:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,499:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,501:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,501:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,502:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,503:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,504:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,505:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,507:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,514:INFO:Calculating mean and std
2024-04-27 09:36:59,515:INFO:Creating metrics dataframe
2024-04-27 09:36:59,516:INFO:Uploading results into container
2024-04-27 09:36:59,517:INFO:Uploading model into container now
2024-04-27 09:36:59,517:INFO:_master_model_container: 2
2024-04-27 09:36:59,517:INFO:_display_container: 2
2024-04-27 09:36:59,517:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-27 09:36:59,517:INFO:create_model() successfully completed......................................
2024-04-27 09:36:59,655:INFO:SubProcess create_model() end ==================================
2024-04-27 09:36:59,655:INFO:Creating metrics dataframe
2024-04-27 09:36:59,658:INFO:Initializing Naive Bayes
2024-04-27 09:36:59,658:INFO:Total runtime is 0.19681894381841025 minutes
2024-04-27 09:36:59,658:INFO:SubProcess create_model() called ==================================
2024-04-27 09:36:59,658:INFO:Initializing create_model()
2024-04-27 09:36:59,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:36:59,658:INFO:Checking exceptions
2024-04-27 09:36:59,658:INFO:Importing libraries
2024-04-27 09:36:59,658:INFO:Copying training dataset
2024-04-27 09:36:59,661:INFO:Defining folds
2024-04-27 09:36:59,661:INFO:Declaring metric variables
2024-04-27 09:36:59,661:INFO:Importing untrained model
2024-04-27 09:36:59,661:INFO:Naive Bayes Imported successfully
2024-04-27 09:36:59,662:INFO:Starting cross validation
2024-04-27 09:36:59,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:36:59,665:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:36:59,694:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,697:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,699:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,700:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,700:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 12)

  warnings.warn(

2024-04-27 09:36:59,701:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,702:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,702:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,703:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,703:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,704:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,704:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,704:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,705:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,706:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,706:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,706:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,706:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,706:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,707:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,707:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,707:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,708:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,708:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,709:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,709:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,709:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,709:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,710:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,710:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,711:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,711:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,711:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,711:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,712:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,712:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,712:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,712:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,713:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,713:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,713:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,713:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,714:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,714:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,714:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,714:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,715:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,715:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,715:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,715:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,716:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,716:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,717:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,717:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,718:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,718:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,719:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,719:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,719:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,720:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,721:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,721:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,722:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,722:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,722:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,724:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,724:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,725:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,727:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,732:INFO:Calculating mean and std
2024-04-27 09:36:59,732:INFO:Creating metrics dataframe
2024-04-27 09:36:59,734:INFO:Uploading results into container
2024-04-27 09:36:59,734:INFO:Uploading model into container now
2024-04-27 09:36:59,735:INFO:_master_model_container: 3
2024-04-27 09:36:59,735:INFO:_display_container: 2
2024-04-27 09:36:59,735:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-27 09:36:59,735:INFO:create_model() successfully completed......................................
2024-04-27 09:36:59,857:INFO:SubProcess create_model() end ==================================
2024-04-27 09:36:59,857:INFO:Creating metrics dataframe
2024-04-27 09:36:59,860:INFO:Initializing Decision Tree Classifier
2024-04-27 09:36:59,860:INFO:Total runtime is 0.2001860499382019 minutes
2024-04-27 09:36:59,860:INFO:SubProcess create_model() called ==================================
2024-04-27 09:36:59,860:INFO:Initializing create_model()
2024-04-27 09:36:59,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:36:59,860:INFO:Checking exceptions
2024-04-27 09:36:59,860:INFO:Importing libraries
2024-04-27 09:36:59,860:INFO:Copying training dataset
2024-04-27 09:36:59,863:INFO:Defining folds
2024-04-27 09:36:59,863:INFO:Declaring metric variables
2024-04-27 09:36:59,863:INFO:Importing untrained model
2024-04-27 09:36:59,863:INFO:Decision Tree Classifier Imported successfully
2024-04-27 09:36:59,864:INFO:Starting cross validation
2024-04-27 09:36:59,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:36:59,867:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:36:59,895:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,896:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 12)

  warnings.warn(

2024-04-27 09:36:59,897:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,898:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,898:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,899:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,900:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,900:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,900:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,901:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,902:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,902:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,902:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,903:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,903:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,904:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,904:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,904:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,904:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,904:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,905:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,906:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,906:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,906:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,906:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,906:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,906:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,907:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,907:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,907:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,908:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,908:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,908:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,908:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,909:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,909:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,910:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,910:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,910:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,911:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,911:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,912:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,912:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,912:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,912:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,913:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,913:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,913:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,913:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,914:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,914:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,914:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,914:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,915:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,916:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,916:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,917:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:36:59,918:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:36:59,918:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,919:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,920:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,920:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,921:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,921:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,922:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,922:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,923:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,924:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,925:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:36:59,926:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:36:59,936:INFO:Calculating mean and std
2024-04-27 09:36:59,937:INFO:Creating metrics dataframe
2024-04-27 09:36:59,938:INFO:Uploading results into container
2024-04-27 09:36:59,938:INFO:Uploading model into container now
2024-04-27 09:36:59,939:INFO:_master_model_container: 4
2024-04-27 09:36:59,939:INFO:_display_container: 2
2024-04-27 09:36:59,939:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5020, splitter='best')
2024-04-27 09:36:59,939:INFO:create_model() successfully completed......................................
2024-04-27 09:37:00,065:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:00,065:INFO:Creating metrics dataframe
2024-04-27 09:37:00,067:INFO:Initializing SVM - Linear Kernel
2024-04-27 09:37:00,067:INFO:Total runtime is 0.20363593101501465 minutes
2024-04-27 09:37:00,068:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:00,068:INFO:Initializing create_model()
2024-04-27 09:37:00,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:00,068:INFO:Checking exceptions
2024-04-27 09:37:00,068:INFO:Importing libraries
2024-04-27 09:37:00,068:INFO:Copying training dataset
2024-04-27 09:37:00,071:INFO:Defining folds
2024-04-27 09:37:00,071:INFO:Declaring metric variables
2024-04-27 09:37:00,071:INFO:Importing untrained model
2024-04-27 09:37:00,071:INFO:SVM - Linear Kernel Imported successfully
2024-04-27 09:37:00,072:INFO:Starting cross validation
2024-04-27 09:37:00,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:00,074:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:00,136:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,136:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,137:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,137:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,137:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,137:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,138:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,138:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,138:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,138:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,139:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,140:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,140:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,140:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,141:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,141:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,142:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,142:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,142:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,143:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,144:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,144:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,144:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,144:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,144:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,145:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,145:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,145:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,146:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,146:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,146:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,147:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,148:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,148:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,148:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,148:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,149:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,150:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,150:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,150:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,151:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,151:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,152:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,152:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,153:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,153:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,155:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,156:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,156:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,157:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,157:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,157:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,158:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,158:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,159:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,159:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,160:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,169:INFO:Calculating mean and std
2024-04-27 09:37:00,170:INFO:Creating metrics dataframe
2024-04-27 09:37:00,171:INFO:Uploading results into container
2024-04-27 09:37:00,172:INFO:Uploading model into container now
2024-04-27 09:37:00,172:INFO:_master_model_container: 5
2024-04-27 09:37:00,172:INFO:_display_container: 2
2024-04-27 09:37:00,172:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-27 09:37:00,173:INFO:create_model() successfully completed......................................
2024-04-27 09:37:00,298:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:00,298:INFO:Creating metrics dataframe
2024-04-27 09:37:00,301:INFO:Initializing Ridge Classifier
2024-04-27 09:37:00,301:INFO:Total runtime is 0.20752832889556885 minutes
2024-04-27 09:37:00,301:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:00,301:INFO:Initializing create_model()
2024-04-27 09:37:00,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:00,301:INFO:Checking exceptions
2024-04-27 09:37:00,302:INFO:Importing libraries
2024-04-27 09:37:00,302:INFO:Copying training dataset
2024-04-27 09:37:00,304:INFO:Defining folds
2024-04-27 09:37:00,304:INFO:Declaring metric variables
2024-04-27 09:37:00,304:INFO:Importing untrained model
2024-04-27 09:37:00,304:INFO:Ridge Classifier Imported successfully
2024-04-27 09:37:00,305:INFO:Starting cross validation
2024-04-27 09:37:00,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:00,307:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:00,354:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,354:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,355:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,355:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,357:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,358:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,358:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,358:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,358:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,358:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,359:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,360:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,360:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,360:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,361:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,363:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,363:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,364:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,364:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,364:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,364:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:00,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,366:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,369:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

fier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,369:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,369:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,370:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,370:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,371:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,372:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,372:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,373:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,389:INFO:Calculating mean and std
2024-04-27 09:37:00,389:INFO:Creating metrics dataframe
2024-04-27 09:37:00,391:INFO:Uploading results into container
2024-04-27 09:37:00,391:INFO:Uploading model into container now
2024-04-27 09:37:00,392:INFO:_master_model_container: 6
2024-04-27 09:37:00,392:INFO:_display_container: 2
2024-04-27 09:37:00,392:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5020, solver='auto',
                tol=0.0001)
2024-04-27 09:37:00,392:INFO:create_model() successfully completed......................................
2024-04-27 09:37:00,516:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:00,516:INFO:Creating metrics dataframe
2024-04-27 09:37:00,518:INFO:Initializing Random Forest Classifier
2024-04-27 09:37:00,518:INFO:Total runtime is 0.21115355491638185 minutes
2024-04-27 09:37:00,519:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:00,519:INFO:Initializing create_model()
2024-04-27 09:37:00,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:00,519:INFO:Checking exceptions
2024-04-27 09:37:00,519:INFO:Importing libraries
2024-04-27 09:37:00,519:INFO:Copying training dataset
2024-04-27 09:37:00,522:INFO:Defining folds
2024-04-27 09:37:00,522:INFO:Declaring metric variables
2024-04-27 09:37:00,522:INFO:Importing untrained model
2024-04-27 09:37:00,522:INFO:Random Forest Classifier Imported successfully
2024-04-27 09:37:00,523:INFO:Starting cross validation
2024-04-27 09:37:00,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:00,525:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:00,756:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,758:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 12)

  warnings.warn(

2024-04-27 09:37:00,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,762:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,764:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,765:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,768:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,771:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,772:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,773:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,773:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,774:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,775:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,777:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,777:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,780:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,780:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,781:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,781:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,784:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,784:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,785:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,785:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,786:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,788:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,788:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,788:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,788:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,789:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,790:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,790:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,790:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,792:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,794:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,794:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,794:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,795:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,795:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,797:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,797:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,798:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,798:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,800:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:00,803:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,803:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:00,804:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,805:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,805:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,806:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,807:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,808:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,808:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,809:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,809:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,810:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:00,810:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,811:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:00,828:INFO:Calculating mean and std
2024-04-27 09:37:00,829:INFO:Creating metrics dataframe
2024-04-27 09:37:00,831:INFO:Uploading results into container
2024-04-27 09:37:00,831:INFO:Uploading model into container now
2024-04-27 09:37:00,832:INFO:_master_model_container: 7
2024-04-27 09:37:00,832:INFO:_display_container: 2
2024-04-27 09:37:00,832:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5020, verbose=0,
                       warm_start=False)
2024-04-27 09:37:00,832:INFO:create_model() successfully completed......................................
2024-04-27 09:37:00,954:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:00,954:INFO:Creating metrics dataframe
2024-04-27 09:37:00,956:INFO:Initializing Quadratic Discriminant Analysis
2024-04-27 09:37:00,956:INFO:Total runtime is 0.21845306158065797 minutes
2024-04-27 09:37:00,956:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:00,957:INFO:Initializing create_model()
2024-04-27 09:37:00,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:00,957:INFO:Checking exceptions
2024-04-27 09:37:00,957:INFO:Importing libraries
2024-04-27 09:37:00,957:INFO:Copying training dataset
2024-04-27 09:37:00,959:INFO:Defining folds
2024-04-27 09:37:00,959:INFO:Declaring metric variables
2024-04-27 09:37:00,959:INFO:Importing untrained model
2024-04-27 09:37:00,960:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-27 09:37:00,960:INFO:Starting cross validation
2024-04-27 09:37:00,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:00,963:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:00,993:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:00,994:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:00,994:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:00,994:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:00,998:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:00,999:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:01,001:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:01,004:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,005:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:01,005:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,005:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,005:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,005:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,007:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,007:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,007:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,007:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-27 09:37:01,007:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,008:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,008:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,009:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,009:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,009:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,009:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,009:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,011:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,011:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,011:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,011:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,011:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,011:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,012:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,012:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,014:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,015:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,015:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,015:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,015:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,015:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,015:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,016:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,016:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,016:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,016:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,017:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,017:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,017:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,017:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,017:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,018:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,018:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,018:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,019:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,020:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,021:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,021:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,021:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,022:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,022:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,023:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,024:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,024:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,025:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,026:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,028:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,033:INFO:Calculating mean and std
2024-04-27 09:37:01,034:INFO:Creating metrics dataframe
2024-04-27 09:37:01,035:INFO:Uploading results into container
2024-04-27 09:37:01,036:INFO:Uploading model into container now
2024-04-27 09:37:01,036:INFO:_master_model_container: 8
2024-04-27 09:37:01,036:INFO:_display_container: 2
2024-04-27 09:37:01,036:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-27 09:37:01,036:INFO:create_model() successfully completed......................................
2024-04-27 09:37:01,156:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:01,157:INFO:Creating metrics dataframe
2024-04-27 09:37:01,159:INFO:Initializing Ada Boost Classifier
2024-04-27 09:37:01,159:INFO:Total runtime is 0.22182875871658325 minutes
2024-04-27 09:37:01,159:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:01,159:INFO:Initializing create_model()
2024-04-27 09:37:01,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:01,159:INFO:Checking exceptions
2024-04-27 09:37:01,159:INFO:Importing libraries
2024-04-27 09:37:01,160:INFO:Copying training dataset
2024-04-27 09:37:01,162:INFO:Defining folds
2024-04-27 09:37:01,162:INFO:Declaring metric variables
2024-04-27 09:37:01,162:INFO:Importing untrained model
2024-04-27 09:37:01,163:INFO:Ada Boost Classifier Imported successfully
2024-04-27 09:37:01,163:INFO:Starting cross validation
2024-04-27 09:37:01,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:01,166:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:01,184:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,186:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,189:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,190:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,193:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,196:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,199:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,201:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,204:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,205:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 09:37:01,304:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,306:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,308:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,311:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,312:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,314:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,316:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,318:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,318:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,320:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,320:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,321:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,321:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,322:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,322:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,323:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,323:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,324:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,325:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

is is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,325:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,325:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,326:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,326:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,326:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,327:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,327:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,327:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,327:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,328:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,328:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,328:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,329:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,329:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,329:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,330:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,330:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,330:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,332:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,332:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,332:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,333:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,333:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,333:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,334:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,335:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,335:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:01,337:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,337:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,337:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,338:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,338:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,338:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,338:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,338:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,339:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,339:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,341:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,343:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:01,345:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:01,364:INFO:Calculating mean and std
2024-04-27 09:37:01,365:INFO:Creating metrics dataframe
2024-04-27 09:37:01,367:INFO:Uploading results into container
2024-04-27 09:37:01,367:INFO:Uploading model into container now
2024-04-27 09:37:01,367:INFO:_master_model_container: 9
2024-04-27 09:37:01,367:INFO:_display_container: 2
2024-04-27 09:37:01,368:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5020)
2024-04-27 09:37:01,368:INFO:create_model() successfully completed......................................
2024-04-27 09:37:01,499:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:01,499:INFO:Creating metrics dataframe
2024-04-27 09:37:01,503:INFO:Initializing Gradient Boosting Classifier
2024-04-27 09:37:01,503:INFO:Total runtime is 0.22756821314493816 minutes
2024-04-27 09:37:01,503:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:01,503:INFO:Initializing create_model()
2024-04-27 09:37:01,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:01,503:INFO:Checking exceptions
2024-04-27 09:37:01,503:INFO:Importing libraries
2024-04-27 09:37:01,503:INFO:Copying training dataset
2024-04-27 09:37:01,507:INFO:Defining folds
2024-04-27 09:37:01,507:INFO:Declaring metric variables
2024-04-27 09:37:01,507:INFO:Importing untrained model
2024-04-27 09:37:01,508:INFO:Gradient Boosting Classifier Imported successfully
2024-04-27 09:37:01,508:INFO:Starting cross validation
2024-04-27 09:37:01,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:01,511:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:02,376:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,378:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,383:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,385:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,387:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,399:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,402:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,406:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,408:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,410:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,418:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,420:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,424:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,426:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,426:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,426:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,428:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,428:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,429:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,431:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,432:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,433:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,434:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,435:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,435:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,435:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,436:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,437:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,437:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,438:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,439:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,439:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,440:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,442:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,444:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,446:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,449:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,453:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,454:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,454:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,455:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,455:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,457:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,457:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,458:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,458:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,458:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,459:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,459:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,460:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,460:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,461:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,461:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,462:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,462:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,463:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,464:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,466:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,478:INFO:Calculating mean and std
2024-04-27 09:37:02,479:INFO:Creating metrics dataframe
2024-04-27 09:37:02,480:INFO:Uploading results into container
2024-04-27 09:37:02,481:INFO:Uploading model into container now
2024-04-27 09:37:02,481:INFO:_master_model_container: 10
2024-04-27 09:37:02,481:INFO:_display_container: 2
2024-04-27 09:37:02,482:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-27 09:37:02,482:INFO:create_model() successfully completed......................................
2024-04-27 09:37:02,606:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:02,606:INFO:Creating metrics dataframe
2024-04-27 09:37:02,609:INFO:Initializing Linear Discriminant Analysis
2024-04-27 09:37:02,609:INFO:Total runtime is 0.24600385030110677 minutes
2024-04-27 09:37:02,609:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:02,609:INFO:Initializing create_model()
2024-04-27 09:37:02,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:02,609:INFO:Checking exceptions
2024-04-27 09:37:02,609:INFO:Importing libraries
2024-04-27 09:37:02,609:INFO:Copying training dataset
2024-04-27 09:37:02,613:INFO:Defining folds
2024-04-27 09:37:02,613:INFO:Declaring metric variables
2024-04-27 09:37:02,613:INFO:Importing untrained model
2024-04-27 09:37:02,613:INFO:Linear Discriminant Analysis Imported successfully
2024-04-27 09:37:02,613:INFO:Starting cross validation
2024-04-27 09:37:02,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:02,616:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:02,652:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,652:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,653:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,653:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,653:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,653:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,655:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,655:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,655:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,655:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,656:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,657:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,657:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,657:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,658:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,658:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,658:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,659:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,659:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,659:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,660:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,660:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,660:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,661:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,661:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,661:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,661:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,661:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,663:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,663:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,663:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,663:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,663:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,663:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,663:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,664:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,664:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,664:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,664:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,665:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,665:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,665:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,665:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,666:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,667:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 09:37:02,667:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,668:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,668:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,668:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,669:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,670:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,672:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,672:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,672:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,673:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:02,674:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:02,693:INFO:Calculating mean and std
2024-04-27 09:37:02,694:INFO:Creating metrics dataframe
2024-04-27 09:37:02,696:INFO:Uploading results into container
2024-04-27 09:37:02,696:INFO:Uploading model into container now
2024-04-27 09:37:02,696:INFO:_master_model_container: 11
2024-04-27 09:37:02,696:INFO:_display_container: 2
2024-04-27 09:37:02,697:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-27 09:37:02,697:INFO:create_model() successfully completed......................................
2024-04-27 09:37:02,820:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:02,820:INFO:Creating metrics dataframe
2024-04-27 09:37:02,822:INFO:Initializing Extra Trees Classifier
2024-04-27 09:37:02,822:INFO:Total runtime is 0.24954462846120198 minutes
2024-04-27 09:37:02,822:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:02,823:INFO:Initializing create_model()
2024-04-27 09:37:02,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:02,823:INFO:Checking exceptions
2024-04-27 09:37:02,823:INFO:Importing libraries
2024-04-27 09:37:02,823:INFO:Copying training dataset
2024-04-27 09:37:02,825:INFO:Defining folds
2024-04-27 09:37:02,825:INFO:Declaring metric variables
2024-04-27 09:37:02,826:INFO:Importing untrained model
2024-04-27 09:37:02,826:INFO:Extra Trees Classifier Imported successfully
2024-04-27 09:37:02,826:INFO:Starting cross validation
2024-04-27 09:37:02,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:02,829:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:03,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,039:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,039:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:03,039:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:03,040:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:03,040:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:03,040:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:03,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,043:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,043:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,044:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,044:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,044:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,044:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,044:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,046:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,046:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,046:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,046:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,047:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,047:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,047:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,047:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,048:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,048:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,049:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,049:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,050:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,050:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,051:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,051:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,052:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,052:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,053:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,054:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,054:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,054:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,054:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:03,055:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:03,055:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:03,057:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,057:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,058:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,059:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,060:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,060:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,060:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,060:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,061:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,061:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,061:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,061:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,062:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,063:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,063:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,063:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:03,065:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:03,078:INFO:Calculating mean and std
2024-04-27 09:37:03,080:INFO:Creating metrics dataframe
2024-04-27 09:37:03,082:INFO:Uploading results into container
2024-04-27 09:37:03,082:INFO:Uploading model into container now
2024-04-27 09:37:03,082:INFO:_master_model_container: 12
2024-04-27 09:37:03,082:INFO:_display_container: 2
2024-04-27 09:37:03,083:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5020, verbose=0,
                     warm_start=False)
2024-04-27 09:37:03,083:INFO:create_model() successfully completed......................................
2024-04-27 09:37:03,206:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:03,206:INFO:Creating metrics dataframe
2024-04-27 09:37:03,208:INFO:Initializing Light Gradient Boosting Machine
2024-04-27 09:37:03,208:INFO:Total runtime is 0.2559752146402995 minutes
2024-04-27 09:37:03,208:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:03,208:INFO:Initializing create_model()
2024-04-27 09:37:03,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:03,208:INFO:Checking exceptions
2024-04-27 09:37:03,208:INFO:Importing libraries
2024-04-27 09:37:03,208:INFO:Copying training dataset
2024-04-27 09:37:03,212:INFO:Defining folds
2024-04-27 09:37:03,212:INFO:Declaring metric variables
2024-04-27 09:37:03,212:INFO:Importing untrained model
2024-04-27 09:37:03,212:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-27 09:37:03,212:INFO:Starting cross validation
2024-04-27 09:37:03,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:03,215:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:04,766:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:04,767:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:04,769:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,774:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,776:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,812:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:04,813:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:04,816:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,818:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,823:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,825:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,827:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:04,852:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 12)

  warnings.warn(

2024-04-27 09:37:04,854:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,856:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,859:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,860:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,863:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,891:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:04,892:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:04,894:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,898:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,897:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:04,900:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,900:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:04,902:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,902:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,906:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:04,907:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,907:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:04,909:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,910:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,911:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,912:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,914:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,916:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,919:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,920:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,958:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:04,959:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:04,962:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,964:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,966:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,968:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,970:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,972:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,975:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:04,976:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:04,978:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,980:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,983:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,985:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:04,987:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:04,989:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,015:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,016:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,018:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,020:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,022:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,024:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,026:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,028:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,032:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,033:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,035:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,039:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,041:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,043:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,051:INFO:Calculating mean and std
2024-04-27 09:37:05,052:INFO:Creating metrics dataframe
2024-04-27 09:37:05,054:INFO:Uploading results into container
2024-04-27 09:37:05,055:INFO:Uploading model into container now
2024-04-27 09:37:05,055:INFO:_master_model_container: 13
2024-04-27 09:37:05,055:INFO:_display_container: 2
2024-04-27 09:37:05,056:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-27 09:37:05,056:INFO:create_model() successfully completed......................................
2024-04-27 09:37:05,196:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:05,196:INFO:Creating metrics dataframe
2024-04-27 09:37:05,199:INFO:Initializing Dummy Classifier
2024-04-27 09:37:05,199:INFO:Total runtime is 0.2891548633575439 minutes
2024-04-27 09:37:05,199:INFO:SubProcess create_model() called ==================================
2024-04-27 09:37:05,199:INFO:Initializing create_model()
2024-04-27 09:37:05,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1A3B95510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:05,200:INFO:Checking exceptions
2024-04-27 09:37:05,200:INFO:Importing libraries
2024-04-27 09:37:05,200:INFO:Copying training dataset
2024-04-27 09:37:05,202:INFO:Defining folds
2024-04-27 09:37:05,202:INFO:Declaring metric variables
2024-04-27 09:37:05,202:INFO:Importing untrained model
2024-04-27 09:37:05,203:INFO:Dummy Classifier Imported successfully
2024-04-27 09:37:05,203:INFO:Starting cross validation
2024-04-27 09:37:05,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 09:37:05,206:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.
  warnings.warn(

2024-04-27 09:37:05,228:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,229:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 12)

  warnings.warn(

2024-04-27 09:37:05,230:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,231:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,231:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,233:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,233:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,234:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,235:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,235:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,235:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,235:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,235:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,236:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,237:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,237:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,237:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,238:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,238:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,239:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,239:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,239:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,240:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,240:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,240:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,241:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,241:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,242:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,242:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,242:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,242:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,243:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,244:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,244:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,244:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,244:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,244:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,245:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,245:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,245:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,246:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,246:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,246:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,247:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,248:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,248:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,249:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,250:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,250:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,250:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,251:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,251:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 09:37:05,251:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,251:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,252:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 09:37:05,253:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,253:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,253:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,254:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,254:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,254:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,254:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,256:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,256:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,257:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,258:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,258:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,259:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,260:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,262:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Whitefish') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 09:37:05,263:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 09:37:05,268:INFO:Calculating mean and std
2024-04-27 09:37:05,268:INFO:Creating metrics dataframe
2024-04-27 09:37:05,270:INFO:Uploading results into container
2024-04-27 09:37:05,270:INFO:Uploading model into container now
2024-04-27 09:37:05,271:INFO:_master_model_container: 14
2024-04-27 09:37:05,271:INFO:_display_container: 2
2024-04-27 09:37:05,271:INFO:DummyClassifier(constant=None, random_state=5020, strategy='prior')
2024-04-27 09:37:05,271:INFO:create_model() successfully completed......................................
2024-04-27 09:37:05,395:INFO:SubProcess create_model() end ==================================
2024-04-27 09:37:05,395:INFO:Creating metrics dataframe
2024-04-27 09:37:05,400:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-27 09:37:05,402:INFO:Initializing create_model()
2024-04-27 09:37:05,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1A409D120>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 09:37:05,403:INFO:Checking exceptions
2024-04-27 09:37:05,403:INFO:Importing libraries
2024-04-27 09:37:05,403:INFO:Copying training dataset
2024-04-27 09:37:05,405:INFO:Defining folds
2024-04-27 09:37:05,406:INFO:Declaring metric variables
2024-04-27 09:37:05,406:INFO:Importing untrained model
2024-04-27 09:37:05,406:INFO:Declaring custom model
2024-04-27 09:37:05,406:INFO:Linear Discriminant Analysis Imported successfully
2024-04-27 09:37:05,407:INFO:Cross validation set to False
2024-04-27 09:37:05,407:INFO:Fitting Model
2024-04-27 09:37:05,416:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-27 09:37:05,416:INFO:create_model() successfully completed......................................
2024-04-27 09:37:05,559:INFO:_master_model_container: 14
2024-04-27 09:37:05,559:INFO:_display_container: 2
2024-04-27 09:37:05,560:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-27 09:37:05,560:INFO:compare_models() successfully completed......................................
2024-04-27 09:37:05,568:INFO:Initializing save_model()
2024-04-27 09:37:05,568:INFO:save_model(model=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Weight', 'Length1', 'Length2',
                                             'Length3', 'Height', 'Width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-27 09:37:05,569:INFO:Adding model into prep_pipe
2024-04-27 09:37:05,574:INFO:best_model.pkl saved in current working directory
2024-04-27 09:37:05,580:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Weight', 'Length1', 'Length2',
                                             'Length3', 'Height', 'Width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2024-04-27 09:37:05,580:INFO:save_model() successfully completed......................................
2024-04-27 13:00:37,101:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'Bream'')
  warnings.warn(

2024-04-27 21:51:20,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 21:51:20,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 21:51:20,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 21:51:20,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 21:54:58,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 21:54:58,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 21:54:58,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 21:54:58,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-27 21:56:34,591:INFO:PyCaret ClassificationExperiment
2024-04-27 21:56:34,591:INFO:Logging name: clf-default-name
2024-04-27 21:56:34,591:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-27 21:56:34,591:INFO:version 3.3.1
2024-04-27 21:56:34,592:INFO:Initializing setup()
2024-04-27 21:56:34,592:INFO:self.USI: c731
2024-04-27 21:56:34,592:INFO:self._variable_keys: {'y_test', 'is_multiclass', 'n_jobs_param', 'gpu_param', 'fix_imbalance', 'X_test', 'data', 'target_param', 'y', 'pipeline', 'fold_shuffle_param', 'fold_generator', 'y_train', 'seed', 'log_plots_param', 'exp_name_log', 'logging_param', 'exp_id', 'USI', '_available_plots', 'idx', 'memory', 'gpu_n_jobs_param', 'X_train', 'html_param', 'fold_groups_param', '_ml_usecase', 'X'}
2024-04-27 21:56:34,592:INFO:Checking environment
2024-04-27 21:56:34,592:INFO:python_version: 3.10.9
2024-04-27 21:56:34,592:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-04-27 21:56:34,592:INFO:machine: AMD64
2024-04-27 21:56:34,611:INFO:platform: Windows-10-10.0.22621-SP0
2024-04-27 21:56:34,611:INFO:Memory: svmem(total=16541904896, available=3837267968, percent=76.8, used=12704636928, free=3837267968)
2024-04-27 21:56:34,611:INFO:Physical Core: 6
2024-04-27 21:56:34,611:INFO:Logical Core: 12
2024-04-27 21:56:34,613:INFO:Checking libraries
2024-04-27 21:56:34,613:INFO:System:
2024-04-27 21:56:34,613:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-04-27 21:56:34,613:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-04-27 21:56:34,613:INFO:   machine: Windows-10-10.0.22621-SP0
2024-04-27 21:56:34,613:INFO:PyCaret required dependencies:
2024-04-27 21:56:35,503:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:36,045:INFO:                 pip: 22.3.1
2024-04-27 21:56:36,045:INFO:          setuptools: 65.6.3
2024-04-27 21:56:36,045:INFO:             pycaret: 3.3.1
2024-04-27 21:56:36,045:INFO:             IPython: 8.12.3
2024-04-27 21:56:36,045:INFO:          ipywidgets: 7.6.5
2024-04-27 21:56:36,045:INFO:                tqdm: 4.64.1
2024-04-27 21:56:36,045:INFO:               numpy: 1.23.5
2024-04-27 21:56:36,045:INFO:              pandas: 2.2.2
2024-04-27 21:56:36,045:INFO:              jinja2: 3.1.2
2024-04-27 21:56:36,046:INFO:               scipy: 1.10.0
2024-04-27 21:56:36,046:INFO:              joblib: 1.3.2
2024-04-27 21:56:36,046:INFO:             sklearn: 1.4.2
2024-04-27 21:56:36,046:INFO:                pyod: 1.1.3
2024-04-27 21:56:36,046:INFO:            imblearn: 0.10.1
2024-04-27 21:56:36,046:INFO:   category_encoders: 2.6.3
2024-04-27 21:56:36,046:INFO:            lightgbm: 4.3.0
2024-04-27 21:56:36,046:INFO:               numba: 0.56.4
2024-04-27 21:56:36,047:INFO:            requests: 2.28.1
2024-04-27 21:56:36,047:INFO:          matplotlib: 3.7.0
2024-04-27 21:56:36,047:INFO:          scikitplot: 0.3.7
2024-04-27 21:56:36,047:INFO:         yellowbrick: 1.5
2024-04-27 21:56:36,047:INFO:              plotly: 5.21.0
2024-04-27 21:56:36,047:INFO:    plotly-resampler: Not installed
2024-04-27 21:56:36,047:INFO:             kaleido: 0.2.1
2024-04-27 21:56:36,047:INFO:           schemdraw: 0.15
2024-04-27 21:56:36,047:INFO:         statsmodels: 0.13.5
2024-04-27 21:56:36,047:INFO:              sktime: 0.26.0
2024-04-27 21:56:36,047:INFO:               tbats: 1.1.3
2024-04-27 21:56:36,047:INFO:            pmdarima: 2.0.4
2024-04-27 21:56:36,047:INFO:              psutil: 5.9.0
2024-04-27 21:56:36,047:INFO:          markupsafe: 2.1.1
2024-04-27 21:56:36,047:INFO:             pickle5: Not installed
2024-04-27 21:56:36,048:INFO:         cloudpickle: 2.0.0
2024-04-27 21:56:36,048:INFO:         deprecation: 2.1.0
2024-04-27 21:56:36,048:INFO:              xxhash: 3.4.1
2024-04-27 21:56:36,048:INFO:           wurlitzer: Not installed
2024-04-27 21:56:36,048:INFO:PyCaret optional dependencies:
2024-04-27 21:56:36,071:INFO:                shap: Not installed
2024-04-27 21:56:36,071:INFO:           interpret: Not installed
2024-04-27 21:56:36,072:INFO:                umap: Not installed
2024-04-27 21:56:36,072:INFO:     ydata_profiling: 4.7.0
2024-04-27 21:56:36,072:INFO:  explainerdashboard: Not installed
2024-04-27 21:56:36,072:INFO:             autoviz: Not installed
2024-04-27 21:56:36,072:INFO:           fairlearn: Not installed
2024-04-27 21:56:36,072:INFO:          deepchecks: Not installed
2024-04-27 21:56:36,072:INFO:             xgboost: Not installed
2024-04-27 21:56:36,072:INFO:            catboost: Not installed
2024-04-27 21:56:36,072:INFO:              kmodes: Not installed
2024-04-27 21:56:36,072:INFO:             mlxtend: Not installed
2024-04-27 21:56:36,072:INFO:       statsforecast: Not installed
2024-04-27 21:56:36,072:INFO:        tune_sklearn: Not installed
2024-04-27 21:56:36,073:INFO:                 ray: Not installed
2024-04-27 21:56:36,073:INFO:            hyperopt: Not installed
2024-04-27 21:56:36,073:INFO:              optuna: Not installed
2024-04-27 21:56:36,073:INFO:               skopt: Not installed
2024-04-27 21:56:36,073:INFO:              mlflow: Not installed
2024-04-27 21:56:36,073:INFO:              gradio: Not installed
2024-04-27 21:56:36,073:INFO:             fastapi: Not installed
2024-04-27 21:56:36,073:INFO:             uvicorn: Not installed
2024-04-27 21:56:36,073:INFO:              m2cgen: Not installed
2024-04-27 21:56:36,073:INFO:           evidently: Not installed
2024-04-27 21:56:36,073:INFO:               fugue: Not installed
2024-04-27 21:56:36,073:INFO:           streamlit: 1.33.0
2024-04-27 21:56:36,073:INFO:             prophet: Not installed
2024-04-27 21:56:36,073:INFO:None
2024-04-27 21:56:36,074:INFO:Set up data.
2024-04-27 21:56:36,082:INFO:Set up folding strategy.
2024-04-27 21:56:36,083:INFO:Set up train/test split.
2024-04-27 21:56:36,092:INFO:Set up index.
2024-04-27 21:56:36,092:INFO:Assigning column types.
2024-04-27 21:56:36,098:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-27 21:56:36,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-27 21:56:36,188:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 21:56:36,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,337:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-27 21:56:36,339:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 21:56:36,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,396:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-27 21:56:36,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 21:56:36,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,620:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-27 21:56:36,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,674:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-27 21:56:36,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:36,961:INFO:Preparing preprocessing pipeline...
2024-04-27 21:56:36,963:INFO:Set up label encoding.
2024-04-27 21:56:36,963:INFO:Set up simple imputation.
2024-04-27 21:56:37,032:INFO:Finished creating preprocessing pipeline.
2024-04-27 21:56:37,041:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-04-27 21:56:37,041:INFO:Creating final display dataframe.
2024-04-27 21:56:37,186:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               8650
1                        Target                                            Species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 6)
5        Transformed data shape                                           (150, 6)
6   Transformed train set shape                                           (105, 6)
7    Transformed test set shape                                            (45, 6)
8              Numeric features                                                  5
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               c731
2024-04-27 21:56:37,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:37,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:37,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:37,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-27 21:56:37,493:INFO:setup() successfully completed in 2.91s...............
2024-04-27 21:56:37,498:INFO:Initializing compare_models()
2024-04-27 21:56:37,498:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-27 21:56:37,498:INFO:Checking exceptions
2024-04-27 21:56:37,504:INFO:Preparing display monitor
2024-04-27 21:56:37,508:INFO:Initializing Logistic Regression
2024-04-27 21:56:37,508:INFO:Total runtime is 0.0 minutes
2024-04-27 21:56:37,510:INFO:SubProcess create_model() called ==================================
2024-04-27 21:56:37,510:INFO:Initializing create_model()
2024-04-27 21:56:37,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:56:37,510:INFO:Checking exceptions
2024-04-27 21:56:37,510:INFO:Importing libraries
2024-04-27 21:56:37,510:INFO:Copying training dataset
2024-04-27 21:56:37,517:INFO:Defining folds
2024-04-27 21:56:37,517:INFO:Declaring metric variables
2024-04-27 21:56:37,517:INFO:Importing untrained model
2024-04-27 21:56:37,519:INFO:Logistic Regression Imported successfully
2024-04-27 21:56:37,519:INFO:Starting cross validation
2024-04-27 21:56:37,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:56:48,415:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,448:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,461:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,517:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,517:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,521:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,530:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,533:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,540:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:48,549:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:49,397:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,405:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,413:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,419:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,420:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,424:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,429:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,437:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,443:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,450:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,459:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,467:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,473:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,480:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,485:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,487:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,489:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,492:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,495:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,497:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,497:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,499:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,501:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,503:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,504:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,507:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,509:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,510:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,511:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,513:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,515:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:56:49,518:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,521:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,523:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,523:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,525:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,532:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,532:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,539:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,558:INFO:Calculating mean and std
2024-04-27 21:56:49,559:INFO:Creating metrics dataframe
2024-04-27 21:56:49,564:INFO:Uploading results into container
2024-04-27 21:56:49,565:INFO:Uploading model into container now
2024-04-27 21:56:49,566:INFO:_master_model_container: 1
2024-04-27 21:56:49,566:INFO:_display_container: 2
2024-04-27 21:56:49,567:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8650, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-27 21:56:49,568:INFO:create_model() successfully completed......................................
2024-04-27 21:56:49,787:INFO:SubProcess create_model() end ==================================
2024-04-27 21:56:49,788:INFO:Creating metrics dataframe
2024-04-27 21:56:49,793:INFO:Initializing K Neighbors Classifier
2024-04-27 21:56:49,793:INFO:Total runtime is 0.20473495721817017 minutes
2024-04-27 21:56:49,793:INFO:SubProcess create_model() called ==================================
2024-04-27 21:56:49,793:INFO:Initializing create_model()
2024-04-27 21:56:49,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:56:49,794:INFO:Checking exceptions
2024-04-27 21:56:49,794:INFO:Importing libraries
2024-04-27 21:56:49,794:INFO:Copying training dataset
2024-04-27 21:56:49,800:INFO:Defining folds
2024-04-27 21:56:49,800:INFO:Declaring metric variables
2024-04-27 21:56:49,801:INFO:Importing untrained model
2024-04-27 21:56:49,802:INFO:K Neighbors Classifier Imported successfully
2024-04-27 21:56:49,802:INFO:Starting cross validation
2024-04-27 21:56:49,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:56:49,914:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:49,914:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:49,915:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:49,927:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:49,927:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:49,928:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:49,928:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:49,928:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:49,928:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:49,932:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,932:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,932:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,933:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,939:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:49,940:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,941:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,941:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,941:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,942:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:49,943:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,945:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:49,946:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,948:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:49,948:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,951:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,951:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,954:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,954:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,956:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,958:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:49,961:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:49,962:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,962:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,964:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,965:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,970:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,970:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:49,977:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:58,343:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:58,346:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-04-27 21:56:59,131:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,131:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,143:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,144:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,150:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,150:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,156:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,156:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,161:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,161:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,181:INFO:Calculating mean and std
2024-04-27 21:56:59,183:INFO:Creating metrics dataframe
2024-04-27 21:56:59,188:INFO:Uploading results into container
2024-04-27 21:56:59,189:INFO:Uploading model into container now
2024-04-27 21:56:59,190:INFO:_master_model_container: 2
2024-04-27 21:56:59,190:INFO:_display_container: 2
2024-04-27 21:56:59,190:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-27 21:56:59,191:INFO:create_model() successfully completed......................................
2024-04-27 21:56:59,393:INFO:SubProcess create_model() end ==================================
2024-04-27 21:56:59,393:INFO:Creating metrics dataframe
2024-04-27 21:56:59,400:INFO:Initializing Naive Bayes
2024-04-27 21:56:59,400:INFO:Total runtime is 0.3648539861043294 minutes
2024-04-27 21:56:59,401:INFO:SubProcess create_model() called ==================================
2024-04-27 21:56:59,402:INFO:Initializing create_model()
2024-04-27 21:56:59,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:56:59,402:INFO:Checking exceptions
2024-04-27 21:56:59,402:INFO:Importing libraries
2024-04-27 21:56:59,402:INFO:Copying training dataset
2024-04-27 21:56:59,409:INFO:Defining folds
2024-04-27 21:56:59,409:INFO:Declaring metric variables
2024-04-27 21:56:59,409:INFO:Importing untrained model
2024-04-27 21:56:59,410:INFO:Naive Bayes Imported successfully
2024-04-27 21:56:59,412:INFO:Starting cross validation
2024-04-27 21:56:59,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:56:59,497:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,499:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,502:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,503:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,504:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,507:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,508:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,509:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,510:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,510:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,514:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,515:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,515:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,517:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,518:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,519:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,519:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,520:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,521:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,522:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,522:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,523:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,523:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,526:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,528:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,529:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,530:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,531:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,531:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,532:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,532:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,535:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,536:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,537:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,537:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,541:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,543:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,544:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,545:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,545:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,546:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,547:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,550:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,552:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,552:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,554:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,557:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,559:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,571:INFO:Calculating mean and std
2024-04-27 21:56:59,573:INFO:Creating metrics dataframe
2024-04-27 21:56:59,576:INFO:Uploading results into container
2024-04-27 21:56:59,576:INFO:Uploading model into container now
2024-04-27 21:56:59,577:INFO:_master_model_container: 3
2024-04-27 21:56:59,577:INFO:_display_container: 2
2024-04-27 21:56:59,577:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-27 21:56:59,577:INFO:create_model() successfully completed......................................
2024-04-27 21:56:59,755:INFO:SubProcess create_model() end ==================================
2024-04-27 21:56:59,755:INFO:Creating metrics dataframe
2024-04-27 21:56:59,760:INFO:Initializing Decision Tree Classifier
2024-04-27 21:56:59,761:INFO:Total runtime is 0.3708841482798258 minutes
2024-04-27 21:56:59,761:INFO:SubProcess create_model() called ==================================
2024-04-27 21:56:59,761:INFO:Initializing create_model()
2024-04-27 21:56:59,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:56:59,762:INFO:Checking exceptions
2024-04-27 21:56:59,762:INFO:Importing libraries
2024-04-27 21:56:59,762:INFO:Copying training dataset
2024-04-27 21:56:59,771:INFO:Defining folds
2024-04-27 21:56:59,771:INFO:Declaring metric variables
2024-04-27 21:56:59,771:INFO:Importing untrained model
2024-04-27 21:56:59,772:INFO:Decision Tree Classifier Imported successfully
2024-04-27 21:56:59,773:INFO:Starting cross validation
2024-04-27 21:56:59,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:56:59,842:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,844:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,844:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,846:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,857:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,858:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,861:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,866:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,867:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,875:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,876:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,879:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,884:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,887:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,891:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,896:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,899:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,903:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,905:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,911:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,918:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,919:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,925:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,927:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,928:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,929:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,930:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,931:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:56:59,931:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,935:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,935:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,936:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,937:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,939:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,940:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,941:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,943:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,945:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,945:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,947:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,949:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:56:59,950:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:56:59,953:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,955:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,956:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,964:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,970:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:56:59,981:INFO:Calculating mean and std
2024-04-27 21:56:59,982:INFO:Creating metrics dataframe
2024-04-27 21:56:59,986:INFO:Uploading results into container
2024-04-27 21:56:59,986:INFO:Uploading model into container now
2024-04-27 21:56:59,987:INFO:_master_model_container: 4
2024-04-27 21:56:59,987:INFO:_display_container: 2
2024-04-27 21:56:59,988:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8650, splitter='best')
2024-04-27 21:56:59,988:INFO:create_model() successfully completed......................................
2024-04-27 21:57:00,181:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:00,181:INFO:Creating metrics dataframe
2024-04-27 21:57:00,186:INFO:Initializing SVM - Linear Kernel
2024-04-27 21:57:00,186:INFO:Total runtime is 0.3779625455538431 minutes
2024-04-27 21:57:00,187:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:00,187:INFO:Initializing create_model()
2024-04-27 21:57:00,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:00,188:INFO:Checking exceptions
2024-04-27 21:57:00,188:INFO:Importing libraries
2024-04-27 21:57:00,188:INFO:Copying training dataset
2024-04-27 21:57:00,193:INFO:Defining folds
2024-04-27 21:57:00,193:INFO:Declaring metric variables
2024-04-27 21:57:00,194:INFO:Importing untrained model
2024-04-27 21:57:00,195:INFO:SVM - Linear Kernel Imported successfully
2024-04-27 21:57:00,196:INFO:Starting cross validation
2024-04-27 21:57:00,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:00,341:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,342:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,342:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,343:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,345:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,346:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,347:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,349:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,353:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,354:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,355:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,357:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,359:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,361:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,361:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,361:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,363:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,366:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,369:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,373:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:00,375:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,377:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,381:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,383:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,383:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,385:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,386:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:00,386:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,387:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:00,391:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,392:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,392:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,396:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:00,397:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,401:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,404:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,407:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:00,407:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,410:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,411:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,416:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,418:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:00,421:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,441:INFO:Calculating mean and std
2024-04-27 21:57:00,443:INFO:Creating metrics dataframe
2024-04-27 21:57:00,445:INFO:Uploading results into container
2024-04-27 21:57:00,446:INFO:Uploading model into container now
2024-04-27 21:57:00,447:INFO:_master_model_container: 5
2024-04-27 21:57:00,447:INFO:_display_container: 2
2024-04-27 21:57:00,447:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8650, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-27 21:57:00,448:INFO:create_model() successfully completed......................................
2024-04-27 21:57:00,631:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:00,631:INFO:Creating metrics dataframe
2024-04-27 21:57:00,636:INFO:Initializing Ridge Classifier
2024-04-27 21:57:00,636:INFO:Total runtime is 0.38545627991358433 minutes
2024-04-27 21:57:00,637:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:00,637:INFO:Initializing create_model()
2024-04-27 21:57:00,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:00,637:INFO:Checking exceptions
2024-04-27 21:57:00,637:INFO:Importing libraries
2024-04-27 21:57:00,637:INFO:Copying training dataset
2024-04-27 21:57:00,643:INFO:Defining folds
2024-04-27 21:57:00,643:INFO:Declaring metric variables
2024-04-27 21:57:00,643:INFO:Importing untrained model
2024-04-27 21:57:00,644:INFO:Ridge Classifier Imported successfully
2024-04-27 21:57:00,645:INFO:Starting cross validation
2024-04-27 21:57:00,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:00,730:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,734:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,735:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,738:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,739:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,740:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,740:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,742:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,745:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,746:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,748:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,748:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,748:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,749:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,750:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,751:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,751:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,753:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,755:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,755:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,756:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,756:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,756:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,758:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,763:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,763:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,766:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:00,766:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,767:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,769:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,772:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,776:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,781:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:00,806:INFO:Calculating mean and std
2024-04-27 21:57:00,808:INFO:Creating metrics dataframe
2024-04-27 21:57:00,810:INFO:Uploading results into container
2024-04-27 21:57:00,811:INFO:Uploading model into container now
2024-04-27 21:57:00,812:INFO:_master_model_container: 6
2024-04-27 21:57:00,812:INFO:_display_container: 2
2024-04-27 21:57:00,812:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8650, solver='auto',
                tol=0.0001)
2024-04-27 21:57:00,813:INFO:create_model() successfully completed......................................
2024-04-27 21:57:00,996:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:00,996:INFO:Creating metrics dataframe
2024-04-27 21:57:01,002:INFO:Initializing Random Forest Classifier
2024-04-27 21:57:01,002:INFO:Total runtime is 0.3915532986323038 minutes
2024-04-27 21:57:01,002:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:01,003:INFO:Initializing create_model()
2024-04-27 21:57:01,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:01,003:INFO:Checking exceptions
2024-04-27 21:57:01,003:INFO:Importing libraries
2024-04-27 21:57:01,003:INFO:Copying training dataset
2024-04-27 21:57:01,009:INFO:Defining folds
2024-04-27 21:57:01,009:INFO:Declaring metric variables
2024-04-27 21:57:01,009:INFO:Importing untrained model
2024-04-27 21:57:01,010:INFO:Random Forest Classifier Imported successfully
2024-04-27 21:57:01,011:INFO:Starting cross validation
2024-04-27 21:57:01,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:01,626:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:01,628:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:01,628:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:01,633:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,635:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,642:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,642:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:01,642:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:01,642:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:01,643:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:01,645:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:01,645:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:01,646:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:01,646:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:01,648:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,650:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,650:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,650:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,650:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,651:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,656:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,656:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,656:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:01,658:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,658:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,658:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,659:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:01,663:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,664:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,665:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,665:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,666:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,674:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,674:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:01,676:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:01,676:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:01,679:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,679:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,681:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,685:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,686:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,689:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,692:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,750:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:01,752:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:01,754:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,764:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:01,789:INFO:Calculating mean and std
2024-04-27 21:57:01,791:INFO:Creating metrics dataframe
2024-04-27 21:57:01,794:INFO:Uploading results into container
2024-04-27 21:57:01,794:INFO:Uploading model into container now
2024-04-27 21:57:01,795:INFO:_master_model_container: 7
2024-04-27 21:57:01,795:INFO:_display_container: 2
2024-04-27 21:57:01,796:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8650, verbose=0,
                       warm_start=False)
2024-04-27 21:57:01,796:INFO:create_model() successfully completed......................................
2024-04-27 21:57:01,983:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:01,983:INFO:Creating metrics dataframe
2024-04-27 21:57:01,988:INFO:Initializing Quadratic Discriminant Analysis
2024-04-27 21:57:01,989:INFO:Total runtime is 0.40801670551300045 minutes
2024-04-27 21:57:01,989:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:01,989:INFO:Initializing create_model()
2024-04-27 21:57:01,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:01,990:INFO:Checking exceptions
2024-04-27 21:57:01,990:INFO:Importing libraries
2024-04-27 21:57:01,990:INFO:Copying training dataset
2024-04-27 21:57:01,996:INFO:Defining folds
2024-04-27 21:57:01,996:INFO:Declaring metric variables
2024-04-27 21:57:01,996:INFO:Importing untrained model
2024-04-27 21:57:01,997:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-27 21:57:01,998:INFO:Starting cross validation
2024-04-27 21:57:02,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:02,082:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,087:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,094:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,095:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,097:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,100:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,102:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,103:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,109:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,110:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,113:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,118:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,118:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,121:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,122:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,123:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,126:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,128:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,128:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,131:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,132:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,134:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,140:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,140:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,141:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,144:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,148:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,150:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,163:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,165:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,167:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,169:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,171:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,172:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,174:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,174:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,177:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,179:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,179:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,184:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,200:INFO:Calculating mean and std
2024-04-27 21:57:02,201:INFO:Creating metrics dataframe
2024-04-27 21:57:02,204:INFO:Uploading results into container
2024-04-27 21:57:02,205:INFO:Uploading model into container now
2024-04-27 21:57:02,206:INFO:_master_model_container: 8
2024-04-27 21:57:02,206:INFO:_display_container: 2
2024-04-27 21:57:02,206:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-27 21:57:02,206:INFO:create_model() successfully completed......................................
2024-04-27 21:57:02,385:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:02,386:INFO:Creating metrics dataframe
2024-04-27 21:57:02,391:INFO:Initializing Ada Boost Classifier
2024-04-27 21:57:02,392:INFO:Total runtime is 0.4147196888923645 minutes
2024-04-27 21:57:02,392:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:02,393:INFO:Initializing create_model()
2024-04-27 21:57:02,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:02,393:INFO:Checking exceptions
2024-04-27 21:57:02,393:INFO:Importing libraries
2024-04-27 21:57:02,393:INFO:Copying training dataset
2024-04-27 21:57:02,399:INFO:Defining folds
2024-04-27 21:57:02,399:INFO:Declaring metric variables
2024-04-27 21:57:02,400:INFO:Importing untrained model
2024-04-27 21:57:02,401:INFO:Ada Boost Classifier Imported successfully
2024-04-27 21:57:02,402:INFO:Starting cross validation
2024-04-27 21:57:02,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:02,453:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,455:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,462:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,465:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,468:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,491:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,506:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,509:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,534:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,539:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-27 21:57:02,729:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,730:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,734:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,735:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,742:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,742:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,748:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,749:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,764:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,772:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,772:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,775:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,776:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,779:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,783:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,784:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,786:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,789:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,790:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,791:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,792:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,795:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,800:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,803:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,804:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,806:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,809:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,811:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,812:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,812:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,813:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:02,815:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,816:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,820:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,825:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,826:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:02,838:INFO:Calculating mean and std
2024-04-27 21:57:02,839:INFO:Creating metrics dataframe
2024-04-27 21:57:02,842:INFO:Uploading results into container
2024-04-27 21:57:02,843:INFO:Uploading model into container now
2024-04-27 21:57:02,843:INFO:_master_model_container: 9
2024-04-27 21:57:02,844:INFO:_display_container: 2
2024-04-27 21:57:02,844:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8650)
2024-04-27 21:57:02,844:INFO:create_model() successfully completed......................................
2024-04-27 21:57:03,024:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:03,024:INFO:Creating metrics dataframe
2024-04-27 21:57:03,030:INFO:Initializing Gradient Boosting Classifier
2024-04-27 21:57:03,030:INFO:Total runtime is 0.42535693248112993 minutes
2024-04-27 21:57:03,030:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:03,031:INFO:Initializing create_model()
2024-04-27 21:57:03,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:03,031:INFO:Checking exceptions
2024-04-27 21:57:03,031:INFO:Importing libraries
2024-04-27 21:57:03,032:INFO:Copying training dataset
2024-04-27 21:57:03,038:INFO:Defining folds
2024-04-27 21:57:03,038:INFO:Declaring metric variables
2024-04-27 21:57:03,038:INFO:Importing untrained model
2024-04-27 21:57:03,039:INFO:Gradient Boosting Classifier Imported successfully
2024-04-27 21:57:03,040:INFO:Starting cross validation
2024-04-27 21:57:03,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:03,603:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,607:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,609:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,613:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,616:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,621:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,623:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,629:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,634:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,638:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,642:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,650:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,664:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,668:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,675:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,676:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,678:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,683:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,684:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,687:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,689:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,693:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,696:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,700:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,701:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,707:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,708:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,708:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,708:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,711:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,711:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,714:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:03,715:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,716:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,718:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,719:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,720:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,725:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,726:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,732:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:03,755:INFO:Calculating mean and std
2024-04-27 21:57:03,756:INFO:Creating metrics dataframe
2024-04-27 21:57:03,759:INFO:Uploading results into container
2024-04-27 21:57:03,760:INFO:Uploading model into container now
2024-04-27 21:57:03,760:INFO:_master_model_container: 10
2024-04-27 21:57:03,761:INFO:_display_container: 2
2024-04-27 21:57:03,761:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8650, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-27 21:57:03,761:INFO:create_model() successfully completed......................................
2024-04-27 21:57:03,935:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:03,935:INFO:Creating metrics dataframe
2024-04-27 21:57:03,940:INFO:Initializing Linear Discriminant Analysis
2024-04-27 21:57:03,940:INFO:Total runtime is 0.4405224164326985 minutes
2024-04-27 21:57:03,940:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:03,941:INFO:Initializing create_model()
2024-04-27 21:57:03,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:03,941:INFO:Checking exceptions
2024-04-27 21:57:03,941:INFO:Importing libraries
2024-04-27 21:57:03,941:INFO:Copying training dataset
2024-04-27 21:57:03,947:INFO:Defining folds
2024-04-27 21:57:03,947:INFO:Declaring metric variables
2024-04-27 21:57:03,947:INFO:Importing untrained model
2024-04-27 21:57:03,947:INFO:Linear Discriminant Analysis Imported successfully
2024-04-27 21:57:03,949:INFO:Starting cross validation
2024-04-27 21:57:03,950:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:04,016:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,025:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,027:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,027:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,029:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,031:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,034:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,035:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,037:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,044:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,045:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,053:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,055:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,058:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,060:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,063:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,066:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,067:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,073:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,074:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,075:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,076:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,082:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,087:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,090:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,093:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,095:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,095:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,099:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,100:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,103:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-27 21:57:04,104:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,105:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,111:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,115:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,130:INFO:Calculating mean and std
2024-04-27 21:57:04,131:INFO:Creating metrics dataframe
2024-04-27 21:57:04,134:INFO:Uploading results into container
2024-04-27 21:57:04,135:INFO:Uploading model into container now
2024-04-27 21:57:04,135:INFO:_master_model_container: 11
2024-04-27 21:57:04,135:INFO:_display_container: 2
2024-04-27 21:57:04,136:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-27 21:57:04,136:INFO:create_model() successfully completed......................................
2024-04-27 21:57:04,308:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:04,308:INFO:Creating metrics dataframe
2024-04-27 21:57:04,313:INFO:Initializing Extra Trees Classifier
2024-04-27 21:57:04,313:INFO:Total runtime is 0.44674634536107377 minutes
2024-04-27 21:57:04,314:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:04,314:INFO:Initializing create_model()
2024-04-27 21:57:04,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:04,316:INFO:Checking exceptions
2024-04-27 21:57:04,316:INFO:Importing libraries
2024-04-27 21:57:04,316:INFO:Copying training dataset
2024-04-27 21:57:04,320:INFO:Defining folds
2024-04-27 21:57:04,321:INFO:Declaring metric variables
2024-04-27 21:57:04,321:INFO:Importing untrained model
2024-04-27 21:57:04,322:INFO:Extra Trees Classifier Imported successfully
2024-04-27 21:57:04,323:INFO:Starting cross validation
2024-04-27 21:57:04,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:04,729:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,731:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:04,735:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,746:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,746:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,748:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:04,748:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:04,749:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,751:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,752:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,760:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,761:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,762:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:04,763:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:04,766:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,766:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,766:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,767:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,774:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,774:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,777:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:04,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,779:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,780:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,786:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,791:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,791:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,792:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,792:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,793:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:04,793:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:04,793:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:04,797:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,797:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,797:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,805:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,805:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,810:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,810:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,812:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,837:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:04,838:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:04,840:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:04,861:INFO:Calculating mean and std
2024-04-27 21:57:04,862:INFO:Creating metrics dataframe
2024-04-27 21:57:04,866:INFO:Uploading results into container
2024-04-27 21:57:04,867:INFO:Uploading model into container now
2024-04-27 21:57:04,868:INFO:_master_model_container: 12
2024-04-27 21:57:04,868:INFO:_display_container: 2
2024-04-27 21:57:04,869:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8650, verbose=0,
                     warm_start=False)
2024-04-27 21:57:04,869:INFO:create_model() successfully completed......................................
2024-04-27 21:57:05,039:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:05,039:INFO:Creating metrics dataframe
2024-04-27 21:57:05,043:INFO:Initializing Light Gradient Boosting Machine
2024-04-27 21:57:05,043:INFO:Total runtime is 0.4589159250259399 minutes
2024-04-27 21:57:05,044:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:05,044:INFO:Initializing create_model()
2024-04-27 21:57:05,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:05,045:INFO:Checking exceptions
2024-04-27 21:57:05,045:INFO:Importing libraries
2024-04-27 21:57:05,045:INFO:Copying training dataset
2024-04-27 21:57:05,050:INFO:Defining folds
2024-04-27 21:57:05,051:INFO:Declaring metric variables
2024-04-27 21:57:05,051:INFO:Importing untrained model
2024-04-27 21:57:05,052:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-27 21:57:05,052:INFO:Starting cross validation
2024-04-27 21:57:05,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:06,525:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,527:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:06,531:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,540:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,554:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,586:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,588:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:06,592:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,601:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,608:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,609:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,611:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:06,615:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,623:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,632:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,641:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,643:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:06,646:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,647:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,648:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:06,653:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,657:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,662:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,666:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,666:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,669:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:06,670:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,674:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,683:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,690:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,715:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,716:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:06,721:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,728:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,731:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,732:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:06,737:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,737:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,744:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,757:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,781:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,783:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:06,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,800:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:06,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:06,804:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,806:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,813:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,821:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:06,836:INFO:Calculating mean and std
2024-04-27 21:57:06,838:INFO:Creating metrics dataframe
2024-04-27 21:57:06,842:INFO:Uploading results into container
2024-04-27 21:57:06,843:INFO:Uploading model into container now
2024-04-27 21:57:06,844:INFO:_master_model_container: 13
2024-04-27 21:57:06,844:INFO:_display_container: 2
2024-04-27 21:57:06,845:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8650, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-27 21:57:06,845:INFO:create_model() successfully completed......................................
2024-04-27 21:57:07,018:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:07,018:INFO:Creating metrics dataframe
2024-04-27 21:57:07,023:INFO:Initializing Dummy Classifier
2024-04-27 21:57:07,023:INFO:Total runtime is 0.4919170220692952 minutes
2024-04-27 21:57:07,024:INFO:SubProcess create_model() called ==================================
2024-04-27 21:57:07,024:INFO:Initializing create_model()
2024-04-27 21:57:07,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000219B26439D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:07,024:INFO:Checking exceptions
2024-04-27 21:57:07,024:INFO:Importing libraries
2024-04-27 21:57:07,024:INFO:Copying training dataset
2024-04-27 21:57:07,031:INFO:Defining folds
2024-04-27 21:57:07,031:INFO:Declaring metric variables
2024-04-27 21:57:07,031:INFO:Importing untrained model
2024-04-27 21:57:07,032:INFO:Dummy Classifier Imported successfully
2024-04-27 21:57:07,033:INFO:Starting cross validation
2024-04-27 21:57:07,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-27 21:57:07,092:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,095:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,100:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,101:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:07,104:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:07,105:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,106:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,108:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:07,108:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,113:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,116:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,118:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,119:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,122:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,123:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,111:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,125:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:07,130:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,130:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,132:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-04-27 21:57:07,132:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,135:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,136:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,140:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,142:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,145:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,145:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,149:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,151:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,154:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,155:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,157:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:07,171:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,173:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:07,173:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,177:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,181:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,185:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,185:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,188:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,189:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,189:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,190:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:07,193:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,193:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,195:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:07,199:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-04-27 21:57:07,199:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,201:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,201:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-04-27 21:57:07,204:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,204:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,206:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,208:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,210:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,210:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,213:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-27 21:57:07,214:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,216:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-27 21:57:07,228:INFO:Calculating mean and std
2024-04-27 21:57:07,229:INFO:Creating metrics dataframe
2024-04-27 21:57:07,231:INFO:Uploading results into container
2024-04-27 21:57:07,233:INFO:Uploading model into container now
2024-04-27 21:57:07,234:INFO:_master_model_container: 14
2024-04-27 21:57:07,234:INFO:_display_container: 2
2024-04-27 21:57:07,234:INFO:DummyClassifier(constant=None, random_state=8650, strategy='prior')
2024-04-27 21:57:07,234:INFO:create_model() successfully completed......................................
2024-04-27 21:57:07,418:INFO:SubProcess create_model() end ==================================
2024-04-27 21:57:07,418:INFO:Creating metrics dataframe
2024-04-27 21:57:07,428:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-27 21:57:07,432:INFO:Initializing create_model()
2024-04-27 21:57:07,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000219B2566110>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8650, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-27 21:57:07,433:INFO:Checking exceptions
2024-04-27 21:57:07,434:INFO:Importing libraries
2024-04-27 21:57:07,434:INFO:Copying training dataset
2024-04-27 21:57:07,439:INFO:Defining folds
2024-04-27 21:57:07,439:INFO:Declaring metric variables
2024-04-27 21:57:07,439:INFO:Importing untrained model
2024-04-27 21:57:07,439:INFO:Declaring custom model
2024-04-27 21:57:07,440:INFO:Random Forest Classifier Imported successfully
2024-04-27 21:57:07,442:INFO:Cross validation set to False
2024-04-27 21:57:07,442:INFO:Fitting Model
2024-04-27 21:57:07,726:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8650, verbose=0,
                       warm_start=False)
2024-04-27 21:57:07,727:INFO:create_model() successfully completed......................................
2024-04-27 21:57:07,921:INFO:_master_model_container: 14
2024-04-27 21:57:07,921:INFO:_display_container: 2
2024-04-27 21:57:07,922:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8650, verbose=0,
                       warm_start=False)
2024-04-27 21:57:07,922:INFO:compare_models() successfully completed......................................
2024-04-27 21:57:07,937:INFO:Initializing save_model()
2024-04-27 21:57:07,938:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8650, verbose=0,
                       warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-27 21:57:07,938:INFO:Adding model into prep_pipe
2024-04-27 21:57:08,059:INFO:best_model.pkl saved in current working directory
2024-04-27 21:57:08,070:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=8650, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-04-27 21:57:08,070:INFO:save_model() successfully completed......................................
2024-05-01 11:11:10,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-01 11:11:10,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-01 11:11:10,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-01 11:11:10,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 11:37:51,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 11:37:51,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 11:37:51,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 11:37:51,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 12:42:04,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 12:42:04,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 12:42:04,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 12:42:04,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-05 12:44:30,378:INFO:PyCaret ClassificationExperiment
2024-05-05 12:44:30,378:INFO:Logging name: clf-default-name
2024-05-05 12:44:30,379:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-05 12:44:30,379:INFO:version 3.3.1
2024-05-05 12:44:30,379:INFO:Initializing setup()
2024-05-05 12:44:30,379:INFO:self.USI: 04ca
2024-05-05 12:44:30,379:INFO:self._variable_keys: {'html_param', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'USI', 'logging_param', 'exp_name_log', 'n_jobs_param', 'data', '_ml_usecase', 'fold_generator', 'is_multiclass', 'pipeline', 'y_train', 'log_plots_param', 'X', 'memory', '_available_plots', 'X_train', 'seed', 'exp_id', 'X_test', 'y', 'fold_groups_param', 'fix_imbalance', 'gpu_param', 'target_param', 'idx'}
2024-05-05 12:44:30,379:INFO:Checking environment
2024-05-05 12:44:30,379:INFO:python_version: 3.10.9
2024-05-05 12:44:30,380:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-05-05 12:44:30,380:INFO:machine: AMD64
2024-05-05 12:44:30,417:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-05 12:44:30,418:INFO:Memory: svmem(total=16541904896, available=2334658560, percent=85.9, used=14207246336, free=2334658560)
2024-05-05 12:44:30,418:INFO:Physical Core: 6
2024-05-05 12:44:30,418:INFO:Logical Core: 12
2024-05-05 12:44:30,418:INFO:Checking libraries
2024-05-05 12:44:30,418:INFO:System:
2024-05-05 12:44:30,418:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-05-05 12:44:30,419:INFO:executable: C:\Users\Asus\anaconda3\python.exe
2024-05-05 12:44:30,419:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-05 12:44:30,419:INFO:PyCaret required dependencies:
2024-05-05 12:44:31,490:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:32,182:INFO:                 pip: 22.3.1
2024-05-05 12:44:32,182:INFO:          setuptools: 65.6.3
2024-05-05 12:44:32,182:INFO:             pycaret: 3.3.1
2024-05-05 12:44:32,182:INFO:             IPython: 8.12.3
2024-05-05 12:44:32,182:INFO:          ipywidgets: 7.6.5
2024-05-05 12:44:32,182:INFO:                tqdm: 4.64.1
2024-05-05 12:44:32,182:INFO:               numpy: 1.23.5
2024-05-05 12:44:32,183:INFO:              pandas: 2.2.2
2024-05-05 12:44:32,183:INFO:              jinja2: 3.1.2
2024-05-05 12:44:32,183:INFO:               scipy: 1.10.0
2024-05-05 12:44:32,183:INFO:              joblib: 1.3.2
2024-05-05 12:44:32,183:INFO:             sklearn: 1.4.2
2024-05-05 12:44:32,183:INFO:                pyod: 1.1.3
2024-05-05 12:44:32,183:INFO:            imblearn: 0.10.1
2024-05-05 12:44:32,183:INFO:   category_encoders: 2.6.3
2024-05-05 12:44:32,183:INFO:            lightgbm: 4.3.0
2024-05-05 12:44:32,183:INFO:               numba: 0.56.4
2024-05-05 12:44:32,183:INFO:            requests: 2.28.1
2024-05-05 12:44:32,184:INFO:          matplotlib: 3.7.0
2024-05-05 12:44:32,184:INFO:          scikitplot: 0.3.7
2024-05-05 12:44:32,184:INFO:         yellowbrick: 1.5
2024-05-05 12:44:32,184:INFO:              plotly: 5.21.0
2024-05-05 12:44:32,184:INFO:    plotly-resampler: Not installed
2024-05-05 12:44:32,185:INFO:             kaleido: 0.2.1
2024-05-05 12:44:32,185:INFO:           schemdraw: 0.15
2024-05-05 12:44:32,185:INFO:         statsmodels: 0.13.5
2024-05-05 12:44:32,185:INFO:              sktime: 0.26.0
2024-05-05 12:44:32,185:INFO:               tbats: 1.1.3
2024-05-05 12:44:32,185:INFO:            pmdarima: 2.0.4
2024-05-05 12:44:32,185:INFO:              psutil: 5.9.0
2024-05-05 12:44:32,185:INFO:          markupsafe: 2.1.1
2024-05-05 12:44:32,185:INFO:             pickle5: Not installed
2024-05-05 12:44:32,185:INFO:         cloudpickle: 2.0.0
2024-05-05 12:44:32,185:INFO:         deprecation: 2.1.0
2024-05-05 12:44:32,185:INFO:              xxhash: 3.4.1
2024-05-05 12:44:32,185:INFO:           wurlitzer: Not installed
2024-05-05 12:44:32,185:INFO:PyCaret optional dependencies:
2024-05-05 12:44:32,214:INFO:                shap: Not installed
2024-05-05 12:44:32,214:INFO:           interpret: Not installed
2024-05-05 12:44:32,215:INFO:                umap: Not installed
2024-05-05 12:44:32,215:INFO:     ydata_profiling: 4.7.0
2024-05-05 12:44:32,215:INFO:  explainerdashboard: Not installed
2024-05-05 12:44:32,215:INFO:             autoviz: Not installed
2024-05-05 12:44:32,216:INFO:           fairlearn: Not installed
2024-05-05 12:44:32,216:INFO:          deepchecks: Not installed
2024-05-05 12:44:32,216:INFO:             xgboost: Not installed
2024-05-05 12:44:32,216:INFO:            catboost: Not installed
2024-05-05 12:44:32,216:INFO:              kmodes: Not installed
2024-05-05 12:44:32,216:INFO:             mlxtend: Not installed
2024-05-05 12:44:32,216:INFO:       statsforecast: Not installed
2024-05-05 12:44:32,217:INFO:        tune_sklearn: Not installed
2024-05-05 12:44:32,217:INFO:                 ray: Not installed
2024-05-05 12:44:32,217:INFO:            hyperopt: Not installed
2024-05-05 12:44:32,217:INFO:              optuna: Not installed
2024-05-05 12:44:32,217:INFO:               skopt: Not installed
2024-05-05 12:44:32,217:INFO:              mlflow: Not installed
2024-05-05 12:44:32,217:INFO:              gradio: Not installed
2024-05-05 12:44:32,217:INFO:             fastapi: Not installed
2024-05-05 12:44:32,217:INFO:             uvicorn: Not installed
2024-05-05 12:44:32,217:INFO:              m2cgen: Not installed
2024-05-05 12:44:32,217:INFO:           evidently: Not installed
2024-05-05 12:44:32,217:INFO:               fugue: Not installed
2024-05-05 12:44:32,217:INFO:           streamlit: 1.33.0
2024-05-05 12:44:32,217:INFO:             prophet: Not installed
2024-05-05 12:44:32,217:INFO:None
2024-05-05 12:44:32,218:INFO:Set up data.
2024-05-05 12:44:32,228:INFO:Set up folding strategy.
2024-05-05 12:44:32,228:INFO:Set up train/test split.
2024-05-05 12:44:32,244:INFO:Set up index.
2024-05-05 12:44:32,245:INFO:Assigning column types.
2024-05-05 12:44:32,251:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-05 12:44:32,348:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-05 12:44:32,359:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-05 12:44:32,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:32,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:32,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-05 12:44:32,541:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-05 12:44:32,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:32,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:32,603:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-05 12:44:32,693:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-05 12:44:32,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:32,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:32,844:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-05 12:44:32,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:32,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:32,903:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-05 12:44:33,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:33,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:33,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:33,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:33,203:INFO:Preparing preprocessing pipeline...
2024-05-05 12:44:33,207:INFO:Set up label encoding.
2024-05-05 12:44:33,207:INFO:Set up simple imputation.
2024-05-05 12:44:33,289:INFO:Finished creating preprocessing pipeline.
2024-05-05 12:44:33,301:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-05 12:44:33,302:INFO:Creating final display dataframe.
2024-05-05 12:44:33,480:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               5354
1                        Target                                            Species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 6)
5        Transformed data shape                                           (150, 6)
6   Transformed train set shape                                           (105, 6)
7    Transformed test set shape                                            (45, 6)
8              Numeric features                                                  5
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               04ca
2024-05-05 12:44:33,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:33,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:33,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:33,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-05 12:44:33,822:INFO:setup() successfully completed in 3.45s...............
2024-05-05 12:44:33,837:INFO:Initializing compare_models()
2024-05-05 12:44:33,837:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-05 12:44:33,837:INFO:Checking exceptions
2024-05-05 12:44:33,846:INFO:Preparing display monitor
2024-05-05 12:44:33,853:INFO:Initializing Logistic Regression
2024-05-05 12:44:33,853:INFO:Total runtime is 0.0 minutes
2024-05-05 12:44:33,855:INFO:SubProcess create_model() called ==================================
2024-05-05 12:44:33,855:INFO:Initializing create_model()
2024-05-05 12:44:33,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:44:33,855:INFO:Checking exceptions
2024-05-05 12:44:33,855:INFO:Importing libraries
2024-05-05 12:44:33,855:INFO:Copying training dataset
2024-05-05 12:44:33,863:INFO:Defining folds
2024-05-05 12:44:33,863:INFO:Declaring metric variables
2024-05-05 12:44:33,863:INFO:Importing untrained model
2024-05-05 12:44:33,864:INFO:Logistic Regression Imported successfully
2024-05-05 12:44:33,864:INFO:Starting cross validation
2024-05-05 12:44:33,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:44:48,345:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,375:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,379:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,393:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,413:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,547:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,551:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,563:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,612:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:48,623:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:44:49,682:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:49,690:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,717:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,725:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,843:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:49,847:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:49,853:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,859:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,865:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,869:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,881:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,883:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,897:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:49,940:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,959:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,967:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:49,969:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,977:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,987:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:49,996:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,052:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:50,073:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,083:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,091:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,143:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:50,155:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,162:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:50,166:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,178:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,182:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,196:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,202:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:50,205:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,215:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,226:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,234:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,239:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:44:50,249:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,262:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,269:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,300:INFO:Calculating mean and std
2024-05-05 12:44:50,302:INFO:Creating metrics dataframe
2024-05-05 12:44:50,308:INFO:Uploading results into container
2024-05-05 12:44:50,310:INFO:Uploading model into container now
2024-05-05 12:44:50,311:INFO:_master_model_container: 1
2024-05-05 12:44:50,311:INFO:_display_container: 2
2024-05-05 12:44:50,312:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5354, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-05 12:44:50,313:INFO:create_model() successfully completed......................................
2024-05-05 12:44:50,578:INFO:SubProcess create_model() end ==================================
2024-05-05 12:44:50,578:INFO:Creating metrics dataframe
2024-05-05 12:44:50,582:INFO:Initializing K Neighbors Classifier
2024-05-05 12:44:50,582:INFO:Total runtime is 0.27881675958633423 minutes
2024-05-05 12:44:50,584:INFO:SubProcess create_model() called ==================================
2024-05-05 12:44:50,584:INFO:Initializing create_model()
2024-05-05 12:44:50,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:44:50,584:INFO:Checking exceptions
2024-05-05 12:44:50,585:INFO:Importing libraries
2024-05-05 12:44:50,585:INFO:Copying training dataset
2024-05-05 12:44:50,592:INFO:Defining folds
2024-05-05 12:44:50,592:INFO:Declaring metric variables
2024-05-05 12:44:50,593:INFO:Importing untrained model
2024-05-05 12:44:50,594:INFO:K Neighbors Classifier Imported successfully
2024-05-05 12:44:50,596:INFO:Starting cross validation
2024-05-05 12:44:50,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:44:50,755:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:44:50,755:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:44:50,756:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:44:50,757:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:44:50,770:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:44:50,773:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:44:50,775:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:44:50,775:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:44:50,776:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:44:50,777:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:44:50,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,779:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,781:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:44:50,781:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,785:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,790:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:44:50,797:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,798:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:44:50,799:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,803:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,807:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,813:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,815:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,816:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:44:50,822:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,826:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,827:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,829:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:44:50,830:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:44:50,833:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,835:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,836:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,844:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,852:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:44:50,853:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:00,162:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:45:00,162:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\dask\dataframe\__init__.py:31: FutureWarning: 
Dask dataframe query planning is disabled because dask-expr is not installed.

You can install it with `pip install dask[dataframe]` or `conda install dask`.
This will raise in a future version.

  warnings.warn(msg, FutureWarning)

2024-05-05 12:45:01,012:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,012:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,025:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,025:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,032:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,032:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,050:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,050:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,063:INFO:Calculating mean and std
2024-05-05 12:45:01,064:INFO:Creating metrics dataframe
2024-05-05 12:45:01,070:INFO:Uploading results into container
2024-05-05 12:45:01,071:INFO:Uploading model into container now
2024-05-05 12:45:01,071:INFO:_master_model_container: 2
2024-05-05 12:45:01,071:INFO:_display_container: 2
2024-05-05 12:45:01,072:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-05 12:45:01,072:INFO:create_model() successfully completed......................................
2024-05-05 12:45:01,308:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:01,308:INFO:Creating metrics dataframe
2024-05-05 12:45:01,315:INFO:Initializing Naive Bayes
2024-05-05 12:45:01,315:INFO:Total runtime is 0.4577052235603333 minutes
2024-05-05 12:45:01,315:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:01,317:INFO:Initializing create_model()
2024-05-05 12:45:01,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:01,317:INFO:Checking exceptions
2024-05-05 12:45:01,317:INFO:Importing libraries
2024-05-05 12:45:01,317:INFO:Copying training dataset
2024-05-05 12:45:01,324:INFO:Defining folds
2024-05-05 12:45:01,324:INFO:Declaring metric variables
2024-05-05 12:45:01,325:INFO:Importing untrained model
2024-05-05 12:45:01,326:INFO:Naive Bayes Imported successfully
2024-05-05 12:45:01,327:INFO:Starting cross validation
2024-05-05 12:45:01,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:01,405:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,417:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,419:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,421:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,423:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,425:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,425:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,426:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,428:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,434:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,436:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,436:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,446:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,448:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,448:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,449:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,451:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,451:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,452:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,452:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,453:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,453:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,456:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,457:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,457:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,458:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,459:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,459:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,461:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,461:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,462:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,461:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,465:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,466:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,467:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,469:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,469:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,470:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,470:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,470:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,473:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,474:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,475:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,477:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,479:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,479:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,482:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,485:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,500:INFO:Calculating mean and std
2024-05-05 12:45:01,501:INFO:Creating metrics dataframe
2024-05-05 12:45:01,505:INFO:Uploading results into container
2024-05-05 12:45:01,505:INFO:Uploading model into container now
2024-05-05 12:45:01,507:INFO:_master_model_container: 3
2024-05-05 12:45:01,507:INFO:_display_container: 2
2024-05-05 12:45:01,507:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-05 12:45:01,507:INFO:create_model() successfully completed......................................
2024-05-05 12:45:01,727:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:01,727:INFO:Creating metrics dataframe
2024-05-05 12:45:01,732:INFO:Initializing Decision Tree Classifier
2024-05-05 12:45:01,732:INFO:Total runtime is 0.4646540006001791 minutes
2024-05-05 12:45:01,733:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:01,733:INFO:Initializing create_model()
2024-05-05 12:45:01,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:01,733:INFO:Checking exceptions
2024-05-05 12:45:01,735:INFO:Importing libraries
2024-05-05 12:45:01,735:INFO:Copying training dataset
2024-05-05 12:45:01,740:INFO:Defining folds
2024-05-05 12:45:01,740:INFO:Declaring metric variables
2024-05-05 12:45:01,741:INFO:Importing untrained model
2024-05-05 12:45:01,742:INFO:Decision Tree Classifier Imported successfully
2024-05-05 12:45:01,743:INFO:Starting cross validation
2024-05-05 12:45:01,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:01,825:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,825:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,826:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,827:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,827:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,829:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,831:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,831:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,833:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,833:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,836:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,838:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,838:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,841:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,842:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,843:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,846:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,846:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,848:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,849:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,851:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,851:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,852:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,853:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,859:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,860:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,860:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,860:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,862:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,868:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,868:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,868:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,869:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,871:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:01,871:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:01,873:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:01,875:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,876:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,878:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,882:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,886:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,892:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,893:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:01,918:INFO:Calculating mean and std
2024-05-05 12:45:01,919:INFO:Creating metrics dataframe
2024-05-05 12:45:01,922:INFO:Uploading results into container
2024-05-05 12:45:01,923:INFO:Uploading model into container now
2024-05-05 12:45:01,924:INFO:_master_model_container: 4
2024-05-05 12:45:01,924:INFO:_display_container: 2
2024-05-05 12:45:01,924:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5354, splitter='best')
2024-05-05 12:45:01,924:INFO:create_model() successfully completed......................................
2024-05-05 12:45:02,147:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:02,148:INFO:Creating metrics dataframe
2024-05-05 12:45:02,156:INFO:Initializing SVM - Linear Kernel
2024-05-05 12:45:02,156:INFO:Total runtime is 0.47171285152435305 minutes
2024-05-05 12:45:02,157:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:02,158:INFO:Initializing create_model()
2024-05-05 12:45:02,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:02,158:INFO:Checking exceptions
2024-05-05 12:45:02,158:INFO:Importing libraries
2024-05-05 12:45:02,158:INFO:Copying training dataset
2024-05-05 12:45:02,166:INFO:Defining folds
2024-05-05 12:45:02,166:INFO:Declaring metric variables
2024-05-05 12:45:02,167:INFO:Importing untrained model
2024-05-05 12:45:02,168:INFO:SVM - Linear Kernel Imported successfully
2024-05-05 12:45:02,169:INFO:Starting cross validation
2024-05-05 12:45:02,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:02,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,363:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,372:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,373:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,374:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,374:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,379:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,380:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,381:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,382:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,384:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:02,385:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,386:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,387:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,388:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,389:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:02,390:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,391:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:02,392:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,392:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:02,392:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,392:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,394:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,395:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,395:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:02,397:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,399:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,399:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,400:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,401:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,401:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,403:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,403:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,409:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,412:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,412:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,416:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:02,417:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,418:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,419:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,430:INFO:Calculating mean and std
2024-05-05 12:45:02,431:INFO:Creating metrics dataframe
2024-05-05 12:45:02,435:INFO:Uploading results into container
2024-05-05 12:45:02,435:INFO:Uploading model into container now
2024-05-05 12:45:02,436:INFO:_master_model_container: 5
2024-05-05 12:45:02,436:INFO:_display_container: 2
2024-05-05 12:45:02,437:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5354, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-05 12:45:02,437:INFO:create_model() successfully completed......................................
2024-05-05 12:45:02,661:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:02,661:INFO:Creating metrics dataframe
2024-05-05 12:45:02,668:INFO:Initializing Ridge Classifier
2024-05-05 12:45:02,669:INFO:Total runtime is 0.4802600105603536 minutes
2024-05-05 12:45:02,669:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:02,670:INFO:Initializing create_model()
2024-05-05 12:45:02,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:02,670:INFO:Checking exceptions
2024-05-05 12:45:02,670:INFO:Importing libraries
2024-05-05 12:45:02,671:INFO:Copying training dataset
2024-05-05 12:45:02,677:INFO:Defining folds
2024-05-05 12:45:02,677:INFO:Declaring metric variables
2024-05-05 12:45:02,678:INFO:Importing untrained model
2024-05-05 12:45:02,679:INFO:Ridge Classifier Imported successfully
2024-05-05 12:45:02,679:INFO:Starting cross validation
2024-05-05 12:45:02,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:02,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,801:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,804:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,806:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,808:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,810:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,814:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,816:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,817:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,820:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,823:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,823:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,824:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,824:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,829:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,835:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,835:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,835:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,837:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,840:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,842:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,845:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,848:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,848:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,850:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,851:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,854:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,858:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,859:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:02,859:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,860:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,863:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,863:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,863:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,871:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,873:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,879:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:02,896:INFO:Calculating mean and std
2024-05-05 12:45:02,897:INFO:Creating metrics dataframe
2024-05-05 12:45:02,901:INFO:Uploading results into container
2024-05-05 12:45:02,902:INFO:Uploading model into container now
2024-05-05 12:45:02,903:INFO:_master_model_container: 6
2024-05-05 12:45:02,903:INFO:_display_container: 2
2024-05-05 12:45:02,903:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5354, solver='auto',
                tol=0.0001)
2024-05-05 12:45:02,903:INFO:create_model() successfully completed......................................
2024-05-05 12:45:03,125:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:03,126:INFO:Creating metrics dataframe
2024-05-05 12:45:03,134:INFO:Initializing Random Forest Classifier
2024-05-05 12:45:03,134:INFO:Total runtime is 0.48800573746363324 minutes
2024-05-05 12:45:03,134:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:03,134:INFO:Initializing create_model()
2024-05-05 12:45:03,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:03,135:INFO:Checking exceptions
2024-05-05 12:45:03,135:INFO:Importing libraries
2024-05-05 12:45:03,135:INFO:Copying training dataset
2024-05-05 12:45:03,141:INFO:Defining folds
2024-05-05 12:45:03,141:INFO:Declaring metric variables
2024-05-05 12:45:03,142:INFO:Importing untrained model
2024-05-05 12:45:03,143:INFO:Random Forest Classifier Imported successfully
2024-05-05 12:45:03,145:INFO:Starting cross validation
2024-05-05 12:45:03,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:03,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,743:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,746:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:03,746:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:03,746:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:03,750:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,750:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,756:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,759:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,760:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,760:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:03,762:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:03,765:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,767:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,767:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,767:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,768:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,773:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,775:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,778:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,779:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,779:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,780:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:03,782:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:03,782:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:03,782:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,786:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,786:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,787:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,794:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,795:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,795:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,795:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:03,796:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,799:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,801:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,802:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,805:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,810:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,909:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:03,911:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:03,914:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,919:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,924:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:03,948:INFO:Calculating mean and std
2024-05-05 12:45:03,949:INFO:Creating metrics dataframe
2024-05-05 12:45:03,952:INFO:Uploading results into container
2024-05-05 12:45:03,953:INFO:Uploading model into container now
2024-05-05 12:45:03,953:INFO:_master_model_container: 7
2024-05-05 12:45:03,953:INFO:_display_container: 2
2024-05-05 12:45:03,955:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5354, verbose=0,
                       warm_start=False)
2024-05-05 12:45:03,955:INFO:create_model() successfully completed......................................
2024-05-05 12:45:04,167:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:04,167:INFO:Creating metrics dataframe
2024-05-05 12:45:04,171:INFO:Initializing Quadratic Discriminant Analysis
2024-05-05 12:45:04,171:INFO:Total runtime is 0.5053038636843363 minutes
2024-05-05 12:45:04,173:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:04,173:INFO:Initializing create_model()
2024-05-05 12:45:04,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:04,173:INFO:Checking exceptions
2024-05-05 12:45:04,173:INFO:Importing libraries
2024-05-05 12:45:04,173:INFO:Copying training dataset
2024-05-05 12:45:04,181:INFO:Defining folds
2024-05-05 12:45:04,181:INFO:Declaring metric variables
2024-05-05 12:45:04,182:INFO:Importing untrained model
2024-05-05 12:45:04,182:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-05 12:45:04,183:INFO:Starting cross validation
2024-05-05 12:45:04,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:04,275:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,277:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,278:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,279:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,281:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,283:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,286:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,287:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,287:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,290:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,290:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,291:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,291:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,291:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,292:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,294:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,294:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,295:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,295:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,298:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,298:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,299:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,300:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,300:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,301:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,302:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,302:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,305:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,306:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,306:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,309:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,309:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,310:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,310:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,315:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,316:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,317:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,319:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,325:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,327:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,351:INFO:Calculating mean and std
2024-05-05 12:45:04,353:INFO:Creating metrics dataframe
2024-05-05 12:45:04,356:INFO:Uploading results into container
2024-05-05 12:45:04,357:INFO:Uploading model into container now
2024-05-05 12:45:04,357:INFO:_master_model_container: 8
2024-05-05 12:45:04,357:INFO:_display_container: 2
2024-05-05 12:45:04,357:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-05 12:45:04,357:INFO:create_model() successfully completed......................................
2024-05-05 12:45:04,567:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:04,568:INFO:Creating metrics dataframe
2024-05-05 12:45:04,575:INFO:Initializing Ada Boost Classifier
2024-05-05 12:45:04,576:INFO:Total runtime is 0.512039597829183 minutes
2024-05-05 12:45:04,576:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:04,576:INFO:Initializing create_model()
2024-05-05 12:45:04,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:04,577:INFO:Checking exceptions
2024-05-05 12:45:04,577:INFO:Importing libraries
2024-05-05 12:45:04,577:INFO:Copying training dataset
2024-05-05 12:45:04,583:INFO:Defining folds
2024-05-05 12:45:04,585:INFO:Declaring metric variables
2024-05-05 12:45:04,585:INFO:Importing untrained model
2024-05-05 12:45:04,586:INFO:Ada Boost Classifier Imported successfully
2024-05-05 12:45:04,587:INFO:Starting cross validation
2024-05-05 12:45:04,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:04,634:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,639:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,648:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,655:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,687:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,686:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,687:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,690:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,698:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,699:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-05 12:45:04,960:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,965:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,972:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,981:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,982:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,985:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:04,986:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,990:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,996:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:04,998:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,000:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:05,004:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,006:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,013:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,018:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:05,022:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,023:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,023:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:05,026:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:05,027:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,027:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:05,030:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,031:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,031:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,031:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:05,034:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,035:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,038:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,039:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:05,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,042:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,046:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,046:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,048:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,050:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,055:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,061:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:05,081:INFO:Calculating mean and std
2024-05-05 12:45:05,083:INFO:Creating metrics dataframe
2024-05-05 12:45:05,087:INFO:Uploading results into container
2024-05-05 12:45:05,088:INFO:Uploading model into container now
2024-05-05 12:45:05,088:INFO:_master_model_container: 9
2024-05-05 12:45:05,088:INFO:_display_container: 2
2024-05-05 12:45:05,088:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5354)
2024-05-05 12:45:05,088:INFO:create_model() successfully completed......................................
2024-05-05 12:45:05,297:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:05,297:INFO:Creating metrics dataframe
2024-05-05 12:45:05,305:INFO:Initializing Gradient Boosting Classifier
2024-05-05 12:45:05,305:INFO:Total runtime is 0.5241910974184673 minutes
2024-05-05 12:45:05,305:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:05,305:INFO:Initializing create_model()
2024-05-05 12:45:05,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:05,305:INFO:Checking exceptions
2024-05-05 12:45:05,306:INFO:Importing libraries
2024-05-05 12:45:05,306:INFO:Copying training dataset
2024-05-05 12:45:05,314:INFO:Defining folds
2024-05-05 12:45:05,314:INFO:Declaring metric variables
2024-05-05 12:45:05,315:INFO:Importing untrained model
2024-05-05 12:45:05,316:INFO:Gradient Boosting Classifier Imported successfully
2024-05-05 12:45:05,316:INFO:Starting cross validation
2024-05-05 12:45:05,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:06,067:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,071:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,080:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,089:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,100:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,104:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,113:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,120:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,120:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,126:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,135:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,143:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,143:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,148:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,151:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,156:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,157:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,158:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,162:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,164:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,164:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,169:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,172:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,177:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,179:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,180:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,182:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,183:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,189:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,189:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,194:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,201:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,204:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,208:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,213:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,252:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,254:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,259:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,266:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,277:INFO:Calculating mean and std
2024-05-05 12:45:06,278:INFO:Creating metrics dataframe
2024-05-05 12:45:06,281:INFO:Uploading results into container
2024-05-05 12:45:06,282:INFO:Uploading model into container now
2024-05-05 12:45:06,283:INFO:_master_model_container: 10
2024-05-05 12:45:06,283:INFO:_display_container: 2
2024-05-05 12:45:06,283:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5354, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-05 12:45:06,283:INFO:create_model() successfully completed......................................
2024-05-05 12:45:06,483:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:06,483:INFO:Creating metrics dataframe
2024-05-05 12:45:06,489:INFO:Initializing Linear Discriminant Analysis
2024-05-05 12:45:06,489:INFO:Total runtime is 0.5439238667488099 minutes
2024-05-05 12:45:06,490:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:06,490:INFO:Initializing create_model()
2024-05-05 12:45:06,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:06,490:INFO:Checking exceptions
2024-05-05 12:45:06,490:INFO:Importing libraries
2024-05-05 12:45:06,490:INFO:Copying training dataset
2024-05-05 12:45:06,496:INFO:Defining folds
2024-05-05 12:45:06,496:INFO:Declaring metric variables
2024-05-05 12:45:06,497:INFO:Importing untrained model
2024-05-05 12:45:06,498:INFO:Linear Discriminant Analysis Imported successfully
2024-05-05 12:45:06,498:INFO:Starting cross validation
2024-05-05 12:45:06,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:06,581:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,585:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,585:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,585:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,586:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,589:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,589:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,590:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,591:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,595:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,597:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,597:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,597:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,598:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,601:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,603:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,605:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,605:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,605:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,605:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,606:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,606:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,609:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,610:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,615:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,615:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,615:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,620:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,622:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,623:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,627:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,627:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-05 12:45:06,628:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,630:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,630:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,638:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,638:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,643:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,645:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:06,663:INFO:Calculating mean and std
2024-05-05 12:45:06,665:INFO:Creating metrics dataframe
2024-05-05 12:45:06,669:INFO:Uploading results into container
2024-05-05 12:45:06,670:INFO:Uploading model into container now
2024-05-05 12:45:06,671:INFO:_master_model_container: 11
2024-05-05 12:45:06,672:INFO:_display_container: 2
2024-05-05 12:45:06,672:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-05 12:45:06,672:INFO:create_model() successfully completed......................................
2024-05-05 12:45:06,884:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:06,884:INFO:Creating metrics dataframe
2024-05-05 12:45:06,893:INFO:Initializing Extra Trees Classifier
2024-05-05 12:45:06,893:INFO:Total runtime is 0.5506686806678772 minutes
2024-05-05 12:45:06,893:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:06,895:INFO:Initializing create_model()
2024-05-05 12:45:06,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:06,895:INFO:Checking exceptions
2024-05-05 12:45:06,895:INFO:Importing libraries
2024-05-05 12:45:06,895:INFO:Copying training dataset
2024-05-05 12:45:06,907:INFO:Defining folds
2024-05-05 12:45:06,907:INFO:Declaring metric variables
2024-05-05 12:45:06,911:INFO:Importing untrained model
2024-05-05 12:45:06,921:INFO:Extra Trees Classifier Imported successfully
2024-05-05 12:45:06,922:INFO:Starting cross validation
2024-05-05 12:45:06,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:07,391:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,391:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,393:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:07,393:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:07,398:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,400:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,406:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,407:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,408:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,409:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:07,413:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,413:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,420:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,420:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,423:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,423:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,423:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:07,424:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:07,424:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,425:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:07,429:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,429:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,429:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,430:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,436:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,438:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,438:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,443:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,445:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,446:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,452:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,452:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,453:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:07,453:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:07,458:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,458:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,464:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,465:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,466:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,469:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:07,469:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,470:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,471:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,476:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,481:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:07,482:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:07,483:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,484:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,490:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,494:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:07,504:INFO:Calculating mean and std
2024-05-05 12:45:07,506:INFO:Creating metrics dataframe
2024-05-05 12:45:07,511:INFO:Uploading results into container
2024-05-05 12:45:07,512:INFO:Uploading model into container now
2024-05-05 12:45:07,513:INFO:_master_model_container: 12
2024-05-05 12:45:07,513:INFO:_display_container: 2
2024-05-05 12:45:07,514:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5354, verbose=0,
                     warm_start=False)
2024-05-05 12:45:07,514:INFO:create_model() successfully completed......................................
2024-05-05 12:45:07,713:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:07,713:INFO:Creating metrics dataframe
2024-05-05 12:45:07,720:INFO:Initializing Light Gradient Boosting Machine
2024-05-05 12:45:07,720:INFO:Total runtime is 0.5644394874572755 minutes
2024-05-05 12:45:07,720:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:07,721:INFO:Initializing create_model()
2024-05-05 12:45:07,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:07,721:INFO:Checking exceptions
2024-05-05 12:45:07,721:INFO:Importing libraries
2024-05-05 12:45:07,721:INFO:Copying training dataset
2024-05-05 12:45:07,730:INFO:Defining folds
2024-05-05 12:45:07,730:INFO:Declaring metric variables
2024-05-05 12:45:07,731:INFO:Importing untrained model
2024-05-05 12:45:07,732:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-05 12:45:07,732:INFO:Starting cross validation
2024-05-05 12:45:07,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:10,088:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,090:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:10,097:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,106:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,121:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,267:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,271:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:10,276:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,288:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,304:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,439:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,441:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:10,448:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,474:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,488:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,537:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,539:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:10,550:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,561:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,573:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,690:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,692:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:10,707:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,719:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,723:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,727:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:10,738:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,738:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,753:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,762:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,788:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,790:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:10,798:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,817:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,833:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,853:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,855:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:10,869:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,874:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,876:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:10,882:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,883:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,893:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,907:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,953:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:10,955:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:10,960:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,974:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:10,983:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,000:INFO:Calculating mean and std
2024-05-05 12:45:11,002:INFO:Creating metrics dataframe
2024-05-05 12:45:11,007:INFO:Uploading results into container
2024-05-05 12:45:11,008:INFO:Uploading model into container now
2024-05-05 12:45:11,009:INFO:_master_model_container: 13
2024-05-05 12:45:11,009:INFO:_display_container: 2
2024-05-05 12:45:11,011:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5354, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-05 12:45:11,011:INFO:create_model() successfully completed......................................
2024-05-05 12:45:11,207:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:11,207:INFO:Creating metrics dataframe
2024-05-05 12:45:11,212:INFO:Initializing Dummy Classifier
2024-05-05 12:45:11,212:INFO:Total runtime is 0.6226415991783143 minutes
2024-05-05 12:45:11,213:INFO:SubProcess create_model() called ==================================
2024-05-05 12:45:11,213:INFO:Initializing create_model()
2024-05-05 12:45:11,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018A5B290CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:11,213:INFO:Checking exceptions
2024-05-05 12:45:11,214:INFO:Importing libraries
2024-05-05 12:45:11,214:INFO:Copying training dataset
2024-05-05 12:45:11,220:INFO:Defining folds
2024-05-05 12:45:11,220:INFO:Declaring metric variables
2024-05-05 12:45:11,221:INFO:Importing untrained model
2024-05-05 12:45:11,221:INFO:Dummy Classifier Imported successfully
2024-05-05 12:45:11,222:INFO:Starting cross validation
2024-05-05 12:45:11,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-05 12:45:11,279:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,281:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:11,284:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,289:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,291:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,291:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:11,292:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,293:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:11,296:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,299:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,299:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,300:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,301:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:11,305:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,307:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,310:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,313:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,313:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,314:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 11)

  warnings.warn(

2024-05-05 12:45:11,314:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,316:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,316:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,318:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,321:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,323:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,324:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,328:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,328:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,329:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,331:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:11,332:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,332:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,348:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,349:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:11,354:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,355:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:11,356:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,359:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,360:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,360:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:11,362:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,364:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,365:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,367:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py:575: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  values = np.array([convert(v) for v in values])

2024-05-05 12:45:11,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,368:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "C:\Users\Asus\anaconda3\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "C:\Users\Asus\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\frame.py", line 867, in __init__
    mgr = ndarray_to_mgr(
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 336, in ndarray_to_mgr
    _check_values_indices_shape_match(values, index, columns)
  File "C:\Users\Asus\anaconda3\lib\site-packages\pandas\core\internals\construction.py", line 420, in _check_values_indices_shape_match
    raise ValueError(f"Shape of passed values is {passed}, indices imply {implied}")
ValueError: Shape of passed values is (2, 1), indices imply (2, 10)

  warnings.warn(

2024-05-05 12:45:11,369:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,371:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,371:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,373:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,373:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,373:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,376:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,378:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,381:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,384:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-05 12:45:11,388:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-05 12:45:11,401:INFO:Calculating mean and std
2024-05-05 12:45:11,404:INFO:Creating metrics dataframe
2024-05-05 12:45:11,406:INFO:Uploading results into container
2024-05-05 12:45:11,407:INFO:Uploading model into container now
2024-05-05 12:45:11,407:INFO:_master_model_container: 14
2024-05-05 12:45:11,408:INFO:_display_container: 2
2024-05-05 12:45:11,408:INFO:DummyClassifier(constant=None, random_state=5354, strategy='prior')
2024-05-05 12:45:11,408:INFO:create_model() successfully completed......................................
2024-05-05 12:45:11,605:INFO:SubProcess create_model() end ==================================
2024-05-05 12:45:11,605:INFO:Creating metrics dataframe
2024-05-05 12:45:11,613:WARNING:C:\Users\Asus\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-05 12:45:11,619:INFO:Initializing create_model()
2024-05-05 12:45:11,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018A5C4CB8B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5354, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-05 12:45:11,619:INFO:Checking exceptions
2024-05-05 12:45:11,620:INFO:Importing libraries
2024-05-05 12:45:11,620:INFO:Copying training dataset
2024-05-05 12:45:11,627:INFO:Defining folds
2024-05-05 12:45:11,627:INFO:Declaring metric variables
2024-05-05 12:45:11,628:INFO:Importing untrained model
2024-05-05 12:45:11,628:INFO:Declaring custom model
2024-05-05 12:45:11,629:INFO:Random Forest Classifier Imported successfully
2024-05-05 12:45:11,631:INFO:Cross validation set to False
2024-05-05 12:45:11,631:INFO:Fitting Model
2024-05-05 12:45:11,960:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5354, verbose=0,
                       warm_start=False)
2024-05-05 12:45:11,960:INFO:create_model() successfully completed......................................
2024-05-05 12:45:12,219:INFO:_master_model_container: 14
2024-05-05 12:45:12,221:INFO:_display_container: 2
2024-05-05 12:45:12,222:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5354, verbose=0,
                       warm_start=False)
2024-05-05 12:45:12,222:INFO:compare_models() successfully completed......................................
2024-05-05 12:45:12,242:INFO:Initializing save_model()
2024-05-05 12:45:12,243:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5354, verbose=0,
                       warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-05 12:45:12,243:INFO:Adding model into prep_pipe
2024-05-05 12:45:12,355:INFO:best_model.pkl saved in current working directory
2024-05-05 12:45:12,369:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=5354, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-05-05 12:45:12,369:INFO:save_model() successfully completed......................................
2024-05-07 15:26:20,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-07 15:26:20,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-07 15:26:20,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-07 15:26:20,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-07 15:27:37,074:INFO:PyCaret ClassificationExperiment
2024-05-07 15:27:37,074:INFO:Logging name: clf-default-name
2024-05-07 15:27:37,074:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-07 15:27:37,074:INFO:version 3.3.2
2024-05-07 15:27:37,074:INFO:Initializing setup()
2024-05-07 15:27:37,074:INFO:self.USI: c68c
2024-05-07 15:27:37,074:INFO:self._variable_keys: {'X', 'data', 'y_train', 'fix_imbalance', 'idx', 'html_param', 'log_plots_param', '_available_plots', 'gpu_param', 'is_multiclass', 'pipeline', 'y_test', 'USI', 'fold_groups_param', 'X_test', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'y', 'logging_param', 'n_jobs_param', 'X_train', 'memory', 'fold_generator', 'target_param', 'seed', 'gpu_n_jobs_param', 'exp_name_log'}
2024-05-07 15:27:37,074:INFO:Checking environment
2024-05-07 15:27:37,074:INFO:python_version: 3.10.14
2024-05-07 15:27:37,074:INFO:python_build: ('main', 'Mar 21 2024 16:20:14')
2024-05-07 15:27:37,074:INFO:machine: AMD64
2024-05-07 15:27:37,083:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-07 15:27:37,090:INFO:Memory: svmem(total=16541904896, available=2006634496, percent=87.9, used=14535270400, free=2006634496)
2024-05-07 15:27:37,090:INFO:Physical Core: 6
2024-05-07 15:27:37,090:INFO:Logical Core: 12
2024-05-07 15:27:37,090:INFO:Checking libraries
2024-05-07 15:27:37,091:INFO:System:
2024-05-07 15:27:37,091:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, Mar 21 2024, 16:20:14) [MSC v.1916 64 bit (AMD64)]
2024-05-07 15:27:37,091:INFO:executable: D:\streamlit projects\ML project\ml_project\Scripts\python.exe
2024-05-07 15:27:37,091:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-07 15:27:37,091:INFO:PyCaret required dependencies:
2024-05-07 15:27:37,143:INFO:                 pip: 23.0.1
2024-05-07 15:27:37,143:INFO:          setuptools: 65.5.0
2024-05-07 15:27:37,143:INFO:             pycaret: 3.3.2
2024-05-07 15:27:37,143:INFO:             IPython: 8.24.0
2024-05-07 15:27:37,143:INFO:          ipywidgets: 8.1.2
2024-05-07 15:27:37,143:INFO:                tqdm: 4.66.4
2024-05-07 15:27:37,143:INFO:               numpy: 1.26.4
2024-05-07 15:27:37,143:INFO:              pandas: 2.1.4
2024-05-07 15:27:37,143:INFO:              jinja2: 3.1.4
2024-05-07 15:27:37,143:INFO:               scipy: 1.11.4
2024-05-07 15:27:37,143:INFO:              joblib: 1.3.2
2024-05-07 15:27:37,143:INFO:             sklearn: 1.4.2
2024-05-07 15:27:37,143:INFO:                pyod: 1.1.3
2024-05-07 15:27:37,143:INFO:            imblearn: 0.12.2
2024-05-07 15:27:37,143:INFO:   category_encoders: 2.6.3
2024-05-07 15:27:37,143:INFO:            lightgbm: 4.3.0
2024-05-07 15:27:37,143:INFO:               numba: 0.59.1
2024-05-07 15:27:37,143:INFO:            requests: 2.31.0
2024-05-07 15:27:37,143:INFO:          matplotlib: 3.7.5
2024-05-07 15:27:37,143:INFO:          scikitplot: 0.3.7
2024-05-07 15:27:37,143:INFO:         yellowbrick: 1.5
2024-05-07 15:27:37,143:INFO:              plotly: 5.22.0
2024-05-07 15:27:37,143:INFO:    plotly-resampler: Not installed
2024-05-07 15:27:37,143:INFO:             kaleido: 0.2.1
2024-05-07 15:27:37,143:INFO:           schemdraw: 0.15
2024-05-07 15:27:37,143:INFO:         statsmodels: 0.14.2
2024-05-07 15:27:37,143:INFO:              sktime: 0.26.0
2024-05-07 15:27:37,143:INFO:               tbats: 1.1.3
2024-05-07 15:27:37,143:INFO:            pmdarima: 2.0.4
2024-05-07 15:27:37,143:INFO:              psutil: 5.9.8
2024-05-07 15:27:37,143:INFO:          markupsafe: 2.1.5
2024-05-07 15:27:37,143:INFO:             pickle5: Not installed
2024-05-07 15:27:37,143:INFO:         cloudpickle: 3.0.0
2024-05-07 15:27:37,143:INFO:         deprecation: 2.1.0
2024-05-07 15:27:37,143:INFO:              xxhash: 3.4.1
2024-05-07 15:27:37,143:INFO:           wurlitzer: Not installed
2024-05-07 15:27:37,143:INFO:PyCaret optional dependencies:
2024-05-07 15:27:37,154:INFO:                shap: Not installed
2024-05-07 15:27:37,154:INFO:           interpret: Not installed
2024-05-07 15:27:37,154:INFO:                umap: Not installed
2024-05-07 15:27:37,154:INFO:     ydata_profiling: 4.7.0
2024-05-07 15:27:37,154:INFO:  explainerdashboard: Not installed
2024-05-07 15:27:37,154:INFO:             autoviz: Not installed
2024-05-07 15:27:37,154:INFO:           fairlearn: Not installed
2024-05-07 15:27:37,154:INFO:          deepchecks: Not installed
2024-05-07 15:27:37,154:INFO:             xgboost: Not installed
2024-05-07 15:27:37,154:INFO:            catboost: Not installed
2024-05-07 15:27:37,154:INFO:              kmodes: Not installed
2024-05-07 15:27:37,154:INFO:             mlxtend: Not installed
2024-05-07 15:27:37,154:INFO:       statsforecast: Not installed
2024-05-07 15:27:37,154:INFO:        tune_sklearn: Not installed
2024-05-07 15:27:37,154:INFO:                 ray: Not installed
2024-05-07 15:27:37,155:INFO:            hyperopt: Not installed
2024-05-07 15:27:37,155:INFO:              optuna: Not installed
2024-05-07 15:27:37,155:INFO:               skopt: Not installed
2024-05-07 15:27:37,155:INFO:              mlflow: Not installed
2024-05-07 15:27:37,155:INFO:              gradio: Not installed
2024-05-07 15:27:37,155:INFO:             fastapi: Not installed
2024-05-07 15:27:37,155:INFO:             uvicorn: Not installed
2024-05-07 15:27:37,155:INFO:              m2cgen: Not installed
2024-05-07 15:27:37,155:INFO:           evidently: Not installed
2024-05-07 15:27:37,155:INFO:               fugue: Not installed
2024-05-07 15:27:37,155:INFO:           streamlit: 1.34.0
2024-05-07 15:27:37,155:INFO:             prophet: Not installed
2024-05-07 15:27:37,155:INFO:None
2024-05-07 15:27:37,155:INFO:Set up data.
2024-05-07 15:27:37,159:INFO:Set up folding strategy.
2024-05-07 15:27:37,159:INFO:Set up train/test split.
2024-05-07 15:27:37,163:INFO:Set up index.
2024-05-07 15:27:37,163:INFO:Assigning column types.
2024-05-07 15:27:37,165:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-07 15:27:37,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-07 15:27:37,212:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-07 15:27:37,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,283:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-07 15:27:37,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-07 15:27:37,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,310:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-07 15:27:37,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-07 15:27:37,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-07 15:27:37,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,444:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-07 15:27:37,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,575:INFO:Preparing preprocessing pipeline...
2024-05-07 15:27:37,576:INFO:Set up label encoding.
2024-05-07 15:27:37,576:INFO:Set up simple imputation.
2024-05-07 15:27:37,616:INFO:Finished creating preprocessing pipeline.
2024-05-07 15:27:37,620:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-05-07 15:27:37,620:INFO:Creating final display dataframe.
2024-05-07 15:27:37,693:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               5922
1                        Target                                            Species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 6)
5        Transformed data shape                                           (150, 6)
6   Transformed train set shape                                           (105, 6)
7    Transformed test set shape                                            (45, 6)
8              Numeric features                                                  5
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               c68c
2024-05-07 15:27:37,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-07 15:27:37,837:INFO:setup() successfully completed in 0.77s...............
2024-05-07 15:27:37,843:INFO:Initializing compare_models()
2024-05-07 15:27:37,843:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-07 15:27:37,843:INFO:Checking exceptions
2024-05-07 15:27:37,845:INFO:Preparing display monitor
2024-05-07 15:27:37,848:INFO:Initializing Logistic Regression
2024-05-07 15:27:37,848:INFO:Total runtime is 0.0 minutes
2024-05-07 15:27:37,848:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:37,848:INFO:Initializing create_model()
2024-05-07 15:27:37,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:37,848:INFO:Checking exceptions
2024-05-07 15:27:37,848:INFO:Importing libraries
2024-05-07 15:27:37,849:INFO:Copying training dataset
2024-05-07 15:27:37,852:INFO:Defining folds
2024-05-07 15:27:37,852:INFO:Declaring metric variables
2024-05-07 15:27:37,852:INFO:Importing untrained model
2024-05-07 15:27:37,853:INFO:Logistic Regression Imported successfully
2024-05-07 15:27:37,853:INFO:Starting cross validation
2024-05-07 15:27:37,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:42,208:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,210:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,215:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,220:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,272:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,275:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,280:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,285:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,285:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,288:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,290:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,293:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,294:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,295:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,296:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,298:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,299:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,303:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,304:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,308:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,316:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,320:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,320:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,325:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,325:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,328:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,329:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,334:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,336:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,340:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,344:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,348:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,354:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,358:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,364:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,367:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,370:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:42,375:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,379:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,383:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,394:INFO:Calculating mean and std
2024-05-07 15:27:42,402:INFO:Creating metrics dataframe
2024-05-07 15:27:42,405:INFO:Uploading results into container
2024-05-07 15:27:42,405:INFO:Uploading model into container now
2024-05-07 15:27:42,406:INFO:_master_model_container: 1
2024-05-07 15:27:42,406:INFO:_display_container: 2
2024-05-07 15:27:42,407:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5922, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-07 15:27:42,407:INFO:create_model() successfully completed......................................
2024-05-07 15:27:42,570:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:42,572:INFO:Creating metrics dataframe
2024-05-07 15:27:42,573:INFO:Initializing K Neighbors Classifier
2024-05-07 15:27:42,573:INFO:Total runtime is 0.07875296672185263 minutes
2024-05-07 15:27:42,573:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:42,574:INFO:Initializing create_model()
2024-05-07 15:27:42,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:42,574:INFO:Checking exceptions
2024-05-07 15:27:42,574:INFO:Importing libraries
2024-05-07 15:27:42,574:INFO:Copying training dataset
2024-05-07 15:27:42,576:INFO:Defining folds
2024-05-07 15:27:42,577:INFO:Declaring metric variables
2024-05-07 15:27:42,577:INFO:Importing untrained model
2024-05-07 15:27:42,577:INFO:K Neighbors Classifier Imported successfully
2024-05-07 15:27:42,577:INFO:Starting cross validation
2024-05-07 15:27:42,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:42,667:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,667:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,669:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,670:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,671:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,672:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,683:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,683:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,684:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,684:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,684:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,687:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,688:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,688:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,688:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,690:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,692:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,692:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,692:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,692:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:42,692:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,738:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,738:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,741:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,741:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,744:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,744:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,763:INFO:Calculating mean and std
2024-05-07 15:27:44,764:INFO:Creating metrics dataframe
2024-05-07 15:27:44,765:INFO:Uploading results into container
2024-05-07 15:27:44,765:INFO:Uploading model into container now
2024-05-07 15:27:44,767:INFO:_master_model_container: 2
2024-05-07 15:27:44,767:INFO:_display_container: 2
2024-05-07 15:27:44,767:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-07 15:27:44,767:INFO:create_model() successfully completed......................................
2024-05-07 15:27:44,904:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:44,904:INFO:Creating metrics dataframe
2024-05-07 15:27:44,908:INFO:Initializing Naive Bayes
2024-05-07 15:27:44,908:INFO:Total runtime is 0.11765564282735189 minutes
2024-05-07 15:27:44,908:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:44,908:INFO:Initializing create_model()
2024-05-07 15:27:44,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:44,909:INFO:Checking exceptions
2024-05-07 15:27:44,909:INFO:Importing libraries
2024-05-07 15:27:44,909:INFO:Copying training dataset
2024-05-07 15:27:44,912:INFO:Defining folds
2024-05-07 15:27:44,912:INFO:Declaring metric variables
2024-05-07 15:27:44,913:INFO:Importing untrained model
2024-05-07 15:27:44,913:INFO:Naive Bayes Imported successfully
2024-05-07 15:27:44,913:INFO:Starting cross validation
2024-05-07 15:27:44,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:44,958:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,960:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,961:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,962:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,962:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,964:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,965:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,965:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,963:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,966:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,967:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,969:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,969:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,969:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,970:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,972:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,974:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,974:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,974:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,975:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,975:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,978:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,978:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,979:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,980:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,984:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,985:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,987:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,987:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:44,994:INFO:Calculating mean and std
2024-05-07 15:27:44,994:INFO:Creating metrics dataframe
2024-05-07 15:27:44,996:INFO:Uploading results into container
2024-05-07 15:27:44,997:INFO:Uploading model into container now
2024-05-07 15:27:44,997:INFO:_master_model_container: 3
2024-05-07 15:27:44,997:INFO:_display_container: 2
2024-05-07 15:27:44,997:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-07 15:27:44,997:INFO:create_model() successfully completed......................................
2024-05-07 15:27:45,132:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:45,132:INFO:Creating metrics dataframe
2024-05-07 15:27:45,135:INFO:Initializing Decision Tree Classifier
2024-05-07 15:27:45,135:INFO:Total runtime is 0.1214373787244161 minutes
2024-05-07 15:27:45,136:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:45,136:INFO:Initializing create_model()
2024-05-07 15:27:45,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:45,136:INFO:Checking exceptions
2024-05-07 15:27:45,136:INFO:Importing libraries
2024-05-07 15:27:45,136:INFO:Copying training dataset
2024-05-07 15:27:45,139:INFO:Defining folds
2024-05-07 15:27:45,139:INFO:Declaring metric variables
2024-05-07 15:27:45,139:INFO:Importing untrained model
2024-05-07 15:27:45,140:INFO:Decision Tree Classifier Imported successfully
2024-05-07 15:27:45,140:INFO:Starting cross validation
2024-05-07 15:27:45,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:45,186:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,186:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,187:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,190:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,190:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,191:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,191:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,191:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,192:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,194:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,195:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,195:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,196:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,196:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,196:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,196:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,199:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,199:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,200:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,200:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,200:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,200:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,203:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,205:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,207:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,207:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,208:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,209:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,210:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,210:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,226:INFO:Calculating mean and std
2024-05-07 15:27:45,226:INFO:Creating metrics dataframe
2024-05-07 15:27:45,228:INFO:Uploading results into container
2024-05-07 15:27:45,228:INFO:Uploading model into container now
2024-05-07 15:27:45,229:INFO:_master_model_container: 4
2024-05-07 15:27:45,229:INFO:_display_container: 2
2024-05-07 15:27:45,229:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5922, splitter='best')
2024-05-07 15:27:45,229:INFO:create_model() successfully completed......................................
2024-05-07 15:27:45,364:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:45,364:INFO:Creating metrics dataframe
2024-05-07 15:27:45,366:INFO:Initializing SVM - Linear Kernel
2024-05-07 15:27:45,366:INFO:Total runtime is 0.12530349493026732 minutes
2024-05-07 15:27:45,366:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:45,366:INFO:Initializing create_model()
2024-05-07 15:27:45,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:45,366:INFO:Checking exceptions
2024-05-07 15:27:45,366:INFO:Importing libraries
2024-05-07 15:27:45,366:INFO:Copying training dataset
2024-05-07 15:27:45,370:INFO:Defining folds
2024-05-07 15:27:45,370:INFO:Declaring metric variables
2024-05-07 15:27:45,370:INFO:Importing untrained model
2024-05-07 15:27:45,370:INFO:SVM - Linear Kernel Imported successfully
2024-05-07 15:27:45,370:INFO:Starting cross validation
2024-05-07 15:27:45,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:45,420:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,422:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,424:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,426:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,442:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,442:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,442:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,443:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,444:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,445:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,445:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,445:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,445:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,445:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,446:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,447:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,447:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,448:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,448:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,449:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,449:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,449:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:45,450:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:45,450:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,450:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,451:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:45,451:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,452:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,452:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:45,453:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,453:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,453:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,454:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,456:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,458:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,459:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,459:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,462:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,462:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,463:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:45,463:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:45,464:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,464:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,477:INFO:Calculating mean and std
2024-05-07 15:27:45,478:INFO:Creating metrics dataframe
2024-05-07 15:27:45,479:INFO:Uploading results into container
2024-05-07 15:27:45,481:INFO:Uploading model into container now
2024-05-07 15:27:45,481:INFO:_master_model_container: 5
2024-05-07 15:27:45,481:INFO:_display_container: 2
2024-05-07 15:27:45,482:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5922, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-07 15:27:45,482:INFO:create_model() successfully completed......................................
2024-05-07 15:27:45,605:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:45,605:INFO:Creating metrics dataframe
2024-05-07 15:27:45,608:INFO:Initializing Ridge Classifier
2024-05-07 15:27:45,608:INFO:Total runtime is 0.12932428121566772 minutes
2024-05-07 15:27:45,608:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:45,608:INFO:Initializing create_model()
2024-05-07 15:27:45,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:45,608:INFO:Checking exceptions
2024-05-07 15:27:45,608:INFO:Importing libraries
2024-05-07 15:27:45,608:INFO:Copying training dataset
2024-05-07 15:27:45,611:INFO:Defining folds
2024-05-07 15:27:45,611:INFO:Declaring metric variables
2024-05-07 15:27:45,611:INFO:Importing untrained model
2024-05-07 15:27:45,611:INFO:Ridge Classifier Imported successfully
2024-05-07 15:27:45,611:INFO:Starting cross validation
2024-05-07 15:27:45,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:45,648:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,649:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,649:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,649:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,650:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,650:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,650:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,650:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,652:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,653:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,656:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,656:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,656:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,656:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,657:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,658:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,658:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,659:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,659:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,660:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,660:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,660:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,660:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,660:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:45,660:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,660:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,662:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,662:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,663:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,664:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,665:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,665:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,665:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,667:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,668:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,668:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,669:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,669:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:45,679:INFO:Calculating mean and std
2024-05-07 15:27:45,680:INFO:Creating metrics dataframe
2024-05-07 15:27:45,681:INFO:Uploading results into container
2024-05-07 15:27:45,682:INFO:Uploading model into container now
2024-05-07 15:27:45,682:INFO:_master_model_container: 6
2024-05-07 15:27:45,682:INFO:_display_container: 2
2024-05-07 15:27:45,682:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5922, solver='auto',
                tol=0.0001)
2024-05-07 15:27:45,683:INFO:create_model() successfully completed......................................
2024-05-07 15:27:45,802:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:45,803:INFO:Creating metrics dataframe
2024-05-07 15:27:45,805:INFO:Initializing Random Forest Classifier
2024-05-07 15:27:45,805:INFO:Total runtime is 0.13261263370513915 minutes
2024-05-07 15:27:45,805:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:45,805:INFO:Initializing create_model()
2024-05-07 15:27:45,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:45,805:INFO:Checking exceptions
2024-05-07 15:27:45,805:INFO:Importing libraries
2024-05-07 15:27:45,805:INFO:Copying training dataset
2024-05-07 15:27:45,808:INFO:Defining folds
2024-05-07 15:27:45,808:INFO:Declaring metric variables
2024-05-07 15:27:45,808:INFO:Importing untrained model
2024-05-07 15:27:45,809:INFO:Random Forest Classifier Imported successfully
2024-05-07 15:27:45,809:INFO:Starting cross validation
2024-05-07 15:27:45,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:46,142:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,143:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,143:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,143:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,145:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,146:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,146:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,148:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,148:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,149:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,150:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,152:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,152:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,153:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,154:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,155:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,155:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,155:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,158:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,159:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,159:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,159:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,163:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,164:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,170:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,170:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,173:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,174:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,177:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,178:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,193:INFO:Calculating mean and std
2024-05-07 15:27:46,194:INFO:Creating metrics dataframe
2024-05-07 15:27:46,195:INFO:Uploading results into container
2024-05-07 15:27:46,196:INFO:Uploading model into container now
2024-05-07 15:27:46,196:INFO:_master_model_container: 7
2024-05-07 15:27:46,196:INFO:_display_container: 2
2024-05-07 15:27:46,196:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5922, verbose=0,
                       warm_start=False)
2024-05-07 15:27:46,196:INFO:create_model() successfully completed......................................
2024-05-07 15:27:46,324:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:46,324:INFO:Creating metrics dataframe
2024-05-07 15:27:46,326:INFO:Initializing Quadratic Discriminant Analysis
2024-05-07 15:27:46,326:INFO:Total runtime is 0.1412983973821004 minutes
2024-05-07 15:27:46,326:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:46,326:INFO:Initializing create_model()
2024-05-07 15:27:46,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:46,326:INFO:Checking exceptions
2024-05-07 15:27:46,326:INFO:Importing libraries
2024-05-07 15:27:46,326:INFO:Copying training dataset
2024-05-07 15:27:46,329:INFO:Defining folds
2024-05-07 15:27:46,329:INFO:Declaring metric variables
2024-05-07 15:27:46,329:INFO:Importing untrained model
2024-05-07 15:27:46,330:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-07 15:27:46,330:INFO:Starting cross validation
2024-05-07 15:27:46,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:46,363:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,367:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,369:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,370:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,370:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,372:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,373:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,373:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,373:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,373:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,374:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,374:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,376:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,376:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,376:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,376:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,377:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,378:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,378:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,379:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,379:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,380:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,380:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,382:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,382:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,383:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,383:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,383:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,384:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,386:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,386:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,387:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,390:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,390:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,392:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,392:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,394:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,397:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,409:INFO:Calculating mean and std
2024-05-07 15:27:46,410:INFO:Creating metrics dataframe
2024-05-07 15:27:46,410:INFO:Uploading results into container
2024-05-07 15:27:46,412:INFO:Uploading model into container now
2024-05-07 15:27:46,412:INFO:_master_model_container: 8
2024-05-07 15:27:46,412:INFO:_display_container: 2
2024-05-07 15:27:46,412:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-07 15:27:46,412:INFO:create_model() successfully completed......................................
2024-05-07 15:27:46,532:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:46,533:INFO:Creating metrics dataframe
2024-05-07 15:27:46,535:INFO:Initializing Ada Boost Classifier
2024-05-07 15:27:46,535:INFO:Total runtime is 0.1447781960169474 minutes
2024-05-07 15:27:46,536:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:46,536:INFO:Initializing create_model()
2024-05-07 15:27:46,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:46,536:INFO:Checking exceptions
2024-05-07 15:27:46,536:INFO:Importing libraries
2024-05-07 15:27:46,536:INFO:Copying training dataset
2024-05-07 15:27:46,539:INFO:Defining folds
2024-05-07 15:27:46,539:INFO:Declaring metric variables
2024-05-07 15:27:46,539:INFO:Importing untrained model
2024-05-07 15:27:46,539:INFO:Ada Boost Classifier Imported successfully
2024-05-07 15:27:46,539:INFO:Starting cross validation
2024-05-07 15:27:46,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:46,559:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,560:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,561:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,565:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,566:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,567:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,568:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,572:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,573:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,579:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-07 15:27:46,710:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,713:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,714:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,714:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,715:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,717:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,717:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,719:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,722:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,723:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,724:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,732:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,737:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,739:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,740:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,740:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,741:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,741:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,743:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,744:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,744:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,745:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,746:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,746:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,746:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,747:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,748:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,750:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,753:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,762:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,763:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,764:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:46,766:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,766:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,767:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,768:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,770:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:46,780:INFO:Calculating mean and std
2024-05-07 15:27:46,781:INFO:Creating metrics dataframe
2024-05-07 15:27:46,782:INFO:Uploading results into container
2024-05-07 15:27:46,783:INFO:Uploading model into container now
2024-05-07 15:27:46,783:INFO:_master_model_container: 9
2024-05-07 15:27:46,783:INFO:_display_container: 2
2024-05-07 15:27:46,783:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5922)
2024-05-07 15:27:46,783:INFO:create_model() successfully completed......................................
2024-05-07 15:27:46,911:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:46,911:INFO:Creating metrics dataframe
2024-05-07 15:27:46,914:INFO:Initializing Gradient Boosting Classifier
2024-05-07 15:27:46,914:INFO:Total runtime is 0.1510892868041992 minutes
2024-05-07 15:27:46,914:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:46,915:INFO:Initializing create_model()
2024-05-07 15:27:46,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:46,915:INFO:Checking exceptions
2024-05-07 15:27:46,915:INFO:Importing libraries
2024-05-07 15:27:46,915:INFO:Copying training dataset
2024-05-07 15:27:46,918:INFO:Defining folds
2024-05-07 15:27:46,918:INFO:Declaring metric variables
2024-05-07 15:27:46,918:INFO:Importing untrained model
2024-05-07 15:27:46,918:INFO:Gradient Boosting Classifier Imported successfully
2024-05-07 15:27:46,918:INFO:Starting cross validation
2024-05-07 15:27:46,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:47,243:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,245:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,250:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,254:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,263:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,265:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,265:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,266:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,268:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,271:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,273:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,274:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,276:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,279:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,282:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,284:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,285:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,287:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,288:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,288:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,289:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,289:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,291:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,291:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,293:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,294:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,296:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,297:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,299:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,300:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,300:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,302:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,302:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,304:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,305:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,306:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,320:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,322:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,324:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,325:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,340:INFO:Calculating mean and std
2024-05-07 15:27:47,340:INFO:Creating metrics dataframe
2024-05-07 15:27:47,343:INFO:Uploading results into container
2024-05-07 15:27:47,343:INFO:Uploading model into container now
2024-05-07 15:27:47,344:INFO:_master_model_container: 10
2024-05-07 15:27:47,344:INFO:_display_container: 2
2024-05-07 15:27:47,344:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5922, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-07 15:27:47,344:INFO:create_model() successfully completed......................................
2024-05-07 15:27:47,468:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:47,468:INFO:Creating metrics dataframe
2024-05-07 15:27:47,471:INFO:Initializing Linear Discriminant Analysis
2024-05-07 15:27:47,471:INFO:Total runtime is 0.16037452220916745 minutes
2024-05-07 15:27:47,471:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:47,471:INFO:Initializing create_model()
2024-05-07 15:27:47,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:47,471:INFO:Checking exceptions
2024-05-07 15:27:47,471:INFO:Importing libraries
2024-05-07 15:27:47,471:INFO:Copying training dataset
2024-05-07 15:27:47,474:INFO:Defining folds
2024-05-07 15:27:47,474:INFO:Declaring metric variables
2024-05-07 15:27:47,474:INFO:Importing untrained model
2024-05-07 15:27:47,474:INFO:Linear Discriminant Analysis Imported successfully
2024-05-07 15:27:47,475:INFO:Starting cross validation
2024-05-07 15:27:47,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:47,512:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,513:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,514:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,514:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,515:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,515:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,515:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,516:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,516:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,516:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,516:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,518:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,518:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,519:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,519:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,520:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,520:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-07 15:27:47,521:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,522:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,522:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,523:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,523:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,523:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,523:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,523:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,525:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,525:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,526:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,526:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,527:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,528:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,528:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,529:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,530:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,530:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,532:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,535:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,541:INFO:Calculating mean and std
2024-05-07 15:27:47,541:INFO:Creating metrics dataframe
2024-05-07 15:27:47,543:INFO:Uploading results into container
2024-05-07 15:27:47,544:INFO:Uploading model into container now
2024-05-07 15:27:47,544:INFO:_master_model_container: 11
2024-05-07 15:27:47,544:INFO:_display_container: 2
2024-05-07 15:27:47,544:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-07 15:27:47,544:INFO:create_model() successfully completed......................................
2024-05-07 15:27:47,665:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:47,665:INFO:Creating metrics dataframe
2024-05-07 15:27:47,668:INFO:Initializing Extra Trees Classifier
2024-05-07 15:27:47,668:INFO:Total runtime is 0.1636577248573303 minutes
2024-05-07 15:27:47,668:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:47,668:INFO:Initializing create_model()
2024-05-07 15:27:47,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:47,668:INFO:Checking exceptions
2024-05-07 15:27:47,668:INFO:Importing libraries
2024-05-07 15:27:47,668:INFO:Copying training dataset
2024-05-07 15:27:47,671:INFO:Defining folds
2024-05-07 15:27:47,671:INFO:Declaring metric variables
2024-05-07 15:27:47,671:INFO:Importing untrained model
2024-05-07 15:27:47,671:INFO:Extra Trees Classifier Imported successfully
2024-05-07 15:27:47,671:INFO:Starting cross validation
2024-05-07 15:27:47,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:47,938:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,939:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,943:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,945:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,950:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,952:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,954:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,954:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,955:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,955:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,957:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,959:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,959:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,959:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,964:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,964:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,964:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,964:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,983:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,983:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,985:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,987:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,987:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,988:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,989:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:47,989:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,044:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,047:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,049:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,054:INFO:Calculating mean and std
2024-05-07 15:27:48,054:INFO:Creating metrics dataframe
2024-05-07 15:27:48,056:INFO:Uploading results into container
2024-05-07 15:27:48,056:INFO:Uploading model into container now
2024-05-07 15:27:48,056:INFO:_master_model_container: 12
2024-05-07 15:27:48,056:INFO:_display_container: 2
2024-05-07 15:27:48,057:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5922, verbose=0,
                     warm_start=False)
2024-05-07 15:27:48,057:INFO:create_model() successfully completed......................................
2024-05-07 15:27:48,182:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:48,182:INFO:Creating metrics dataframe
2024-05-07 15:27:48,184:INFO:Initializing Light Gradient Boosting Machine
2024-05-07 15:27:48,184:INFO:Total runtime is 0.17226812044779458 minutes
2024-05-07 15:27:48,184:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:48,184:INFO:Initializing create_model()
2024-05-07 15:27:48,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:48,184:INFO:Checking exceptions
2024-05-07 15:27:48,184:INFO:Importing libraries
2024-05-07 15:27:48,184:INFO:Copying training dataset
2024-05-07 15:27:48,187:INFO:Defining folds
2024-05-07 15:27:48,187:INFO:Declaring metric variables
2024-05-07 15:27:48,187:INFO:Importing untrained model
2024-05-07 15:27:48,187:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-07 15:27:48,187:INFO:Starting cross validation
2024-05-07 15:27:48,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:48,905:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,907:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,910:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,912:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,915:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,915:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,946:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,950:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,955:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,957:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,962:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:48,967:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,010:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,014:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,021:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,030:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,037:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,042:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,046:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,050:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,055:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,063:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,066:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,074:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,079:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,083:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,087:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,092:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,095:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,098:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,122:INFO:Calculating mean and std
2024-05-07 15:27:49,123:INFO:Creating metrics dataframe
2024-05-07 15:27:49,125:INFO:Uploading results into container
2024-05-07 15:27:49,125:INFO:Uploading model into container now
2024-05-07 15:27:49,126:INFO:_master_model_container: 13
2024-05-07 15:27:49,126:INFO:_display_container: 2
2024-05-07 15:27:49,127:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5922, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-07 15:27:49,127:INFO:create_model() successfully completed......................................
2024-05-07 15:27:49,263:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:49,263:INFO:Creating metrics dataframe
2024-05-07 15:27:49,265:INFO:Initializing Dummy Classifier
2024-05-07 15:27:49,265:INFO:Total runtime is 0.19028551975886024 minutes
2024-05-07 15:27:49,265:INFO:SubProcess create_model() called ==================================
2024-05-07 15:27:49,265:INFO:Initializing create_model()
2024-05-07 15:27:49,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000150515FF970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:49,266:INFO:Checking exceptions
2024-05-07 15:27:49,266:INFO:Importing libraries
2024-05-07 15:27:49,266:INFO:Copying training dataset
2024-05-07 15:27:49,268:INFO:Defining folds
2024-05-07 15:27:49,268:INFO:Declaring metric variables
2024-05-07 15:27:49,268:INFO:Importing untrained model
2024-05-07 15:27:49,268:INFO:Dummy Classifier Imported successfully
2024-05-07 15:27:49,268:INFO:Starting cross validation
2024-05-07 15:27:49,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-07 15:27:49,301:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,305:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,306:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,306:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,306:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,307:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,308:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,308:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,309:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,309:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,309:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,310:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,311:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,311:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,311:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,313:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,313:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,313:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,314:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,314:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,315:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,315:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,315:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,315:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,315:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,316:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,316:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,317:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,317:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,319:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,319:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,319:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,319:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,321:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,321:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-07 15:27:49,321:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,323:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,324:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 'Iris-virginica') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-07 15:27:49,342:INFO:Calculating mean and std
2024-05-07 15:27:49,343:INFO:Creating metrics dataframe
2024-05-07 15:27:49,344:INFO:Uploading results into container
2024-05-07 15:27:49,344:INFO:Uploading model into container now
2024-05-07 15:27:49,344:INFO:_master_model_container: 14
2024-05-07 15:27:49,345:INFO:_display_container: 2
2024-05-07 15:27:49,345:INFO:DummyClassifier(constant=None, random_state=5922, strategy='prior')
2024-05-07 15:27:49,345:INFO:create_model() successfully completed......................................
2024-05-07 15:27:49,464:INFO:SubProcess create_model() end ==================================
2024-05-07 15:27:49,464:INFO:Creating metrics dataframe
2024-05-07 15:27:49,468:WARNING:D:\streamlit projects\ML project\ml_project\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-07 15:27:49,469:INFO:Initializing create_model()
2024-05-07 15:27:49,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015047F8AE30>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5922, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-07 15:27:49,469:INFO:Checking exceptions
2024-05-07 15:27:49,469:INFO:Importing libraries
2024-05-07 15:27:49,469:INFO:Copying training dataset
2024-05-07 15:27:49,472:INFO:Defining folds
2024-05-07 15:27:49,472:INFO:Declaring metric variables
2024-05-07 15:27:49,473:INFO:Importing untrained model
2024-05-07 15:27:49,473:INFO:Declaring custom model
2024-05-07 15:27:49,473:INFO:Logistic Regression Imported successfully
2024-05-07 15:27:49,474:INFO:Cross validation set to False
2024-05-07 15:27:49,474:INFO:Fitting Model
2024-05-07 15:27:49,520:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5922, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-07 15:27:49,520:INFO:create_model() successfully completed......................................
2024-05-07 15:27:49,652:INFO:_master_model_container: 14
2024-05-07 15:27:49,652:INFO:_display_container: 2
2024-05-07 15:27:49,653:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5922, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-07 15:27:49,653:INFO:compare_models() successfully completed......................................
2024-05-07 15:27:49,660:INFO:Initializing save_model()
2024-05-07 15:27:49,661:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5922, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Asus\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-05-07 15:27:49,661:INFO:Adding model into prep_pipe
2024-05-07 15:27:49,665:INFO:best_model.pkl saved in current working directory
2024-05-07 15:27:49,671:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Id', 'SepalLengthCm',
                                             'SepalWidthCm', 'PetalLengthCm',
                                             'PetalWidthCm'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=5922,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-05-07 15:27:49,671:INFO:save_model() successfully completed......................................
